{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"LCLS-Live","text":"<p>The LCLS accelerator complex consists of multiple electron sources and multiple beam paths. Live models are computer simulation programs that continuously execute with inputs taken from the machine, and serve physics predictions of the beam behavior.</p> <p>LCLS-Live is a Python package with related tools and data to help in translating machine settings to simulation models. Currently it is heavly biased towards Bmad models of the accelerators. In the future we will extent it through the X-ray beamlines. </p> <p></p>"},{"location":"#design-models","title":"Design models","text":""},{"location":"#copper-linac","title":"Copper Linac","text":"cu_hxrcu_sxrcu_spec"},{"location":"#superconducting-linac","title":"Superconducting Linac","text":"sc_hxrsc_sxrsc_diag0sc_injsc_bsydsc_dasel <p>The input files for various simulation software are collected in the LCLS-Lattice repository.</p>"},{"location":"#simulation-software","title":"Simulation software","text":"<ul> <li>Bmad and Tao for charged particle beam dynamics.</li> <li>LUME-Impact for running Impact-T from Python.</li> <li>tensorflow for neural network-based machine learning (ML) surrogate models. </li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#bmad-and-tao-tutorial","title":"Bmad and Tao Tutorial","text":"<p>If you are new to Bmad and Tao, please go to the official Bmad website and follow the Tutorial document using the Example files.</p> <p>The tutorial is designed to be self-paced, with an introductory video presentation and chapter-specific channels in the Bmad Slack Workspace</p>"},{"location":"getting-started/#setup","title":"Setup","text":"<p>See Enviromnent for how to set up your environment on various systems.</p>"},{"location":"getting-started/#tao-command-line","title":"Tao command line","text":"<pre><code>tao -init $LCLS_LATTICE/bmad/models/cu_hxr/tao.init\n</code></pre>"},{"location":"getting-started/#pytao","title":"PyTao","text":"<pre><code>from pytao import Tao\ntao = Tao('-init $LCLS_LATTICE/bmad/models/cu_hxr/tao.init')\n</code></pre>"},{"location":"getting-started/#live-or-archived-pv-data","title":"Live or archived PV data","text":"<p>Use the get-lcls-live command line tool to extract PV data from EPICS or the archiver, and form the appropriate tao commands:</p> <pre><code>get-lcls-live --beampath cu_hxr --source epics --tao &gt; cmds.tao\n</code></pre>"},{"location":"help/","title":"Getting Help","text":"<p>General questions about Bmad should be directed to the Bmad Slack Workspace. Please search the Bmad manual or Tao manual first.</p> <p>SLAC Bmad specific questions: #bmad channel in the SLAC workspace</p> <p>LCLS Live questions #lcls-live channel in the SLAC workspace</p>"},{"location":"developer/","title":"SLAC Developer setup","text":""},{"location":"developer/#lcls-production-environment","title":"LCLS Production Environment","text":"<p>Developers on the LCLS production environment should use the nightly builds: <pre><code>source $TOOLS/script/use_python3_devel.sh\n</code></pre> This is described in LCLS Python Environments. This includes the lattice files.</p>"},{"location":"developer/#local","title":"Local","text":"<p>Local developers should clone the LCLS-Live repository and create a conda environment from the <code>environment-dev.yml</code>: <pre><code>conda env create -f environment-dev.yml\nconda activate lcls-live-dev\n</code></pre></p> <p>Lattice files are protected and must be install separately according to the instructions in LCLS-Lattice-Data </p> <p>This documentation can be built with: <pre><code>mkdocs serve\n</code></pre></p>"},{"location":"developer/mkdocs/","title":"Updating this documentation","text":"<p>These docs are created using mkdocs:</p>"},{"location":"developer/mkdocs/#setup","title":"Setup","text":"<p>Install mkdocs and its various plugins using <code>conda</code> and <code>pip</code>:</p> <pre><code>conda install mkdocs pygments mkdocs-material\n\npip install mkdocs-minify-plugin\n</code></pre>"},{"location":"developer/mkdocs/#deploy-to-github-pages","title":"Deploy to GitHub pages","text":"<pre><code>mkdocs gh-deploy\n</code></pre>"},{"location":"developer/mkdocs/#slac-clone","title":"SLAC clone","text":"<p>A clone of the lcls-live gh-pages branch is here</p> <p><code>/afs/slac/www/grp/ad/docs/python/lcls-live</code></p> <p>and are served here</p>"},{"location":"developer/requirements/","title":"Requirements for Models and Model Services (live models)","text":"<p>Physics-based <code>models</code> are intended to provide physical predictions of beam-related quantities. We have an immediate need for injector and beamline <code>model services</code> that continuously read from a common EPICS network and serve some of these quantities as PVs on the same network.  </p> <p>The following are <code>minimal</code> requirements.</p>"},{"location":"developer/requirements/#computing","title":"Computing","text":"<ul> <li>All models and model services should be able to run on the production, devel, and SDF environments. </li> </ul>"},{"location":"developer/requirements/#models","title":"Models","text":"<p>Models are collected in git repositories hosted at https://github.com/slaclab/</p> <p>Baseline physics models are collected in the <code>lcls-lattice</code> git repository. The main source is hosted at: https://github.com/slaclab/lcls-lattice with the <code>$LCLS_LATTICE</code> enviromnental variable defined on local systems to point to a checked out version.</p>"},{"location":"developer/requirements/#lcls-cu-inj","title":"lcls-cu-inj","text":"<ul> <li>source: <code>$LCLS_LATTICE/impact/models/cu_inj</code></li> <li>documentation: TODO</li> <li>dependencies: <ul> <li>Impact-T executable</li> </ul> </li> </ul>"},{"location":"developer/requirements/#lcls-cu-inj-surrogate","title":"lcls-cu-inj-surrogate","text":"<ul> <li>source: https://github.com/slaclab/lcls-cu-inj-surrogate</li> <li>developers:<ul> <li>Auralee Edelen</li> </ul> </li> <li>description: Pre-trained neural network surrogage model for the lcls-cu-inj model. </li> <li>documentation: at source</li> <li>dependencies: <ul> <li>Python <ul> <li>tensorflow</li> </ul> </li> </ul> </li> </ul>"},{"location":"developer/requirements/#lcls-beamlines","title":"lcls-beamlines","text":"<ul> <li>source: <code>$LCLS_LATTICE/bmad/models/cu_hxr</code>, <code>cu_sxr</code></li> <li>documentation: TODO</li> <li>dependencies: Bmad distribution (executables and libraries)</li> </ul>"},{"location":"developer/requirements/#model-services","title":"Model Services","text":""},{"location":"developer/requirements/#lcls-cu-inj-live","title":"lcls-cu-inj-live","text":"<ul> <li>source: https://github.com/slaclab/lcls-cu-inj-live</li> <li> <p>Developers:</p> <ul> <li>Jaqueline Garrahan</li> <li>Hugo Slepicka </li> </ul> </li> <li> <p>documentation: https://github.com/slaclab/lcls-cu-inj-live/blob/main/README.md</p> </li> <li> <p>dependencies:</p> </li> <li>model: lcls-cu-inj-surrogate</li> <li> <p>software:</p> <ul> <li>Python<ul> <li>tensorflow</li> <li>lume-model</li> <li>lume-epics</li> </ul> </li> </ul> </li> <li> <p>EPICS inputs: </p> <ul> <li>laser parameters</li> <li>Gun and Linac phases and amplitudes</li> <li>Magnet strengths (Solenoid, corrector quads, quads)</li> </ul> </li> <li> <p>EPICS outputs:</p> <ul> <li>beam sigma matrix at screens:<ul> <li>YAG02</li> <li>OTR2</li> </ul> </li> <li>beam phase space projections at the same screens</li> </ul> </li> </ul>"},{"location":"developer/requirements/#lcls-beamlines_1","title":"lcls-beamlines","text":"<ul> <li>source: https://github.com/slaclab/lcls_live_model</li> <li> <p>developers:</p> <ul> <li>Matt Gibbs</li> <li>Christopher Mayes</li> <li>Hugo Slepicka</li> </ul> </li> <li> <p>documentation: TODO</p> </li> <li> <p>dependencies: </p> <ul> <li>lcls-beamlines models</li> <li>Python<ul> <li>pyepics</li> </ul> </li> </ul> </li> <li> <p>EPICS inputs: </p> <ul> <li>Initial Twiss (TODO)</li> <li>Klystron level phases and amplitudes</li> <li>Linac overall phases</li> <li>quadrupole strengths</li> <li>bunch compressor settings</li> </ul> </li> <li> <p>EPICS outputs:</p> <ul> <li>Twiss parameters at all elements</li> </ul> </li> </ul>"},{"location":"developer/requirements/#deployment","title":"Deployment","text":""},{"location":"developer/requirements/#cu-inj-surrogate","title":"cu-inj-surrogate","text":"<p>on DMZ</p> <p>retraining using SDF</p>"},{"location":"developer/requirements/#lcls-beamlinessxr-hxr","title":"lcls-beamlines:sxr, hxr","text":"<p>on DMZ</p>"},{"location":"developer/roadmap/","title":"Development Roadmap","text":""},{"location":"developer/roadmap/#basic-requirements-for-the-accelerator-models","title":"Basic requirements for the accelerator models","text":"<ul> <li>Read PVs from the live machine</li> <li>publish transfer matrices, computed Twiss as PV tables</li> <li>Refresh rate should be 1/2 Hz, to help an operator hand-tune. <ul> <li>How fast can it be?</li> </ul> </li> <li>Read initial Twiss from PVs (served from cu_inj surrogate)</li> </ul>"},{"location":"developer/roadmap/#next-requirements","title":"Next requirements","text":"<ul> <li>Read correctors, serve orbit. (Needs some analysis)</li> <li>Serve response matrices:<ul> <li>Corrector to BPM</li> </ul> </li> <li>LEM </li> <li>Track particles (OpenMP will speed up)</li> </ul>"},{"location":"developer/roadmap/#lcls-live-model-development-todo","title":"LCLS Live Model development TODO","text":"<p>Roughly in order of priority</p> <p>https://github.com/slaclab/lcls_live_model?organization=slaclab&amp;organization=slaclab</p>"},{"location":"developer/roadmap/#beam-code-switch-for-second-beam","title":"Beam code switch for 'second beam'","text":"<ul> <li>needs a command line switch on init?</li> <li>BEAMCODE 1, 2</li> <li>Current init is: cu_sxr, cu_hxr. </li> </ul>"},{"location":"developer/roadmap/#read-initial-twiss","title":"Read initial Twiss","text":"<ul> <li>should be served by cu-inj-surrogate. S<ul> <li>Surrogate should serve sigma matrix, derived 'Twiss'</li> </ul> </li> <li>Should read from PVs</li> </ul>"},{"location":"developer/roadmap/#offline-use","title":"Offline use","text":"<ul> <li>Simple method to test this without EPICs</li> <li>Collect internal state </li> <li>Vanilla Tao</li> </ul>"},{"location":"developer/roadmap/#live-model-live-bmad-models","title":"Live Model -&gt; Live Bmad models","text":"<ul> <li>There will be other models</li> <li>multi-fidelity models (see below)</li> </ul>"},{"location":"developer/roadmap/#clean-up-modelservice-class","title":"Clean up ModelService class","text":"<ul> <li>move NTTable init outside</li> <li> <p>generalize to serve:</p> <ul> <li>orbit</li> <li>get ele dict info, other structures from pytao</li> <li>response matrices (optional)</li> <li>beam tracking (probably a seperate model instance for this, can use OpenMP)</li> </ul> </li> <li> <p>Tao object</p> <ul> <li>Tao -&gt; TaoModel -&gt; (LCLSTaoModel that has all Tao commands.)</li> </ul> </li> <li> <p>Brige: PV -&gt; bridge -&gt; Vanilla Tao</p> </li> <li> <p>Model saving for simple reload in tao: <code>tao -lat lat.bmad</code></p> </li> <li> <p>Make more similar to the cu-inj-surrogate, LUME-model, or vice-versa?</p> </li> <li> <p>keep track of internal state</p> </li> </ul>"},{"location":"developer/roadmap/#generalize-to-compute-on-sdf","title":"Generalize to compute on SDF","text":"<ul> <li>Tao, Impact-T, Impact-Z, Genesis 1.3, SRW... </li> <li>under LUME scope</li> </ul>"},{"location":"developer/roadmap/#add-lcls-live-as-a-dependency","title":"Add lcls-live as a dependency","text":"<ul> <li>rely on CSV mapping from lcls-live</li> <li>Klystron class from lcls-live</li> </ul>"},{"location":"developer/roadmap/#clean-up-klystron-reader","title":"Clean up Klystron reader","text":"<ul> <li>many things are hardcoded tao commands</li> </ul>"},{"location":"developer/roadmap/#clean-up-repository","title":"Clean up repository","text":"<ul> <li>move Python code into a subdirector, add docs</li> <li>OR, make this a very small script that depends on lcls-live classes and functions. </li> </ul>"},{"location":"developer/roadmap/#documentation","title":"Documentation","text":"<p>The code is pretty clear, but needs docstrings, examples, etc.</p>"},{"location":"developer/roadmap/#ctrl-c-doesnt-kill","title":"CTRL-C doesn't kill","text":""},{"location":"developer/roadmap/#need-to-serve-fake-pvs-for-testing","title":"Need to serve fake PVs for testing","text":"<ul> <li>simulation mode, from JSON file</li> <li>or simple PV server from JSON</li> <li>expand lcls-live/epics_proxy</li> </ul>"},{"location":"developer/roadmap/#klystron-reader-fails-when-no-pvs-are-there","title":"Klystron reader fails when no PVs are there","text":"<pre><code>lcls_live_model/klystron_tools.py\", line 220, in testbit\n    return ((int(word) &amp; mask) &gt; 0)\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'NoneType'\n</code></pre>"},{"location":"environment/","title":"User Environment","text":"<ul> <li>A compiled Bmad distribution, and enabled </li> <li> <p>Python 3.7 or greater environment with:</p> <ul> <li><code>pyepics</code></li> <li><code>pytao</code></li> <li><code>lcls_live</code></li> </ul> </li> <li> <p><code>$LCLS_LATTICE</code> environmental variable pointing to the LCLS-Lattice files</p> </li> <li>EPICS installation (for live PVs)</li> <li>Archiver access (for archived PVs)</li> </ul> LCLS ProductionLocal <p>Most LCLS users should use the standard Python environemt: <pre><code>source $TOOLS/script/use_python3.sh\n</code></pre></p> <p>Developers should use the nightly environment: <pre><code>source $TOOLS/script/use_python3_nightly.sh\n</code></pre></p> <p>These is described in LCLS Python Environments and includ the lattice files.</p> <p>Local developers should clone the LCLS-Live repository and create a conda environment from the <code>environment-dev.yml</code>: <pre><code>conda env create -f environment-dev.yml\nconda activate lcls-live-dev\n</code></pre></p> <p>Lattice files are protected and must be install separately according to the instructions in LCLS-Lattice-Data </p>"},{"location":"examples/LCLS_beam_tracking/","title":"LCLS cu_hxr from archived data","text":"In\u00a0[1]: Copied! <pre># Useful for debugging\n%load_ext autoreload\n%autoreload 2\n\n%config InlineBackend.figure_format = 'retina'\n</pre> # Useful for debugging %load_ext autoreload %autoreload 2  %config InlineBackend.figure_format = 'retina' In\u00a0[2]: Copied! <pre>%pylab inline\n</pre> %pylab inline <pre>%pylab is deprecated, use %matplotlib inline and import the required libraries.\nPopulating the interactive namespace from numpy and matplotlib\n</pre> In\u00a0[3]: Copied! <pre>from lcls_live.datamaps import get_datamaps\nfrom lcls_live.archiver import lcls_archiver_restore\n\nimport os\n</pre> from lcls_live.datamaps import get_datamaps from lcls_live.archiver import lcls_archiver_restore  import os In\u00a0[4]: Copied! <pre>BEAMPATH = 'cu_hxr'\n</pre> BEAMPATH = 'cu_hxr' In\u00a0[5]: Copied! <pre>DM = get_datamaps(BEAMPATH)\n\nDM.keys()\n</pre> DM = get_datamaps(BEAMPATH)  DM.keys() Out[5]: <pre>dict_keys(['bpms', 'correctors', 'subboosters', 'linac', 'K21_1', 'K21_2', 'K21_3', 'K21_4', 'K21_5', 'K21_6', 'K21_7', 'K21_8', 'K22_1', 'K22_2', 'K22_3', 'K22_4', 'K22_5', 'K22_6', 'K22_7', 'K22_8', 'K23_1', 'K23_2', 'K23_3', 'K23_4', 'K23_5', 'K23_6', 'K23_7', 'K23_8', 'K24_1', 'K24_2', 'K24_3', 'K24_4', 'K24_5', 'K24_6', 'K25_1', 'K25_2', 'K25_3', 'K25_4', 'K25_5', 'K25_6', 'K25_7', 'K25_8', 'K26_1', 'K26_2', 'K26_3', 'K26_4', 'K26_5', 'K26_6', 'K26_7', 'K26_8', 'K27_1', 'K27_2', 'K27_3', 'K27_4', 'K27_5', 'K27_6', 'K27_7', 'K27_8', 'K28_1', 'K28_2', 'K28_3', 'K28_4', 'K28_5', 'K28_6', 'K28_7', 'K28_8', 'K29_1', 'K29_2', 'K29_3', 'K29_4', 'K29_5', 'K29_6', 'K29_7', 'K29_8', 'K30_1', 'K30_2', 'K30_3', 'K30_4', 'K30_5', 'K30_6', 'K30_7', 'K30_8', 'quad', 'beginning_WS02', 'tao_energy_measurements'])</pre> In\u00a0[6]: Copied! <pre># datamaps to exclude\nDENYLIST = ['beginning_WS02', 'quad', 'bpms', 'correctors']\n</pre> # datamaps to exclude DENYLIST = ['beginning_WS02', 'quad', 'bpms', 'correctors'] In\u00a0[7]: Copied! <pre># PVs needed\nALLPVS =  []\nfor name, dm in DM.items():\n    if name in DENYLIST:\n        continue\n    ALLPVS.extend(dm.pvlist)\nALLPVS = list(set(ALLPVS))\nlen(ALLPVS)\n</pre> # PVs needed ALLPVS =  [] for name, dm in DM.items():     if name in DENYLIST:         continue     ALLPVS.extend(dm.pvlist) ALLPVS = list(set(ALLPVS)) len(ALLPVS) Out[7]: <pre>553</pre> In\u00a0[8]: Copied! <pre>ISOTIME = '2022-06-29T06:55:00.000000-07:00'\n</pre> ISOTIME = '2022-06-29T06:55:00.000000-07:00' In\u00a0[9]: Copied! <pre># Optional off-site setup\n\n# Open an SSH tunnel in a terminal like:\n# ssh -D 8080 &lt;some user&gt;@&lt;some SLAC machine&gt;\n\nOFFSITE=True\n\nif OFFSITE:\n    os.environ['http_proxy']='socks5h://localhost:8080'\n    os.environ['HTTPS_PROXY']='socks5h://localhost:8080'\n    os.environ['ALL_PROXY']='socks5h://localhost:8080'\n</pre> # Optional off-site setup  # Open an SSH tunnel in a terminal like: # ssh -D 8080 @  OFFSITE=True  if OFFSITE:     os.environ['http_proxy']='socks5h://localhost:8080'     os.environ['HTTPS_PROXY']='socks5h://localhost:8080'     os.environ['ALL_PROXY']='socks5h://localhost:8080' In\u00a0[10]: Copied! <pre>PVDATA = lcls_archiver_restore(ALLPVS, ISOTIME)\n</pre> PVDATA = lcls_archiver_restore(ALLPVS, ISOTIME) <pre>Requesting: http://lcls-archapp.slac.stanford.edu/retrieval/data/getDataAtTime?at=2021-11-21T08:10:25.000000-07:00&amp;includeProxies=true\n</pre> In\u00a0[11]: Copied! <pre>CMDS = []\nfor name, dm in DM.items():\n    CMDS.extend(dm.as_tao(PVDATA))\n\nCMDS[0:5]\n</pre> CMDS = [] for name, dm in DM.items():     CMDS.extend(dm.as_tao(PVDATA))  CMDS[0:5] Out[11]: <pre>['! Bad value for orbit.x[1][]: None',\n '! Bad value for orbit.x[2][]: None',\n '! Bad value for orbit.x[3][]: None',\n '! Bad value for orbit.x[4][]: None',\n '! Bad value for orbit.x[5][]: None']</pre> In\u00a0[12]: Copied! <pre>from pytao import Tao\n</pre> from pytao import Tao In\u00a0[13]: Copied! <pre>tao = Tao(f'-init $LCLS_LATTICE/bmad/models/{BEAMPATH}/tao.init -slice BEGINNING:ENDUNDH -noplot')\n</pre> tao = Tao(f'-init $LCLS_LATTICE/bmad/models/{BEAMPATH}/tao.init -slice BEGINNING:ENDUNDH -noplot') In\u00a0[14]: Copied! <pre># apply commands all at once\ntao.cmds(CMDS);\n</pre> # apply commands all at once tao.cmds(CMDS); In\u00a0[15]: Copied! <pre># Explicitly save beam \ntao.cmd('set beam saved_at = MARKER::*')\n#tao.cmd('set beam saved_at = BEGUNDH,ENDUNDH')\n</pre> # Explicitly save beam  tao.cmd('set beam saved_at = MARKER::*') #tao.cmd('set beam saved_at = BEGUNDH,ENDUNDH') Out[15]: <pre>[]</pre> In\u00a0[16]: Copied! <pre># Turn on CSR\ntao.cmd(f'call $LCLS_LATTICE/bmad/models/{BEAMPATH}/scripts/Activate_CSR.tao');\n</pre> # Turn on CSR tao.cmd(f'call $LCLS_LATTICE/bmad/models/{BEAMPATH}/scripts/Activate_CSR.tao'); In\u00a0[17]: Copied! <pre># Turn on the beam\ntao.cmd('set beam_init n_particle = 10000')\n</pre> # Turn on the beam tao.cmd('set beam_init n_particle = 10000') Out[17]: <pre>[]</pre> In\u00a0[18]: Copied! <pre>#toggle on and off\ntao.cmd('set global track_type = beam', raises=False) \n</pre> #toggle on and off tao.cmd('set global track_type = beam', raises=False)  Out[18]: <pre>['Beam at Element: 1679. Time: 1 min', 'Beam at Element: 1872. Time: 2 min']</pre> In\u00a0[19]: Copied! <pre>tao.cmd('set global track_type = single') \n</pre> tao.cmd('set global track_type = single')  Out[19]: <pre>[]</pre> In\u00a0[20]: Copied! <pre>from pmd_beamphysics import ParticleGroup\n</pre> from pmd_beamphysics import ParticleGroup In\u00a0[21]: Copied! <pre>P = ParticleGroup(data=tao.bunch_data('ENDUNDH'))\n# Select out live particles\nP = P[P.status==1]\n</pre> P = ParticleGroup(data=tao.bunch_data('ENDUNDH')) # Select out live particles P = P[P.status==1] In\u00a0[22]: Copied! <pre>P.plot('t', 'energy')\n</pre> P.plot('t', 'energy') In\u00a0[23]: Copied! <pre># Make a function for this\ndef get_beam(ele):\n    P = ParticleGroup(data=tao.bunch_data(ele))\n    # Select out live particles\n    P = P[P.status==1]    \n    \n    return P\n</pre> # Make a function for this def get_beam(ele):     P = ParticleGroup(data=tao.bunch_data(ele))     # Select out live particles     P = P[P.status==1]              return P In\u00a0[24]: Copied! <pre>P1 = get_beam('BEGUNDH')\nP1.plot('delta_t', 'delta_energy')\n</pre> P1 = get_beam('BEGUNDH') P1.plot('delta_t', 'delta_energy') In\u00a0[25]: Copied! <pre>P2 = get_beam('ENDUNDH')\nP2.plot('delta_t', 'delta_energy')\n</pre> P2 = get_beam('ENDUNDH') P2.plot('delta_t', 'delta_energy') In\u00a0[26]: Copied! <pre>%%tao\nsho beam 2823\n</pre> %%tao sho beam 2823 <pre>-------------------------\nTao&gt; sho beam 2823\nBunch parameters at: RFBHX45 (2823)\n  Parameters for bunch:       1\n  S-position:                   1.68055764E+03\n  In branch:                  0\n  Particles surviving:        10000\n  Particles lost:             0\n  Particles lost (%):         .000\n  Charge live (C):              2.50000000E-10\n  Centroid: -7.76130185E-05  2.11279989E-06  7.52340483E-08  1.73397823E-08 -5.71297016E-05 -2.82776806E-03\n  RMS:       6.16340998E-05  2.68061431E-06  2.14073515E-05  1.98094351E-06  1.02469430E-05  8.82717218E-04\n\n               norm_emitt            emit            beta           alpha\n  a:         8.21719362E-07  4.11117286E-11  3.61999433E+01  1.79075358E+00\n  b:         5.12404873E-07  2.56363073E-11  1.77459709E+01 -1.30780669E+00\n  x:         9.33624400E-07  4.67104887E-11  3.41105299E+01  1.57513674E+00\n  y:         5.13796157E-07  2.57059151E-11  1.78274499E+01 -1.31203839E+00\n  z:         1.37544706E-04  6.88154725E-09  1.52581733E-02\n\nSigma Mat       x              px               y              py              z             pz\nx     3.79876225E-09 -1.46612988E-10  2.81783662E-12  5.80982008E-13  3.92915072E-10  4.14542909E-08\npx   -1.46612988E-10  7.18569308E-12 -1.06971776E-12 -6.20128915E-14 -1.03725912E-11 -1.37284052E-09\ny     2.81783662E-12 -1.06971776E-12  4.58274700E-10  3.37269800E-11  1.35861156E-13  5.43106327E-11\npy    5.80982008E-13 -6.20128915E-14  3.37269800E-11  3.92413720E-12  9.24546927E-14 -2.40281015E-12\nz     3.92915072E-10 -1.03725912E-11  1.35861156E-13  9.24546927E-14  1.04999841E-10  5.87018742E-09\npz    4.14542909E-08 -1.37284052E-09  5.43106327E-11 -2.40281015E-12  5.87018742E-09  7.79189687E-07\n\nNote: Individual particle positions are not saved at this element.\n-------------------------\nTao&gt; \n</pre> In\u00a0[27]: Copied! <pre># Compare on the same plot\nk1= 'delta_t'\nk2 = 'delta_energy'\nplt.scatter(P1[k1], P1[k2], marker='.', alpha=0.1)\nplt.scatter(P2[k1], P2[k2], marker='.', alpha=0.1)\nplt.xlabel(f'{k1} ({P1.units(k1).unitSymbol})')\nplt.ylabel(f'{k2} ({P1.units(k2).unitSymbol})')\n</pre> # Compare on the same plot k1= 'delta_t' k2 = 'delta_energy' plt.scatter(P1[k1], P1[k2], marker='.', alpha=0.1) plt.scatter(P2[k1], P2[k2], marker='.', alpha=0.1) plt.xlabel(f'{k1} ({P1.units(k1).unitSymbol})') plt.ylabel(f'{k2} ({P1.units(k2).unitSymbol})') Out[27]: <pre>Text(0, 0.5, 'delta_energy (eV)')</pre> In\u00a0[28]: Copied! <pre>import pandas as pd\n</pre> import pandas as pd In\u00a0[29]: Copied! <pre># Get list of indices\nIX = tao.lat_list('*', 'ele.ix_ele')\n\n# Stop before the dump\nS_STOP = tao.ele_head('ENDUNDH')['s']\n\nstats = []\nfor ele in IX:\n    d = tao.bunch_params(ele)\n    # Skipl ones with no beam\n    if d['charge_live'] == 0:\n        continue\n    \n    if d['s'] &gt; S_STOP:\n        break\n        \n    stats.append(d)\n\ndf = pd.DataFrame(stats)#.set_index('ix_ele')\n</pre> # Get list of indices IX = tao.lat_list('*', 'ele.ix_ele')  # Stop before the dump S_STOP = tao.ele_head('ENDUNDH')['s']  stats = [] for ele in IX:     d = tao.bunch_params(ele)     # Skipl ones with no beam     if d['charge_live'] == 0:         continue          if d['s'] &gt; S_STOP:         break              stats.append(d)  df = pd.DataFrame(stats)#.set_index('ix_ele')  In\u00a0[30]: Copied! <pre>fig, ax = plt.subplots(figsize=(12,5))\nplt.plot(df['s'], df['sigma_x']*1e6, label=r'$\\sigma_x$')\nplt.plot(df['s'], df['sigma_y']*1e6, label=r'$\\sigma_y$')\nplt.xlabel('s (m)')\nplt.ylabel('beam sizes (\u00b5m)')\nplt.legend();\n</pre> fig, ax = plt.subplots(figsize=(12,5)) plt.plot(df['s'], df['sigma_x']*1e6, label=r'$\\sigma_x$') plt.plot(df['s'], df['sigma_y']*1e6, label=r'$\\sigma_y$') plt.xlabel('s (m)') plt.ylabel('beam sizes (\u00b5m)') plt.legend(); In\u00a0[31]: Copied! <pre># Get an array of where the beam is saved\ns_saved = np.array(df[df['beam_saved']]['s'])\n</pre> # Get an array of where the beam is saved s_saved = np.array(df[df['beam_saved']]['s']) In\u00a0[32]: Copied! <pre>fig, ax = plt.subplots(figsize=(12,5))\nplt.plot(df['s'], df['norm_emit_x']*1e6, label=r'$\\epsilon_{n,x}$')\nplt.plot(df['s'], df['norm_emit_y']*1e6, label=r'$\\epsilon_{n,y}$')\nplt.xlabel('s (m)')\nplt.ylabel('Beam emittance(mm-mrad)')\n\n\n# This is where the beam is saved\nplt.scatter(s_saved, np.ones(len(s_saved))*0, color = 'black', marker = 'x')\n\n\nplt.legend();\n</pre> fig, ax = plt.subplots(figsize=(12,5)) plt.plot(df['s'], df['norm_emit_x']*1e6, label=r'$\\epsilon_{n,x}$') plt.plot(df['s'], df['norm_emit_y']*1e6, label=r'$\\epsilon_{n,y}$') plt.xlabel('s (m)') plt.ylabel('Beam emittance(mm-mrad)')   # This is where the beam is saved plt.scatter(s_saved, np.ones(len(s_saved))*0, color = 'black', marker = 'x')   plt.legend();"},{"location":"examples/LCLS_beam_tracking/#lcls-cu_hxr-from-archived-data","title":"LCLS cu_hxr from archived data\u00b6","text":""},{"location":"examples/LCLS_beam_tracking/#datamaps-and-all-pvs-needed","title":"Datamaps, and all PVs needed\u00b6","text":""},{"location":"examples/LCLS_beam_tracking/#archiver-restore","title":"Archiver restore\u00b6","text":""},{"location":"examples/LCLS_beam_tracking/#form-commands-using-pvdata-and-datamaps","title":"Form commands using PVDATA and datamaps\u00b6","text":""},{"location":"examples/LCLS_beam_tracking/#start-tao","title":"Start Tao\u00b6","text":""},{"location":"examples/LCLS_beam_tracking/#get-particles","title":"Get particles\u00b6","text":""},{"location":"examples/LCLS_beam_tracking/#get-giant-table-of-bunch-stats","title":"Get giant table of bunch stats\u00b6","text":""},{"location":"examples/SXR_energy_profile/","title":"SXR Energy Profile","text":"In\u00a0[1]: Copied! <pre># Useful for debugging\n%load_ext autoreload\n%autoreload 2\n\n%config InlineBackend.figure_format = 'retina'\n%pylab inline\n</pre> # Useful for debugging %load_ext autoreload %autoreload 2  %config InlineBackend.figure_format = 'retina' %pylab inline <pre>Populating the interactive namespace from numpy and matplotlib\n</pre> In\u00a0[2]: Copied! <pre>from lcls_live.datamaps import get_datamaps\nfrom lcls_live.archiver import lcls_archiver_restore\n\nfrom pytao import Tao\n\nimport os\n</pre> from lcls_live.datamaps import get_datamaps from lcls_live.archiver import lcls_archiver_restore  from pytao import Tao  import os In\u00a0[3]: Copied! <pre>BEAMPATH = 'cu_sxr'\n</pre> BEAMPATH = 'cu_sxr' In\u00a0[4]: Copied! <pre>DM = get_datamaps(BEAMPATH)\n\nDM.keys()\n</pre> DM = get_datamaps(BEAMPATH)  DM.keys() Out[4]: <pre>dict_keys(['bpms', 'correctors', 'subboosters', 'linac', 'K21_1', 'K21_2', 'K21_3', 'K21_4', 'K21_5', 'K21_6', 'K21_7', 'K21_8', 'K22_1', 'K22_2', 'K22_3', 'K22_4', 'K22_5', 'K22_6', 'K22_7', 'K22_8', 'K23_1', 'K23_2', 'K23_3', 'K23_4', 'K23_5', 'K23_6', 'K23_7', 'K23_8', 'K24_1', 'K24_2', 'K24_3', 'K24_4', 'K24_5', 'K24_6', 'K25_1', 'K25_2', 'K25_3', 'K25_4', 'K25_5', 'K25_6', 'K25_7', 'K25_8', 'K26_1', 'K26_2', 'K26_3', 'K26_4', 'K26_5', 'K26_6', 'K26_7', 'K26_8', 'K27_1', 'K27_2', 'K27_3', 'K27_4', 'K27_5', 'K27_6', 'K27_7', 'K27_8', 'K28_1', 'K28_2', 'K28_3', 'K28_4', 'K28_5', 'K28_6', 'K28_7', 'K28_8', 'K29_1', 'K29_2', 'K29_3', 'K29_4', 'K29_5', 'K29_6', 'K29_7', 'K29_8', 'K30_1', 'K30_2', 'K30_3', 'K30_4', 'K30_5', 'K30_6', 'K30_7', 'K30_8', 'quad', 'beginning_WS02', 'tao_energy_measurements'])</pre> In\u00a0[5]: Copied! <pre># datamaps to exclude\nDENYLIST = ['beginning_WS02', 'quad', 'correctors', 'bpms']\n\n# PVs needed\nALLPVS =  []\nfor name, dm in DM.items():\n    if name in DENYLIST:\n        continue\n    ALLPVS.extend(dm.pvlist)\nALLPVS = list(set(ALLPVS))\n\n\nlen(ALLPVS)\n</pre>  # datamaps to exclude DENYLIST = ['beginning_WS02', 'quad', 'correctors', 'bpms']  # PVs needed ALLPVS =  [] for name, dm in DM.items():     if name in DENYLIST:         continue     ALLPVS.extend(dm.pvlist) ALLPVS = list(set(ALLPVS))   len(ALLPVS) Out[5]: <pre>553</pre> In\u00a0[6]: Copied! <pre>ISOTIME = '2021-12-01T16:45:00.000000-08:00'\n</pre> ISOTIME = '2021-12-01T16:45:00.000000-08:00' In\u00a0[7]: Copied! <pre># Optional: \n\n# Open an SSH tunnel in a terminal like:\n# ssh -D 8080 &lt;some user&gt;@&lt;some SLAC machine&gt;\n# And then set:\nos.environ['http_proxy']='socks5h://localhost:8080'\nos.environ['HTTPS_PROXY']='socks5h://localhost:8080'\nos.environ['ALL_PROXY']='socks5h://localhost:8080'\n</pre> # Optional:   # Open an SSH tunnel in a terminal like: # ssh -D 8080 @ # And then set: os.environ['http_proxy']='socks5h://localhost:8080' os.environ['HTTPS_PROXY']='socks5h://localhost:8080' os.environ['ALL_PROXY']='socks5h://localhost:8080' In\u00a0[8]: Copied! <pre>PVDATA = lcls_archiver_restore(ALLPVS, ISOTIME)\nlen(PVDATA)\n</pre> PVDATA = lcls_archiver_restore(ALLPVS, ISOTIME) len(PVDATA) <pre>Requesting: http://lcls-archapp.slac.stanford.edu/retrieval/data/getDataAtTime?at=2021-12-01T16:45:00.000000-08:00&amp;includeProxies=true\n</pre> Out[8]: <pre>553</pre> In\u00a0[21]: Copied! <pre>CMDS = []\nfor name, dm in DM.items():\n    CMDS.extend(dm.as_tao(PVDATA))\n\nCMDS[0:5]\n</pre> CMDS = [] for name, dm in DM.items():     CMDS.extend(dm.as_tao(PVDATA))  CMDS[0:5] Out[21]: <pre>['! Bad value for orbit.x[1][]: None',\n '! Bad value for orbit.x[2][]: None',\n '! Bad value for orbit.x[3][]: None',\n '! Bad value for orbit.x[4][]: None',\n '! Bad value for orbit.x[5][]: None']</pre> In\u00a0[22]: Copied! <pre># Write to file for running with vanilla Tao\nwith open('cmds.tao', 'w') as f:\n    f.write('set global lattice_calc_on = F\\n')\n    f.write('set global plot_on = F\\n')    \n    for cmd in CMDS:\n        f.write(cmd+'\\n')\n    f.write('set global lattice_calc_on = T\\n')        \n    f.write('set global plot_on = T\\n')            \n</pre> # Write to file for running with vanilla Tao with open('cmds.tao', 'w') as f:     f.write('set global lattice_calc_on = F\\n')     f.write('set global plot_on = F\\n')         for cmd in CMDS:         f.write(cmd+'\\n')     f.write('set global lattice_calc_on = T\\n')             f.write('set global plot_on = T\\n')             In\u00a0[23]: Copied! <pre>from lcls_live.datamaps.klystron import klystron_pvinfo\nd = klystron_pvinfo(24, 2, beamcode=2)\nd\n</pre> from lcls_live.datamaps.klystron import klystron_pvinfo d = klystron_pvinfo(24, 2, beamcode=2) d Out[23]: <pre>{'name': 'K24_2',\n 'sector': 24,\n 'station': 2,\n 'description': 'Klystron in sector 24, station 2, beamcode 2 for special feedback',\n 'enld_pvname': 'KLYS:LI24:21:ENLD',\n 'phase_pvname': 'ACCL:LI24:200:KLY_PDES:SETDATA_2',\n 'accelerate_pvname': 'KLYS:LI24:21:BEAMCODE2_STAT',\n 'swrd_pvname': 'KLYS:LI24:21:SWRD',\n 'stat_pvname': 'KLYS:LI24:21:STAT',\n 'hdsc_pvname': 'KLYS:LI24:21:HDSC',\n 'dsta_pvname': 'KLYS:LI24:21:DSTA'}</pre> In\u00a0[24]: Copied! <pre>d2 = {}\nfor k in d:\n    if k.endswith('_pvname'):\n        d2[k] = PVDATA[d[k]]\nd2        \n</pre> d2 = {} for k in d:     if k.endswith('_pvname'):         d2[k] = PVDATA[d[k]] d2         Out[24]: <pre>{'enld_pvname': 178.02,\n 'phase_pvname': -85.54768846080982,\n 'accelerate_pvname': 1.0,\n 'swrd_pvname': 128,\n 'stat_pvname': 33,\n 'hdsc_pvname': 1.0,\n 'dsta_pvname': [1610612737.0, 528640.0]}</pre> In\u00a0[27]: Copied! <pre>init = f'-init $LCLS_LATTICE/bmad/models/{BEAMPATH}/tao.init'\ninit\n</pre> init = f'-init $LCLS_LATTICE/bmad/models/{BEAMPATH}/tao.init' init Out[27]: <pre>'-init $LCLS_LATTICE/bmad/models/cu_sxr/tao.init'</pre> In\u00a0[28]: Copied! <pre>tao = Tao(init)\n</pre> tao = Tao(init) In\u00a0[29]: Copied! <pre>%%tao\nplace floor energy\n</pre> %%tao place floor energy <pre>-------------------------\nTao&gt; place floor energy\n-------------------------\nTao&gt; \n</pre> In\u00a0[30]: Copied! <pre># apply commands all at once\ntao.cmds(CMDS);\n</pre> # apply commands all at once tao.cmds(CMDS); In\u00a0[31]: Copied! <pre>s = tao.lat_list('*', 'ele.s')\ne_tot = tao.lat_list('*', 'ele.e_tot')\n\nfig, ax = plt.subplots(figsize=(12,4))\nax.plot(s, e_tot/1e9)\nax.set_xlabel('s (m)')\nax.set_ylabel('Energy (GeV)')\nax.set_title(f'Bmad LCLS-Live {BEAMPATH} at {ISOTIME}')\nax.set_ylim(0, 4.5)\n</pre> s = tao.lat_list('*', 'ele.s') e_tot = tao.lat_list('*', 'ele.e_tot')  fig, ax = plt.subplots(figsize=(12,4)) ax.plot(s, e_tot/1e9) ax.set_xlabel('s (m)') ax.set_ylabel('Energy (GeV)') ax.set_title(f'Bmad LCLS-Live {BEAMPATH} at {ISOTIME}') ax.set_ylim(0, 4.5) Out[31]: <pre>(0.0, 4.5)</pre> In\u00a0[32]: Copied! <pre>%%tao\nsho ele endbc2\n</pre> %%tao sho ele endbc2 <pre>-------------------------\nTao&gt; sho ele endbc2\nElement # 755\nElement Name: ENDBC2\nKey: Marker\nS_start, S:    423.734561,    423.734561\nRef_time:  1.413449E-06\n\nAttribute values [Only non-zero values shown]:\n    1  L                           =  0.0000000E+00 m\n    5  CRUNCH                      =  0.0000000E+00 rad\n    6  NOISE                       =  0.0000000E+00\n    7  OSC_AMPLITUDE               =  0.0000000E+00 m\n   21  CRUNCH_CALIB                =  0.0000000E+00 rad\n   24  TILT_CALIB                  =  0.0000000E+00 rad\n   25  DE_ETA_MEAS                 =  0.0000000E+00\n   26  N_SAMPLE                    =  0.0000000E+00\n   50  DELTA_REF_TIME              =  0.0000000E+00 sec\n   53  P0C                         =  4.4135203E+09 eV           BETA                        =  9.9999999E-01\n   54  E_TOT                       =  4.4135203E+09 eV           GAMMA                       =  8.6370438E+03\n\n       TRACKING_METHOD              =  Bmad_Standard             APERTURE_AT                =  Exit_End\n       MAT6_CALC_METHOD             =  Bmad_Standard             APERTURE_TYPE              =  Rectangular\n       SPIN_TRACKING_METHOD         =  Tracking                  OFFSET_MOVES_APERTURE      =  F\n       PTC_INTEGRATION_TYPE         =  Matrix_Kick               LONGITUDINAL ORIENTATION   =       1\n\nSlave_status: Free\n\nLord_status:  Not_a_Lord\n\nTwiss at end of element:\n                          A              B            Cbar                        C_mat\n  Beta (m)        10.63295439    68.63848710  |   0.00000000   0.00000000      0.00000000   0.00000000\n  Alpha           -0.92687996     2.13846597  |   0.00000000   0.00000000      0.00000000   0.00000000\n  Gamma (1/m)      0.17484383     0.08119405  |   Gamma_c =   1.00000000       Mode_Flip = F\n  Phi (rad)       36.30100832    33.06058940            X              Y              Z\n  Eta (m)         -0.00000000    -0.00000000    -0.00000000    -0.00000000     0.00547512\n  Etap            -0.00000000     0.00000000    -0.00000000     0.00000000    -0.00000000\n\nOrbit:  Electron   State: Alive\n         Position[mm] Momentum[mrad]        Spin   |\n  X:      -0.00000000    -0.00000000               | t_particle [sec]:        1.41344853E-06  E_tot: 4.41352E+09\n  Y:       0.00000000     0.00000000               | t_part-t_ref [sec]:      0.00000000E+00  PC:    4.41352E+09\n  Z:      -0.00000000     0.00000000               | (t_ref-t_part)*Vel [m]:  0.00000000E+00  Beta:  0.999999993\n-------------------------\nTao&gt; \n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/SXR_energy_profile/#sxr-energy-profile","title":"SXR Energy Profile\u00b6","text":""},{"location":"examples/SXR_energy_profile/#datamaps-and-all-pvs-needed","title":"Datamaps, and all PVs needed\u00b6","text":""},{"location":"examples/SXR_energy_profile/#archiver-restore","title":"Archiver restore\u00b6","text":""},{"location":"examples/SXR_energy_profile/#form-commands-using-pvdata-and-datamaps","title":"Form commands using PVDATA and datamaps\u00b6","text":""},{"location":"examples/SXR_energy_profile/#examine-klystrons","title":"Examine klystrons\u00b6","text":""},{"location":"examples/SXR_energy_profile/#start-tao","title":"Start Tao\u00b6","text":""},{"location":"examples/archiver_example/","title":"LCLS Archiver restore","text":"In\u00a0[1]: Copied! <pre>%pylab --no-import-all inline\n%config InlineBackend.figure_format = 'retina'\n</pre> %pylab --no-import-all inline %config InlineBackend.figure_format = 'retina' <pre>%pylab is deprecated, use %matplotlib inline and import the required libraries.\nPopulating the interactive namespace from numpy and matplotlib\n</pre> In\u00a0[2]: Copied! <pre>from lcls_live.archiver import lcls_archiver_restore\nfrom lcls_live import data_dir\nimport json\nimport os\n\n# This is the main function\n?lcls_archiver_restore\n</pre> from lcls_live.archiver import lcls_archiver_restore from lcls_live import data_dir import json import os  # This is the main function ?lcls_archiver_restore <pre>Signature:\nlcls_archiver_restore(\n    pvlist,\n    isotime='2018-08-11T10:40:00.000-07:00',\n    verbose=True,\n)\nDocstring:\nReturns a dict of {'pvname':val} given a list of pvnames, at a time in ISO 8601 format, using the EPICS Archiver Appliance:\n\nhttps://slacmshankar.github.io/epicsarchiver_docs/userguide.html\nFile:      ~/Code/GitHub/lcls-live/lcls_live/archiver.py\nType:      function\n</pre> In\u00a0[3]: Copied! <pre># Optional: \n\n# Open an SSH tunnel in a terminal like:\n# ssh -D 8080 &lt;some user&gt;@&lt;some SLAC machine&gt;\n# And then set:\nos.environ['http_proxy']='socks5h://localhost:8080'\nos.environ['HTTPS_PROXY']='socks5h://localhost:8080'\nos.environ['ALL_PROXY']='socks5h://localhost:8080'\n</pre> # Optional:   # Open an SSH tunnel in a terminal like: # ssh -D 8080 @ # And then set: os.environ['http_proxy']='socks5h://localhost:8080' os.environ['HTTPS_PROXY']='socks5h://localhost:8080' os.environ['ALL_PROXY']='socks5h://localhost:8080' In\u00a0[4]: Copied! <pre>pvlist = [\n          'IRIS:LR20:130:MOTR_ANGLE', \n          'SOLN:IN20:121:BDES',\n          'QUAD:IN20:121:BDES',\n          'QUAD:IN20:122:BDES',\n          'ACCL:IN20:300:L0A_ADES',\n          'ACCL:IN20:300:L0A_PDES'\n]\n\nlcls_archiver_restore(pvlist, '2020-07-09T05:01:21.000000-07:00')\n</pre> pvlist = [           'IRIS:LR20:130:MOTR_ANGLE',            'SOLN:IN20:121:BDES',           'QUAD:IN20:121:BDES',           'QUAD:IN20:122:BDES',           'ACCL:IN20:300:L0A_ADES',           'ACCL:IN20:300:L0A_PDES' ]  lcls_archiver_restore(pvlist, '2020-07-09T05:01:21.000000-07:00') <pre>Requesting: http://lcls-archapp.slac.stanford.edu/retrieval/data/getDataAtTime?at=2020-07-09T05:01:21.000000-07:00&amp;includeProxies=true\n</pre> Out[4]: <pre>{'IRIS:LR20:130:MOTR_ANGLE': 220.6020050048828,\n 'SOLN:IN20:121:BDES': 0.4745,\n 'QUAD:IN20:121:BDES': 0.0,\n 'QUAD:IN20:122:BDES': 0.0,\n 'ACCL:IN20:300:L0A_ADES': 58.5,\n 'ACCL:IN20:300:L0A_PDES': 0.0}</pre> In\u00a0[5]: Copied! <pre># Get list of PVs\nfname = os.path.join(data_dir, 'classic/full_pvlist.json')\npvlist = json.load(open(fname))\npvlist[0:3]\n</pre> # Get list of PVs fname = os.path.join(data_dir, 'classic/full_pvlist.json') pvlist = json.load(open(fname)) pvlist[0:3] Out[5]: <pre>['ACCL:IN20:350:FUDGE', 'ACCL:LI21:180:L1X_S_AV', 'ACCL:LI21:180:L1X_S_PV']</pre> In\u00a0[6]: Copied! <pre># Simple filename naming\ndef snapshot_filename(isotime):\n    return  'epics_snapshot_'+isotime+'.json'\n</pre> # Simple filename naming def snapshot_filename(isotime):     return  'epics_snapshot_'+isotime+'.json' In\u00a0[7]: Copied! <pre>times = ['2022-03-06T15:21:15.000000-08:00']\n\nlcls_archiver_restore(pvlist[0:10], times[0])\n</pre> times = ['2022-03-06T15:21:15.000000-08:00']  lcls_archiver_restore(pvlist[0:10], times[0]) <pre>Requesting: http://lcls-archapp.slac.stanford.edu/retrieval/data/getDataAtTime?at=2022-03-06T15:21:15.000000-08:00&amp;includeProxies=true\n</pre> Out[7]: <pre>{'ACCL:IN20:350:FUDGE': 1.0085738911621906,\n 'ACCL:LI21:180:L1X_S_AV': 21.00412087581118,\n 'ACCL:LI21:180:L1X_S_PV': -159.84138473850933,\n 'ACCL:LI21:1:FUDGE': 1.0100564939191123,\n 'ACCL:LI21:1:L1S_S_PV': -19.680153655018337,\n 'ACCL:LI22:1:FUDGE': 0.9296999422680153,\n 'ACCL:LI24:100:KLY_PDES': 15.11477461877093,\n 'ACCL:LI24:200:KLY_PDES': -28.841842462210366,\n 'ACCL:LI24:300:KLY_PDES': -72.63314256041122,\n 'ACCL:LI25:1:FUDGE': 0.9872969769907864}</pre> In\u00a0[8]: Copied! <pre>%%time\n# Make multiple files\nroot = './data/'\nfor t in times:\n    newdata = lcls_archiver_restore(pvlist, t)\n    fname = os.path.join(root, snapshot_filename(t))\n    with open(fname, 'w') as f:\n        f.write(json.dumps(newdata))\n    print('Written:', fname)\n</pre> %%time # Make multiple files root = './data/' for t in times:     newdata = lcls_archiver_restore(pvlist, t)     fname = os.path.join(root, snapshot_filename(t))     with open(fname, 'w') as f:         f.write(json.dumps(newdata))     print('Written:', fname) <pre>Requesting: http://lcls-archapp.slac.stanford.edu/retrieval/data/getDataAtTime?at=2022-03-06T15:21:15.000000-08:00&amp;includeProxies=true\nWarning: Missing PV: BTRM:LTU1:280:BDES\nWarning: Missing PV: SHTR:LR20:200:UV_STS\nWarning: Missing PV: XCOR:LTU1:288:BDES\nWarning: Missing PV: XCOR:LTU1:448:BDES\nWritten: ./data/epics_snapshot_2022-03-06T15:21:15.000000-08:00.json\nCPU times: user 20.8 ms, sys: 5.85 ms, total: 26.7 ms\nWall time: 2min\n</pre> In\u00a0[9]: Copied! <pre>from lcls_live.archiver import lcls_archiver_history, lcls_archiver_history_dataframe\n\nt_start = '2020-07-09T05:01:15.000000-07:00'\nt_end =   '2020-07-09T05:03:00.000000-07:00'\n\nsecs, vals = lcls_archiver_history('SOLN:IN20:121:BDES', start=t_start, end=t_end)\n\nsecs[0:5], vals[0:5]\n</pre> from lcls_live.archiver import lcls_archiver_history, lcls_archiver_history_dataframe  t_start = '2020-07-09T05:01:15.000000-07:00' t_end =   '2020-07-09T05:03:00.000000-07:00'  secs, vals = lcls_archiver_history('SOLN:IN20:121:BDES', start=t_start, end=t_end)  secs[0:5], vals[0:5] <pre>http://lcls-archapp.slac.stanford.edu/retrieval/data/getData.json?pv=SOLN:IN20:121:BDES&amp;from=2020-07-09T05:01:15.000000-07:00&amp;to=2020-07-09T05:03:00.000000-07:00\n</pre> Out[9]: <pre>([1594296071, 1594296075, 1594296079, 1594296084, 1594296088],\n [0.47, 0.47224999999999995, 0.4745, 0.47675, 0.479])</pre> <p>More convenient, is to format this as a pandas dataframe.</p> In\u00a0[10]: Copied! <pre>?lcls_archiver_history_dataframe\n</pre> ?lcls_archiver_history_dataframe <pre>Signature: lcls_archiver_history_dataframe(pvname, **kwargs)\nDocstring: Same as lcls_archiver_history, but returns a dataframe with the index as the time. \nFile:      ~/Code/GitHub/lcls-live/lcls_live/archiver.py\nType:      function\n</pre> In\u00a0[11]: Copied! <pre>df1 = lcls_archiver_history_dataframe('YAGS:IN20:241:YRMS', start=t_start, end=t_end)\ndf1[0:5]\n</pre> df1 = lcls_archiver_history_dataframe('YAGS:IN20:241:YRMS', start=t_start, end=t_end) df1[0:5] <pre>http://lcls-archapp.slac.stanford.edu/retrieval/data/getData.json?pv=YAGS:IN20:241:YRMS&amp;from=2020-07-09T05:01:15.000000-07:00&amp;to=2020-07-09T05:03:00.000000-07:00\n</pre> Out[11]: YAGS:IN20:241:YRMS time 2020-07-09 11:59:48 433.009985 2020-07-09 12:01:15 292.644774 2020-07-09 12:01:19 262.210378 2020-07-09 12:01:23 226.717519 2020-07-09 12:01:28 230.642901 In\u00a0[12]: Copied! <pre># Pandas has convenient plotting\ndf1.plot()\n</pre> # Pandas has convenient plotting df1.plot() Out[12]: <pre>&lt;AxesSubplot:xlabel='time'&gt;</pre> In\u00a0[13]: Copied! <pre>import pandas as pd\n</pre> import pandas as pd In\u00a0[14]: Copied! <pre># Try another PV. This one was smoothy scanned\ndf2 = lcls_archiver_history_dataframe('SOLN:IN20:121:BDES', start=t_start, end=t_end)\ndf2\n</pre> # Try another PV. This one was smoothy scanned df2 = lcls_archiver_history_dataframe('SOLN:IN20:121:BDES', start=t_start, end=t_end) df2 <pre>http://lcls-archapp.slac.stanford.edu/retrieval/data/getData.json?pv=SOLN:IN20:121:BDES&amp;from=2020-07-09T05:01:15.000000-07:00&amp;to=2020-07-09T05:03:00.000000-07:00\n</pre> Out[14]: SOLN:IN20:121:BDES time 2020-07-09 12:01:11 0.470000 2020-07-09 12:01:15 0.472250 2020-07-09 12:01:19 0.474500 2020-07-09 12:01:24 0.476750 2020-07-09 12:01:28 0.479000 2020-07-09 12:01:32 0.481250 2020-07-09 12:01:37 0.483500 2020-07-09 12:01:41 0.485750 2020-07-09 12:01:46 0.488000 2020-07-09 12:01:50 0.465016 In\u00a0[15]: Copied! <pre>df2.plot()\n</pre> df2.plot() Out[15]: <pre>&lt;AxesSubplot:xlabel='time'&gt;</pre> In\u00a0[16]: Copied! <pre># Notice that some data are taken at the same time, others are not\ndf4 = pd.concat([df1, df2], axis=1)\ndf4\n</pre> # Notice that some data are taken at the same time, others are not df4 = pd.concat([df1, df2], axis=1) df4 Out[16]: YAGS:IN20:241:YRMS SOLN:IN20:121:BDES time 2020-07-09 11:59:48 433.009985 NaN 2020-07-09 12:01:11 NaN 0.470000 2020-07-09 12:01:15 292.644774 0.472250 2020-07-09 12:01:19 262.210378 0.474500 2020-07-09 12:01:23 226.717519 NaN 2020-07-09 12:01:24 NaN 0.476750 2020-07-09 12:01:28 230.642901 0.479000 2020-07-09 12:01:32 243.905289 0.481250 2020-07-09 12:01:37 NaN 0.483500 2020-07-09 12:01:41 342.439957 0.485750 2020-07-09 12:01:45 427.501542 NaN 2020-07-09 12:01:46 NaN 0.488000 2020-07-09 12:01:49 486.459644 NaN 2020-07-09 12:01:50 NaN 0.465016 In\u00a0[17]: Copied! <pre># This will fill in the missing  values, and drop trailing NaNs\ndf5 = df4.interpolate().dropna()\ndf5\n</pre> # This will fill in the missing  values, and drop trailing NaNs df5 = df4.interpolate().dropna() df5 Out[17]: YAGS:IN20:241:YRMS SOLN:IN20:121:BDES time 2020-07-09 12:01:11 362.827380 0.470000 2020-07-09 12:01:15 292.644774 0.472250 2020-07-09 12:01:19 262.210378 0.474500 2020-07-09 12:01:23 226.717519 0.475625 2020-07-09 12:01:24 228.680210 0.476750 2020-07-09 12:01:28 230.642901 0.479000 2020-07-09 12:01:32 243.905289 0.481250 2020-07-09 12:01:37 293.172623 0.483500 2020-07-09 12:01:41 342.439957 0.485750 2020-07-09 12:01:45 427.501542 0.486875 2020-07-09 12:01:46 456.980593 0.488000 2020-07-09 12:01:49 486.459644 0.476508 2020-07-09 12:01:50 486.459644 0.465016 In\u00a0[18]: Copied! <pre># make a plot\nDF = df5[:-2] # The last two points are outside the main scan. \nk1 = 'SOLN:IN20:121:BDES'\nk2 = 'YAGS:IN20:241:YRMS'\nplt.xlabel(k1)\nplt.ylabel(k2)\nplt.title(t_start+'\\n to '+t_end)\nplt.scatter(DF[k1], DF[k2], marker='.', color='black')\n</pre> # make a plot DF = df5[:-2] # The last two points are outside the main scan.  k1 = 'SOLN:IN20:121:BDES' k2 = 'YAGS:IN20:241:YRMS' plt.xlabel(k1) plt.ylabel(k2) plt.title(t_start+'\\n to '+t_end) plt.scatter(DF[k1], DF[k2], marker='.', color='black') Out[18]: <pre>&lt;matplotlib.collections.PathCollection at 0x14e3e4340&gt;</pre> In\u00a0[19]: Copied! <pre>pvlist = ['SOLN:IN20:121:BDES', 'YAGS:IN20:241:XRMS', 'YAGS:IN20:241:YRMS']\n\ndflist = []\nfor pvname in pvlist:\n    dflist.append(lcls_archiver_history_dataframe(pvname, start=t_start, end=t_end))\ndf6 = pd.concat(dflist, axis=1).interpolate().dropna()\n</pre> pvlist = ['SOLN:IN20:121:BDES', 'YAGS:IN20:241:XRMS', 'YAGS:IN20:241:YRMS']  dflist = [] for pvname in pvlist:     dflist.append(lcls_archiver_history_dataframe(pvname, start=t_start, end=t_end)) df6 = pd.concat(dflist, axis=1).interpolate().dropna() <pre>http://lcls-archapp.slac.stanford.edu/retrieval/data/getData.json?pv=SOLN:IN20:121:BDES&amp;from=2020-07-09T05:01:15.000000-07:00&amp;to=2020-07-09T05:03:00.000000-07:00\nhttp://lcls-archapp.slac.stanford.edu/retrieval/data/getData.json?pv=YAGS:IN20:241:XRMS&amp;from=2020-07-09T05:01:15.000000-07:00&amp;to=2020-07-09T05:03:00.000000-07:00\nhttp://lcls-archapp.slac.stanford.edu/retrieval/data/getData.json?pv=YAGS:IN20:241:YRMS&amp;from=2020-07-09T05:01:15.000000-07:00&amp;to=2020-07-09T05:03:00.000000-07:00\n</pre> In\u00a0[20]: Copied! <pre>df6 \n</pre> df6  Out[20]: SOLN:IN20:121:BDES YAGS:IN20:241:XRMS YAGS:IN20:241:YRMS time 2020-07-09 12:01:11 0.470000 393.366373 362.827380 2020-07-09 12:01:15 0.472250 325.602016 292.644774 2020-07-09 12:01:19 0.474500 297.144936 262.210378 2020-07-09 12:01:23 0.475625 269.941236 226.717519 2020-07-09 12:01:24 0.476750 262.813117 228.680210 2020-07-09 12:01:28 0.479000 255.684997 230.642901 2020-07-09 12:01:32 0.481250 246.747285 243.905289 2020-07-09 12:01:36 0.482375 266.423525 276.750178 2020-07-09 12:01:37 0.483500 279.129956 309.595068 2020-07-09 12:01:41 0.485750 291.836386 342.439957 2020-07-09 12:01:45 0.486875 335.522076 427.501542 2020-07-09 12:01:46 0.488000 367.396032 456.980593 2020-07-09 12:01:49 0.476508 399.269987 486.459644 2020-07-09 12:01:50 0.465016 399.269987 486.459644 In\u00a0[21]: Copied! <pre>DF = df6[:-2] # Drop the last two that are unrelated to the scan\nk1 = 'SOLN:IN20:121:BDES'\nk2 = 'YAGS:IN20:241:XRMS'\nk3 = 'YAGS:IN20:241:YRMS'\nplt.xlabel(k1+' (kG-m)')\nplt.ylabel('Measurement (um)')\nplt.title(t_start+'\\n to '+t_end)\n\nX1 = DF[k1]\nX2 = DF[k2]\nX3 = DF[k3]\n\nplt.scatter(X1, X2, marker='x', color='blue', label=k2)\nplt.scatter(X1, X3, marker='x', color='green', label=k3)\nplt.legend()\n</pre> DF = df6[:-2] # Drop the last two that are unrelated to the scan k1 = 'SOLN:IN20:121:BDES' k2 = 'YAGS:IN20:241:XRMS' k3 = 'YAGS:IN20:241:YRMS' plt.xlabel(k1+' (kG-m)') plt.ylabel('Measurement (um)') plt.title(t_start+'\\n to '+t_end)  X1 = DF[k1] X2 = DF[k2] X3 = DF[k3]  plt.scatter(X1, X2, marker='x', color='blue', label=k2) plt.scatter(X1, X3, marker='x', color='green', label=k3) plt.legend() Out[21]: <pre>&lt;matplotlib.legend.Legend at 0x14e453d30&gt;</pre>"},{"location":"examples/archiver_example/#lcls-archiver-restore","title":"LCLS Archiver restore\u00b6","text":"<p>These examples show how single snapshots, and time series can be retreived from the archiver appliance.</p> <p>Note that the times must always be in ISO 8601 format, UTC time (not local time).</p>"},{"location":"examples/archiver_example/#optional-off-site-setup","title":"Optional: off-site setup\u00b6","text":""},{"location":"examples/archiver_example/#restore-known-pvs","title":"Restore known PVs\u00b6","text":""},{"location":"examples/archiver_example/#get-snapshot-from-a-large-list","title":"Get snapshot from a large list\u00b6","text":"<p>Same as above, but for processing large amounts of data</p>"},{"location":"examples/archiver_example/#get-history-of-a-single-pv","title":"Get history of a single PV\u00b6","text":"<p>This package also has a couple functions for getting the time history data of a pv.</p> <p>The first, <code>lcls_archiver_history</code>, returns the raw data</p>"},{"location":"examples/archiver_example/#aligning-the-history-of-two-pvs","title":"Aligning the history of two PVs\u00b6","text":"<p>The returned data will not necessarily be time-aligned. Here we will use Pandas' interpolate capabilities to fill in missing data.</p>"},{"location":"examples/archiver_example/#this-easily-extends-to-a-list","title":"This easily extends to a list\u00b6","text":""},{"location":"examples/archiver_restore_serve/","title":"Restore and serve EPICS PVs from the Archiver","text":"In\u00a0[1]: Copied! <pre>from lcls_live.archiver import lcls_archiver_restore\nimport json\nimport os\n</pre> from lcls_live.archiver import lcls_archiver_restore import json import os In\u00a0[2]: Copied! <pre># A list of some interesting PVs\nPVDB_JSON = 'data/live_model_PVDB.json'\n\n# Pick a proper time\nISOTIME = '2021-04-13T15:14:00.000000-07:00'\n</pre> # A list of some interesting PVs PVDB_JSON = 'data/live_model_PVDB.json'  # Pick a proper time ISOTIME = '2021-04-13T15:14:00.000000-07:00' In\u00a0[3]: Copied! <pre># Get starting PVDB\nprefix = ''\npvdb = json.load(open(PVDB_JSON))\n</pre> # Get starting PVDB prefix = '' pvdb = json.load(open(PVDB_JSON)) In\u00a0[4]: Copied! <pre># Add some extras for fun\nextra_pvs = ['BMLN:LI21:235:MOTR',\n 'BMLN:LI24:805:MOTR',\n 'ACCL:LI22:1:PDES',\n 'ACCL:LI25:1:PDES']\nfor pv in extra_pvs:\n    pvdb[pv] = {}\n</pre> # Add some extras for fun extra_pvs = ['BMLN:LI21:235:MOTR',  'BMLN:LI24:805:MOTR',  'ACCL:LI22:1:PDES',  'ACCL:LI25:1:PDES'] for pv in extra_pvs:     pvdb[pv] = {} In\u00a0[5]: Copied! <pre># Optional: update from live EPICS\n# import epics\n# \n# pvnames = list(pvdb)\n# vals = epics.caget_many(list(pvdb))\n# pvdb = {}\n# for name, val in zip(pvnames, vals):\n#     pvdb[name] = {'value':val}\n# \n</pre> # Optional: update from live EPICS # import epics #  # pvnames = list(pvdb) # vals = epics.caget_many(list(pvdb)) # pvdb = {} # for name, val in zip(pvnames, vals): #     pvdb[name] = {'value':val} #  In\u00a0[6]: Copied! <pre># Optional: \n\n# Open an SSH tunnel in a terminal like:\n# ssh -D 8080 &lt;SLAC username&gt;@&lt;SLAC machine&gt;\n# And then set:\nos.environ['http_proxy']='socks5h://localhost:8080'\nos.environ['HTTPS_PROXY']='socks5h://localhost:8080'\nos.environ['ALL_PROXY']='socks5h://localhost:8080'\n</pre> # Optional:   # Open an SSH tunnel in a terminal like: # ssh -D 8080 @ # And then set: os.environ['http_proxy']='socks5h://localhost:8080' os.environ['HTTPS_PROXY']='socks5h://localhost:8080' os.environ['ALL_PROXY']='socks5h://localhost:8080' In\u00a0[7]: Copied! <pre># Update\nnew_pvdata = lcls_archiver_restore(list(pvdb), ISOTIME)\nfor k, v in new_pvdata.items():\n#    print(pvdb[k]['value'], v)\n    if v is None:\n        print(k, 'Bad value:', v)\n    else:\n        pvdb[k]['value'] = v\n</pre> # Update new_pvdata = lcls_archiver_restore(list(pvdb), ISOTIME) for k, v in new_pvdata.items(): #    print(pvdb[k]['value'], v)     if v is None:         print(k, 'Bad value:', v)     else:         pvdb[k]['value'] = v <pre>Requesting: http://lcls-archapp.slac.stanford.edu/retrieval/data/getDataAtTime?at=2021-04-13T15:14:00.000000-07:00&amp;includeProxies=true\nWarning: Missing PV: SBST:LI20:1:PHAS\nWarning: Missing PV: GUN:IN20:1:GN1_AAVG\nWarning: Missing PV: GUN:IN20:1:GN1_PAVG\nWarning: Missing PV: ACCL:IN20:300:L0A_AAVG\nWarning: Missing PV: ACCL:IN20:300:L0A_PAVG\nWarning: Missing PV: ACCL:IN20:400:L0B_AAVG\nWarning: Missing PV: ACCL:IN20:400:L0B_PAVG\nWarning: Missing PV: ACCL:LI21:1:L1S_AAVG\nWarning: Missing PV: ACCL:LI21:1:L1S_PAVG\nWarning: Missing PV: ACCL:LI21:180:L1X_AAVG\nWarning: Missing PV: ACCL:LI21:180:L1X_PAVG\nKLYS:LI24:61:PHAS Bad value: None\nKLYS:LI25:11:PHAS Bad value: None\nKLYS:LI25:21:PHAS Bad value: None\nKLYS:LI25:31:PHAS Bad value: None\nKLYS:LI25:41:PHAS Bad value: None\nKLYS:LI25:51:PHAS Bad value: None\nKLYS:LI25:61:PHAS Bad value: None\nKLYS:LI25:71:PHAS Bad value: None\nKLYS:LI25:81:PHAS Bad value: None\nKLYS:LI26:11:PHAS Bad value: None\nKLYS:LI26:21:PHAS Bad value: None\nKLYS:LI26:41:PHAS Bad value: None\nKLYS:LI26:51:PHAS Bad value: None\nKLYS:LI26:61:PHAS Bad value: None\nKLYS:LI26:71:PHAS Bad value: None\nKLYS:LI26:81:PHAS Bad value: None\nKLYS:LI27:11:PHAS Bad value: None\nKLYS:LI27:21:PHAS Bad value: None\nKLYS:LI27:41:PHAS Bad value: None\nKLYS:LI27:51:PHAS Bad value: None\nKLYS:LI27:81:PHAS Bad value: None\nKLYS:LI28:11:PHAS Bad value: None\nKLYS:LI28:21:PHAS Bad value: None\nKLYS:LI28:31:PHAS Bad value: None\nKLYS:LI28:41:PHAS Bad value: None\nKLYS:LI28:51:PHAS Bad value: None\nKLYS:LI28:61:PHAS Bad value: None\nKLYS:LI28:71:PHAS Bad value: None\nKLYS:LI28:81:PHAS Bad value: None\nKLYS:LI29:11:PHAS Bad value: None\nKLYS:LI29:31:PHAS Bad value: None\nKLYS:LI29:41:PHAS Bad value: None\nKLYS:LI29:51:PHAS Bad value: None\nKLYS:LI30:31:PHAS Bad value: None\nKLYS:LI30:41:PHAS Bad value: None\nKLYS:LI30:51:PHAS Bad value: None\nKLYS:LI30:61:PHAS Bad value: None\n</pre> In\u00a0[8]: Copied! <pre># Dump to file for safekeeping\noutfile = f'data/live_model_PVDB-{ISOTIME}.json'\njson.dump(pvdb, open(outfile, 'w'))\n</pre> # Dump to file for safekeeping outfile = f'data/live_model_PVDB-{ISOTIME}.json' json.dump(pvdb, open(outfile, 'w')) In\u00a0[9]: Copied! <pre>from pcaspy import Driver, SimpleServer\n</pre> from pcaspy import Driver, SimpleServer <pre>\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nInput In [9], in &lt;cell line: 1&gt;()\n----&gt; 1 from pcaspy import Driver, SimpleServer\n\nModuleNotFoundError: No module named 'pcaspy'</pre> In\u00a0[10]: Copied! <pre>class myDriver(Driver):\n    def __init__(self):\n        super(myDriver, self).__init__()\n        \n    def getParam(self, reason):\n        #print('myDriver.getParam', reason) \n        return super().getParam(reason)\n</pre> class myDriver(Driver):     def __init__(self):         super(myDriver, self).__init__()              def getParam(self, reason):         #print('myDriver.getParam', reason)          return super().getParam(reason) <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nInput In [10], in &lt;cell line: 1&gt;()\n----&gt; 1 class myDriver(Driver):\n      2     def __init__(self):\n      3         super(myDriver, self).__init__()\n\nNameError: name 'Driver' is not defined</pre> In\u00a0[12]: Copied! <pre>server = SimpleServer()\nserver.createPV(prefix, pvdb)\ndriver = myDriver()\n</pre> server = SimpleServer() server.createPV(prefix, pvdb) driver = myDriver() In\u00a0[\u00a0]: Copied! <pre>while True:\n    # process CA transactions\n    server.process(0.1)\n</pre> while True:     # process CA transactions     server.process(0.1) In\u00a0[14]: Copied! <pre># cleanup\nos.remove(outfile)\n</pre> # cleanup os.remove(outfile)"},{"location":"examples/archiver_restore_serve/#restore-and-serve-epics-pvs-from-the-archiver","title":"Restore and serve EPICS PVs from the Archiver\u00b6","text":"<p>Using a simple JSON file to seed a dict of <code>pvname:{'value':value}</code>, this will acquire values from the archiver, and run a simple EPICS server locally.</p>"},{"location":"examples/archiver_restore_serve/#simpleserver-from-pcaspy","title":"SimpleServer from pcaspy\u00b6","text":"<p>This following is adapted from: https://pcaspy.readthedocs.io/en/latest/tutorial.html</p>"},{"location":"examples/bmad-live-cu-inj/","title":"cu_inj Live","text":"In\u00a0[1]: Copied! <pre># Useful for debugging\n%load_ext autoreload\n%autoreload 2\n\n%config InlineBackend.figure_format = 'retina'\n%matplotlib inline\n</pre> # Useful for debugging %load_ext autoreload %autoreload 2  %config InlineBackend.figure_format = 'retina' %matplotlib inline In\u00a0[37]: Copied! <pre>from lcls_live.datamaps import get_datamaps\nfrom lcls_live.archiver import lcls_archiver_restore\n\nfrom lcls_live.tools import isotime\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport os\n</pre> from lcls_live.datamaps import get_datamaps from lcls_live.archiver import lcls_archiver_restore  from lcls_live.tools import isotime  import matplotlib.pyplot as plt import numpy as np  import os In\u00a0[3]: Copied! <pre>BEAMPATH = 'cu_spec'\n</pre> BEAMPATH = 'cu_spec' In\u00a0[4]: Copied! <pre>DM = get_datamaps(BEAMPATH)\n\n# Hack in 10 Hz\ndf = DM['bpms'].data\nDM['bpms'].data['pvname'] = [name[:-2]+'TH' for name in df['pvname']]\n\nDM.keys()\n</pre> DM = get_datamaps(BEAMPATH)  # Hack in 10 Hz df = DM['bpms'].data DM['bpms'].data['pvname'] = [name[:-2]+'TH' for name in df['pvname']]  DM.keys() Out[4]: <pre>dict_keys(['bpms', 'correctors', 'quad', 'linac'])</pre> In\u00a0[5]: Copied! <pre># datamaps to exclude\nDENYLIST = ['correctors', 'linac'] #, 'quad']\n</pre> # datamaps to exclude DENYLIST = ['correctors', 'linac'] #, 'quad'] In\u00a0[6]: Copied! <pre># PVs needed\nPVLIST =  []\nfor name, dm in DM.items():\n    if name in DENYLIST:\n        continue\n    PVLIST.extend(dm.pvlist)\nPVLIST = list(set(PVLIST))\nlen(PVLIST)\n</pre> # PVs needed PVLIST =  [] for name, dm in DM.items():     if name in DENYLIST:         continue     PVLIST.extend(dm.pvlist) PVLIST = list(set(PVLIST)) len(PVLIST) Out[6]: <pre>46</pre> In\u00a0[8]: Copied! <pre>import epics\nfrom time import sleep, time\n</pre> import epics from time import sleep, time In\u00a0[9]: Copied! <pre>MONITOR = {pvname:epics.PV(pvname) for pvname in PVLIST}\nsleep(5) # Wait for all to connect\n</pre> MONITOR = {pvname:epics.PV(pvname) for pvname in PVLIST} sleep(5) # Wait for all to connect In\u00a0[10]: Copied! <pre>def get_pvdata():   \n    itime = isotime()\n    pvdata =  {k:MONITOR[k].get() for k in MONITOR}\n    return pvdata\nPVDATA = get_pvdata()\n</pre> def get_pvdata():        itime = isotime()     pvdata =  {k:MONITOR[k].get() for k in MONITOR}     return pvdata PVDATA = get_pvdata() In\u00a0[11]: Copied! <pre># Check for bad PVs\nbad = set()\nfor k, v in PVDATA.items():\n    if v is None:\n        bad.add(k.split(':')[2])\n        print(k)\nassert len(bad) == 0\n</pre> # Check for bad PVs bad = set() for k, v in PVDATA.items():     if v is None:         bad.add(k.split(':')[2])         print(k) assert len(bad) == 0 In\u00a0[12]: Copied! <pre>def tao_commands(pvdata):\n    cmds = []\n    for name, dm in DM.items():\n        cmds.extend(dm.as_tao(pvdata))\n    return cmds\n</pre> def tao_commands(pvdata):     cmds = []     for name, dm in DM.items():         cmds.extend(dm.as_tao(pvdata))     return cmds In\u00a0[13]: Copied! <pre>def save_cmds(cmds, filename='cmds.tao'): # Write to file for running with vanilla Tao\n    with open(filename, 'w') as f:\n        f.write('set global lattice_calc_on = F\\n')\n        f.write('set global plot_on = F\\n')    \n        for cmd in CMDS:\n            f.write(cmd+'\\n')\n        f.write('set global lattice_calc_on = T\\n')        \n        f.write('set global plot_on = T\\n')   \n</pre> def save_cmds(cmds, filename='cmds.tao'): # Write to file for running with vanilla Tao     with open(filename, 'w') as f:         f.write('set global lattice_calc_on = F\\n')         f.write('set global plot_on = F\\n')             for cmd in CMDS:             f.write(cmd+'\\n')         f.write('set global lattice_calc_on = T\\n')                 f.write('set global plot_on = T\\n')    In\u00a0[14]: Copied! <pre>def toggle_beam():\n    tao.cmd('set global track_type = beam') \n    tao.cmd('set global track_type = single') \n</pre> def toggle_beam():     tao.cmd('set global track_type = beam')      tao.cmd('set global track_type = single')  In\u00a0[15]: Copied! <pre>tao_commands(PVDATA)[0:5]\n</pre> tao_commands(PVDATA)[0:5] Out[15]: <pre>['set data orbit.x[1]|meas  = 0.001 * 0.18149997293949127',\n 'set data orbit.x[2]|meas  = 0.001 * 0.3294964134693146',\n 'set data orbit.x[3]|meas  = 0.001 * 2.2582709789276123e-05',\n 'set data orbit.x[4]|meas  = 0.001 * -0.008475333452224731',\n 'set data orbit.x[5]|meas  = 0.001 * -0.03837699070572853']</pre> In\u00a0[16]: Copied! <pre>from pytao import Tao\n</pre> from pytao import Tao In\u00a0[18]: Copied! <pre>MODEL_ROOT = f'$LCLS_LATTICE/bmad/models/{BEAMPATH}/'\ninit = f'-init {MODEL_ROOT}/tao.init'\ntao = Tao(init)\ntao.cmd('set ele quad::* field_master = T')\ninit\n</pre> MODEL_ROOT = f'$LCLS_LATTICE/bmad/models/{BEAMPATH}/' init = f'-init {MODEL_ROOT}/tao.init' tao = Tao(init) tao.cmd('set ele quad::* field_master = T') init Out[18]: <pre>'-init $LCLS_LATTICE/bmad/models/cu_spec//tao.init'</pre> In\u00a0[19]: Copied! <pre>%%time\n# Turn on the beam\ntao.cmd('set beam_init n_particle = 10000')\ntoggle_beam()\n</pre> %%time # Turn on the beam tao.cmd('set beam_init n_particle = 10000') toggle_beam() <pre>CPU times: user 1.39 s, sys: 146 ms, total: 1.54 s\nWall time: 536 ms\n</pre> In\u00a0[27]: Copied! <pre>%%tao\nplace floor none\nplace top2 bpm_orbit\nplace middle2 bunch_sigma_xy \n\nsc top2 -2 2\n\nset graph middle2 y%label = \"\\gs\\fn\\dx\\u, \\gs\\fn\\dy\\u (\\gmm)\"\nset curve middle2.g.x y_axis_scale_factor = 1e6\nset curve middle2.g.y y_axis_scale_factor = 1e6\nsc middle2 ! 0 600\n\n\nx-a all s \n</pre> %%tao place floor none place top2 bpm_orbit place middle2 bunch_sigma_xy   sc top2 -2 2  set graph middle2 y%label = \"\\gs\\fn\\dx\\u, \\gs\\fn\\dy\\u (\\gmm)\" set curve middle2.g.x y_axis_scale_factor = 1e6 set curve middle2.g.y y_axis_scale_factor = 1e6 sc middle2 ! 0 600   x-a all s  <pre>-------------------------\nTao&gt; place floor none\n-------------------------\nTao&gt; place top2 bpm_orbit\n-------------------------\nTao&gt; place middle2 bunch_sigma_xy \n-------------------------\nTao&gt; \n-------------------------\nTao&gt; sc top2 -2 2\n-------------------------\nTao&gt; \n-------------------------\nTao&gt; set graph middle2 y%label = \"\\gs\\fn\\dx\\u, \\gs\\fn\\dy\\u (\\gmm)\"\n-------------------------\nTao&gt; set curve middle2.g.x y_axis_scale_factor = 1e6\n-------------------------\nTao&gt; set curve middle2.g.y y_axis_scale_factor = 1e6\n-------------------------\nTao&gt; sc middle2 ! 0 600\n-------------------------\nTao&gt; \n-------------------------\nTao&gt; \n-------------------------\nTao&gt; x-a all s \n-------------------------\nTao&gt; \n</pre> In\u00a0[28]: Copied! <pre>#tao.cmd(f'call {MODEL_ROOT}/scripts/SC.tao')\n</pre> #tao.cmd(f'call {MODEL_ROOT}/scripts/SC.tao') In\u00a0[29]: Copied! <pre>def run1():\n    #sleep(.001)\n    t1 = time()\n    pvdata = get_pvdata()\n    cmds = tao_commands(pvdata)\n    tao.cmd('set global plot_on = F;set global lattice_calc_on = F')\n    tao.cmds(cmds); # Apply\n\n    tao.cmd('set global lattice_calc_on = T')\n    tao.cmd('set global plot_on = T')\n    toggle_beam()\n    \n    dt = time()-t1\n    #print(dt)    \n</pre> def run1():     #sleep(.001)     t1 = time()     pvdata = get_pvdata()     cmds = tao_commands(pvdata)     tao.cmd('set global plot_on = F;set global lattice_calc_on = F')     tao.cmds(cmds); # Apply      tao.cmd('set global lattice_calc_on = T')     tao.cmd('set global plot_on = T')     toggle_beam()          dt = time()-t1     #print(dt)      In\u00a0[30]: Copied! <pre>%%time\nrun1()\n</pre> %%time run1() <pre>CPU times: user 2.57 s, sys: 274 ms, total: 2.85 s\nWall time: 727 ms\n</pre> In\u00a0[\u00a0]: Copied! <pre>while True:\n    run1()\n</pre> while True:     run1() In\u00a0[32]: Copied! <pre>%%time\n#toggle on and off\ntao.cmd('set global track_type = beam', raises=False) \ntao.cmd('set global track_type = single') \n</pre> %%time #toggle on and off tao.cmd('set global track_type = beam', raises=False)  tao.cmd('set global track_type = single')  <pre>CPU times: user 1.33 s, sys: 113 ms, total: 1.44 s\nWall time: 382 ms\n</pre> Out[32]: <pre>[]</pre> In\u00a0[33]: Copied! <pre>%%tao\nplace top2 beambeta\nplace middle2 bunch_sigma_xy\nx-a all s\nsc\n</pre> %%tao place top2 beambeta place middle2 bunch_sigma_xy x-a all s sc <pre>-------------------------\nTao&gt; place top2 beambeta\n-------------------------\nTao&gt; place middle2 bunch_sigma_xy\n-------------------------\nTao&gt; x-a all s\n-------------------------\nTao&gt; sc\n-------------------------\nTao&gt; \n</pre> In\u00a0[34]: Copied! <pre>from pmd_beamphysics import ParticleGroup\n</pre> from pmd_beamphysics import ParticleGroup In\u00a0[35]: Copied! <pre>P = ParticleGroup(data=tao.bunch_data('OTR2'))\n# Select out live particles\nP = P[P.status==1]\nP.drift_to_z()\n</pre> P = ParticleGroup(data=tao.bunch_data('OTR2')) # Select out live particles P = P[P.status==1] P.drift_to_z() In\u00a0[38]: Copied! <pre>P.plot('delta_t', 'energy')\nplt.title('OTR2')\n</pre> P.plot('delta_t', 'energy') plt.title('OTR2') Out[38]: <pre>Text(0.5, 1.0, 'OTR2')</pre> In\u00a0[39]: Copied! <pre>P.plot('x', 'y')\n</pre> P.plot('x', 'y') In\u00a0[40]: Copied! <pre>P.plot('t', 'x')\n</pre> P.plot('t', 'x') In\u00a0[41]: Copied! <pre># Make a function for this\ndef get_beam(ele):\n    P = ParticleGroup(data=tao.bunch_data(ele))\n    # Select out live particles\n    P = P[P.status==1]    \n    \n    return P\n</pre> # Make a function for this def get_beam(ele):     P = ParticleGroup(data=tao.bunch_data(ele))     # Select out live particles     P = P[P.status==1]              return P In\u00a0[42]: Copied! <pre>P1 = get_beam('OTR2')\nP1.plot('delta_t', 'delta_energy')\n</pre> P1 = get_beam('OTR2') P1.plot('delta_t', 'delta_energy') In\u00a0[43]: Copied! <pre>P2 = get_beam('OTR2')\nP2.plot('x', 'y')\n</pre> P2 = get_beam('OTR2') P2.plot('x', 'y') In\u00a0[44]: Copied! <pre>import pandas as pd\n</pre> import pandas as pd In\u00a0[45]: Copied! <pre># Get list of indices\nIX = tao.lat_list('*', 'ele.ix_ele')\n\n# Stop before the dump\nS_STOP = tao.ele_head('OTR2')['s']\n\nstats = []\nfor ele in IX:\n    d = tao.bunch_params(ele)\n    # Skipl ones with no beam\n    if d['charge_live'] == 0:\n        continue\n    \n    if d['s'] &gt; S_STOP:\n        break\n        \n    stats.append(d)\n\ndf = pd.DataFrame(stats)#.set_index('ix_ele')\ndf\n</pre> # Get list of indices IX = tao.lat_list('*', 'ele.ix_ele')  # Stop before the dump S_STOP = tao.ele_head('OTR2')['s']  stats = [] for ele in IX:     d = tao.bunch_params(ele)     # Skipl ones with no beam     if d['charge_live'] == 0:         continue          if d['s'] &gt; S_STOP:         break              stats.append(d)  df = pd.DataFrame(stats)#.set_index('ix_ele') df Out[45]: beta_x alpha_x gamma_x phi_x eta_x etap_x sigma_x sigma_p_x emit_x norm_emit_x ... ix_ele direction species location s charge_live n_particle_tot n_particle_live n_particle_lost_in_ele beam_saved 0 17.172295 -4.832192 1.417986 0.0 -0.001708 -0.000506 0.000245 0.000070 3.502335e-09 4.377142e-07 ... 62 1 Electron Downstream_End 4.614539 2.500000e-11 10000 10000 0 True 1 18.282401 -4.992310 1.417929 0.0 -0.001765 -0.000506 0.000253 0.000070 3.502475e-09 4.377317e-07 ... 63 1 Electron Downstream_End 4.727324 2.500000e-11 10000 10000 0 False 2 19.026422 -5.096805 1.417892 0.0 -0.001803 -0.000506 0.000258 0.000070 3.502567e-09 4.377431e-07 ... 64 1 Electron Downstream_End 4.800934 2.500000e-11 10000 10000 0 False 3 23.573059 -39.263591 65.440366 0.0 -0.002009 -0.003367 0.000287 0.000479 3.504147e-09 4.379407e-07 ... 65 1 Electron Downstream_End 4.908934 2.500000e-11 10000 10000 0 False 4 31.566605 -45.416435 65.374550 0.0 -0.002327 -0.003367 0.000333 0.000479 3.507675e-09 4.383816e-07 ... 66 1 Electron Downstream_End 5.003418 2.500000e-11 10000 10000 0 False ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 82 74.549507 -0.570622 0.017782 0.0 -0.009313 -0.000028 0.000353 0.000005 1.672918e-09 4.413671e-07 ... 144 1 Electron Downstream_End 14.089061 2.500000e-11 10000 10000 0 True 83 74.636433 -0.571975 0.017782 0.0 -0.009315 -0.000028 0.000353 0.000005 1.672918e-09 4.413671e-07 ... 145 1 Electron Downstream_End 14.165045 2.500000e-11 10000 10000 0 False 84 74.636433 -0.571975 0.017782 0.0 -0.009315 -0.000028 0.000353 0.000005 1.672918e-09 4.413671e-07 ... 146 1 Electron Downstream_End 14.165045 2.500000e-11 10000 10000 0 True 85 74.723564 -0.573328 0.017782 0.0 -0.009317 -0.000028 0.000354 0.000005 1.672918e-09 4.413670e-07 ... 147 1 Electron Downstream_End 14.241029 2.500000e-11 10000 10000 0 False 86 74.723564 -0.573328 0.017782 0.0 -0.009317 -0.000028 0.000354 0.000005 1.672918e-09 4.413670e-07 ... 148 1 Electron Downstream_End 14.241029 2.500000e-11 10000 10000 0 True <p>87 rows \u00d7 127 columns</p> In\u00a0[46]: Copied! <pre>fig, ax = plt.subplots(figsize=(12,5))\nplt.plot(df['s'], df['sigma_x']*1e6, label=r'$\\sigma_x$')\nplt.plot(df['s'], df['sigma_y']*1e6, label=r'$\\sigma_y$')\nplt.xlabel('s (m)')\nplt.ylabel('beam sizes (\u00b5m)')\nplt.legend();\n</pre> fig, ax = plt.subplots(figsize=(12,5)) plt.plot(df['s'], df['sigma_x']*1e6, label=r'$\\sigma_x$') plt.plot(df['s'], df['sigma_y']*1e6, label=r'$\\sigma_y$') plt.xlabel('s (m)') plt.ylabel('beam sizes (\u00b5m)') plt.legend(); In\u00a0[47]: Copied! <pre># Get an array of where the beam is saved\ns_saved = np.array(df[df['beam_saved']]['s'])\n</pre> # Get an array of where the beam is saved s_saved = np.array(df[df['beam_saved']]['s']) In\u00a0[48]: Copied! <pre>fig, ax = plt.subplots(figsize=(12,5))\nplt.plot(df['s'], df['norm_emit_x']*1e6, label=r'$\\epsilon_{n,x}$')\nplt.plot(df['s'], df['norm_emit_y']*1e6, label=r'$\\epsilon_{n,y}$')\nplt.xlabel('s (m)')\nplt.ylabel('Beam emittance(mm-mrad)')\n\n\n# This is where the beam is saved\nplt.scatter(s_saved, np.ones(len(s_saved))*0, color = 'black', marker = 'x')\n\n\nplt.legend();\n</pre> fig, ax = plt.subplots(figsize=(12,5)) plt.plot(df['s'], df['norm_emit_x']*1e6, label=r'$\\epsilon_{n,x}$') plt.plot(df['s'], df['norm_emit_y']*1e6, label=r'$\\epsilon_{n,y}$') plt.xlabel('s (m)') plt.ylabel('Beam emittance(mm-mrad)')   # This is where the beam is saved plt.scatter(s_saved, np.ones(len(s_saved))*0, color = 'black', marker = 'x')   plt.legend();"},{"location":"examples/bmad-live-cu-inj/#cu_inj-live","title":"cu_inj Live\u00b6","text":""},{"location":"examples/bmad-live-cu-inj/#datamaps-and-all-pvs-needed","title":"Datamaps, and all PVs needed\u00b6","text":""},{"location":"examples/bmad-live-cu-inj/#epics","title":"EPICS\u00b6","text":""},{"location":"examples/bmad-live-cu-inj/#tao-conveniences","title":"Tao conveniences\u00b6","text":""},{"location":"examples/bmad-live-cu-inj/#form-commands-using-pvdata-and-datamaps","title":"Form commands using PVDATA and datamaps\u00b6","text":""},{"location":"examples/bmad-live-cu-inj/#start-tao","title":"Start Tao\u00b6","text":""},{"location":"examples/bmad-live-cu-inj/#continuous-loop","title":"Continuous loop\u00b6","text":""},{"location":"examples/bmad-live-cu-inj/#get-particles","title":"Get particles\u00b6","text":""},{"location":"examples/bmad-live-cu-inj/#get-giant-table-of-bunch-stats","title":"Get giant table of bunch stats\u00b6","text":""},{"location":"examples/bmad-live-sc-linac/","title":"Live","text":"In\u00a0[1]: Copied! <pre>import lcls_live\nimport os\nos.__file__\n</pre> import lcls_live import os os.__file__ Out[1]: <pre>'/Users/mpe/miniconda3/envs/lcls-live-dev/lib/python3.8/os.py'</pre> In\u00a0[2]: Copied! <pre># Useful for debugging\n%load_ext autoreload\n%autoreload 2\n\n%config InlineBackend.figure_format = 'retina'\n%matplotlib inline\n</pre> # Useful for debugging %load_ext autoreload %autoreload 2  %config InlineBackend.figure_format = 'retina' %matplotlib inline In\u00a0[3]: Copied! <pre>from lcls_live.datamaps import get_datamaps\nfrom lcls_live.archiver import lcls_archiver_restore\n\nfrom lcls_live.tools import isotime\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport os\n</pre> from lcls_live.datamaps import get_datamaps from lcls_live.archiver import lcls_archiver_restore  from lcls_live.tools import isotime  import matplotlib.pyplot as plt import numpy as np  import os In\u00a0[4]: Copied! <pre># Pick a model and slice\n\nMODEL = 'sc_bsyd' # or sc_diag0 or sc_inj\n\nBEGELE = 'BEGINNING'\n#ENDELE = 'OTR0H04'\n#ENDELE = 'ENDCOL0'\nENDELE = 'END'\n</pre> # Pick a model and slice  MODEL = 'sc_bsyd' # or sc_diag0 or sc_inj  BEGELE = 'BEGINNING' #ENDELE = 'OTR0H04' #ENDELE = 'ENDCOL0' ENDELE = 'END' In\u00a0[5]: Copied! <pre>from pytao import Tao\nimport pandas as pd\n</pre> from pytao import Tao import pandas as pd In\u00a0[6]: Copied! <pre>tao = Tao(f'-init $LCLS_LATTICE/bmad/models/{MODEL}/tao.init  -slice  {BEGELE}:{ENDELE}')\ntao.cmd('place floor bpm_orbit')\ntao.cmd('place middle energy')\ntao.cmd('sc floor -10 10')\n\ndef ele_info(ele):\n    dat = tao.ele_head(ele)\n    dat.update(tao.ele_gen_attribs(ele))\n    return dat\n\ndef ele_table(match=\"*\"):\n    ix_ele = tao.lat_list(match, \"ele.ix_ele\", flags=\"-no_slaves\")\n    dat = list(map(ele_info, ix_ele))\n    df = pd.DataFrame(dat, index=ix_ele)\n    df.L.fillna(0, inplace=True)\n    df['s_center'] = df['s'] - df['L']/2\n    df['s_beginning'] = df['s'] - df['L']\n    return  df\n\ndf = ele_table()\n\n# Elements with device names\ndevices = df[df['alias'] != '']\n#devices['name alias s'.split()]\n</pre> tao = Tao(f'-init $LCLS_LATTICE/bmad/models/{MODEL}/tao.init  -slice  {BEGELE}:{ENDELE}') tao.cmd('place floor bpm_orbit') tao.cmd('place middle energy') tao.cmd('sc floor -10 10')  def ele_info(ele):     dat = tao.ele_head(ele)     dat.update(tao.ele_gen_attribs(ele))     return dat  def ele_table(match=\"*\"):     ix_ele = tao.lat_list(match, \"ele.ix_ele\", flags=\"-no_slaves\")     dat = list(map(ele_info, ix_ele))     df = pd.DataFrame(dat, index=ix_ele)     df.L.fillna(0, inplace=True)     df['s_center'] = df['s'] - df['L']/2     df['s_beginning'] = df['s'] - df['L']     return  df  df = ele_table()  # Elements with device names devices = df[df['alias'] != ''] #devices['name alias s'.split()] In\u00a0[7]: Copied! <pre>tao.cmd('x_scale * 0 800')\nprint(tao.cmd('sho var'))\n</pre> tao.cmd('x_scale * 0 800') print(tao.cmd('sho var')) <pre>['       Name                                      Using for Optimization', '    begtwiss[1:6]', '    gradient_L0[1:8]', '    phi0_L0[1:8]', '    q_HTR[1:8]', '    q_L1[1:5]', '    q_L2[1:4]', '    q_L3[1:4]', '    linac_phase[1:4]', '    q_COL1[1:4]', '    q_EMIT2[1:4]', '    bc1[1:1]', '    bc2[1:1]', '    xcor[1:93]', '    ycor[1:93]']\n</pre> In\u00a0[8]: Copied! <pre>from copy import deepcopy\ndef filter_datamap(dm, bmad_names):\n    bnames = dm.data['bmad_name'] \n    bmad_names = set(bmad_names)\n    ix = bnames[[name in bmad_names for name in bnames]].index\n    dm2 = deepcopy(dm)\n    dm2.data = dm.data.loc[ix]\n    return dm2\n</pre> from copy import deepcopy def filter_datamap(dm, bmad_names):     bnames = dm.data['bmad_name']      bmad_names = set(bmad_names)     ix = bnames[[name in bmad_names for name in bnames]].index     dm2 = deepcopy(dm)     dm2.data = dm.data.loc[ix]     return dm2 In\u00a0[9]: Copied! <pre>DM0 = get_datamaps(MODEL)\nDM0.keys()\n</pre> DM0 = get_datamaps(MODEL) DM0.keys() Out[9]: <pre>dict_keys(['bpms', 'cavities', 'correctors', 'tao_energy_measurements', 'quad', 'quad_corrector', 'solenoid'])</pre> In\u00a0[10]: Copied! <pre>good_names = set(df['name'])\nbad_eles = [] # any bad eles\n\nfor ele in bad_eles:\n    good_names.remove(ele)\n\nDM = {}\nfor name, dm in DM0.items():\n    if name == 'tao_energy_measurements':\n        # don't filter\n        DM[name] = dm\n    else:\n        DM[name] = filter_datamap(dm, good_names)\n\nDM['cavities'];\n</pre> good_names = set(df['name']) bad_eles = [] # any bad eles  for ele in bad_eles:     good_names.remove(ele)  DM = {} for name, dm in DM0.items():     if name == 'tao_energy_measurements':         # don't filter         DM[name] = dm     else:         DM[name] = filter_datamap(dm, good_names)  DM['cavities']; In\u00a0[11]: Copied! <pre># datamaps to exclude\nDENYLIST = [\n    #'bpms',\n   # 'cavities',\n    'correctors',\n    #'quad',\n]\n</pre> # datamaps to exclude DENYLIST = [     #'bpms',    # 'cavities',     'correctors',     #'quad', ] In\u00a0[20]: Copied! <pre># PVs needed\nPVLIST =  []\nfor name, dm in DM.items():\n    if name in DENYLIST:\n        continue\n    PVLIST.extend(dm.pvlist)\nPVLIST = list(set(PVLIST))\nlen(PVLIST)\nPVLIST[0:10]\n</pre> # PVs needed PVLIST =  [] for name, dm in DM.items():     if name in DENYLIST:         continue     PVLIST.extend(dm.pvlist) PVLIST = list(set(PVLIST)) len(PVLIST) PVLIST[0:10] Out[20]: <pre>['BPMS:EMIT2:150:X',\n 'ACCL:L2B:0630:AACTMEAN',\n 'ACCL:L2B:0770:AACTMEAN',\n 'BPMS:HTR:760:X',\n 'ACCL:L3B:3530:PACTMEAN',\n 'ACCL:L2B:1250:PACTMEAN',\n 'ACCL:L2B:1470:PACTMEAN',\n 'ACCL:L1B:H220:PACTMEAN',\n 'ACCL:L3B:2080:AACTMEAN',\n 'ACCL:L3B:1970:AACTMEAN']</pre> In\u00a0[21]: Copied! <pre>os.environ['http_proxy']='socks5h://localhost:8080'\nos.environ['HTTPS_PROXY']='socks5h://localhost:8080'\nos.environ['ALL_PROXY']='socks5h://localhost:8080'\n\nPVDATA=lcls_archiver_restore(PVLIST, '2023-06-08T23:09:50.000000-07:00')\n</pre> os.environ['http_proxy']='socks5h://localhost:8080' os.environ['HTTPS_PROXY']='socks5h://localhost:8080' os.environ['ALL_PROXY']='socks5h://localhost:8080'  PVDATA=lcls_archiver_restore(PVLIST, '2023-06-08T23:09:50.000000-07:00') <pre>Requesting: http://lcls-archapp.slac.stanford.edu/retrieval/data/getDataAtTime?at=2023-06-08T23:09:50.000000-07:00&amp;includeProxies=true\nWarning: Missing PV: BPMS:EMIT2:150:X\nWarning: Missing PV: BPMS:HTR:760:X\nWarning: Missing PV: BPMS:DOG:740:X\nWarning: Missing PV: BPMS:SPD:955:TMIT\nWarning: Missing PV: BPMS:DOG:575:Y\nWarning: Missing PV: BPMS:BPN16:400:Y\nWarning: Missing PV: BPMS:COL1:120:Y\nWarning: Missing PV: BPMS:DOG:120:TMIT\nWarning: Missing PV: BPMS:EXT:748:X\nWarning: Missing PV: BPMS:BPN24:400:Y\nWarning: Missing PV: BPMS:SLTD:895:Y\nWarning: Missing PV: BPMS:DOG:355:TMIT\nWarning: Missing PV: BPMS:DOG:280:X\nWarning: Missing PV: BPMS:BPN22:400:TMIT\nWarning: Missing PV: BPMS:L3B:1783:Y\nWarning: Missing PV: BPMS:BPN26:400:TMIT\nWarning: Missing PV: BPMS:L2B:1383:X\nWarning: Missing PV: BPMS:L2B:1183:Y\nWarning: Missing PV: BPMS:BPN13:400:Y\nWarning: Missing PV: BPMS:L3B:1883:TMIT\nWarning: Missing PV: BPMS:BC1B:125:Y\nWarning: Missing PV: BPMS:L3B:3383:Y\nWarning: Missing PV: BPMS:DOG:230:Y\nWarning: Missing PV: BPMS:BPN26:400:X\nWarning: Missing PV: BPMS:L3B:2483:Y\nWarning: Missing PV: BPMS:DOG:250:TMIT\nWarning: Missing PV: BPMS:COL0:400:Y\nWarning: Missing PV: BPMS:L3B:2283:Y\nWarning: Missing PV: BPMS:SLTD:625:Y\nWarning: Missing PV: BPMS:COL1:800:Y\nWarning: Missing PV: BPMS:L3B:2383:X\nWarning: Missing PV: BPMS:BPN27:400:TMIT\nWarning: Missing PV: BPMS:HTR:540:X\nWarning: Missing PV: BPMS:BPN15:400:X\nWarning: Missing PV: BPMS:BPN15:400:Y\nWarning: Missing PV: ACCL:GUNB:455:AACT_AVG\nWarning: Missing PV: BPMS:BPN17:400:Y\nWarning: Missing PV: BPMS:L2B:0883:TMIT\nWarning: Missing PV: BPMS:COL0:940:X\nWarning: Missing PV: BPMS:L1B:0283:X\nWarning: Missing PV: BPMS:DOG:335:X\nWarning: Missing PV: BPMS:BPN19:400:X\nWarning: Missing PV: BPMS:BC2B:530:Y\nWarning: Missing PV: BPMS:HTR:960:X\nWarning: Missing PV: BPMS:DOG:200:X\nWarning: Missing PV: BPMS:DOG:740:TMIT\nWarning: Missing PV: BPMS:COL0:800:X\nWarning: Missing PV: BPMS:L3B:2083:X\nWarning: Missing PV: BPMS:L3B:2883:TMIT\nWarning: Missing PV: BPMS:L0B:0183:X\nWarning: Missing PV: BPMS:BPN28:400:X\nWarning: Missing PV: BPMS:L3B:2183:TMIT\nWarning: Missing PV: BPMS:BPN14:400:TMIT\nWarning: Missing PV: BPMS:L2B:0483:X\nWarning: Missing PV: BPMS:BPN23:400:TMIT\nWarning: Missing PV: BPMS:EMIT2:900:TMIT\nWarning: Missing PV: BPMS:HTR:980:X\nWarning: Missing PV: BPMS:DOG:150:X\nWarning: Missing PV: BPMS:L3B:2183:X\nWarning: Missing PV: BPMS:COL0:320:X\nWarning: Missing PV: BPMS:L3B:3483:Y\nWarning: Missing PV: BPMS:L2B:0783:Y\nWarning: Missing PV: BPMS:COL1:880:Y\nWarning: Missing PV: BPMS:SPD:525:TMIT\nWarning: Missing PV: BPMS:L2B:0583:TMIT\nWarning: Missing PV: BPMS:COL0:940:Y\nWarning: Missing PV: BPMS:COL1:280:Y\nWarning: Missing PV: BPMS:SPD:955:X\nWarning: Missing PV: BPMS:HTR:320:Y\nWarning: Missing PV: BPMS:SPD:420:TMIT\nWarning: Missing PV: BPMS:EMIT2:300:Y\nWarning: Missing PV: BPMS:L2B:0483:Y\nWarning: Missing PV: BPMS:BPN25:400:Y\nWarning: Missing PV: BPMS:DOG:135:TMIT\nWarning: Missing PV: BPMS:COL0:400:X\nWarning: Missing PV: BPMS:BPN18:400:X\nWarning: Missing PV: BPMS:BPN18:400:Y\nWarning: Missing PV: BPMS:COL1:640:TMIT\nWarning: Missing PV: BPMS:BPN20:400:Y\nWarning: Missing PV: BPMS:COL1:560:Y\nWarning: Missing PV: BPMS:DOG:355:Y\nWarning: Missing PV: BPMS:L3B:3183:X\nWarning: Missing PV: BPMS:EXT:351:X\nWarning: Missing PV: BPMS:L2B:0983:TMIT\nWarning: Missing PV: BPMS:COL1:640:Y\nWarning: Missing PV: BPMS:L2B:1583:Y\nWarning: Missing PV: BPMS:L1B:H283:TMIT\nWarning: Missing PV: BPMS:DOG:120:X\nWarning: Missing PV: BPMS:COL1:960:TMIT\nWarning: Missing PV: BPMS:L3B:1783:X\nWarning: Missing PV: BPMS:COL1:260:X\nWarning: Missing PV: BPMS:COL0:880:X\nWarning: Missing PV: BPMS:L2B:1083:Y\nWarning: Missing PV: BPMS:L2B:0683:X\nWarning: Missing PV: BPMS:L3B:2583:TMIT\nWarning: Missing PV: BPMS:HTR:540:Y\nWarning: Missing PV: BPMS:COL0:135:TMIT\nWarning: Missing PV: BPMS:COL0:720:TMIT\nWarning: Missing PV: BPMS:COL0:720:X\nWarning: Missing PV: BPMS:EMIT2:150:Y\nWarning: Missing PV: BPMS:L3B:1883:X\nWarning: Missing PV: BPMS:COL1:720:Y\nWarning: Missing PV: BPMS:SLTD:895:X\nWarning: Missing PV: BPMS:COL1:120:TMIT\nWarning: Missing PV: BPMS:COL0:280:TMIT\nWarning: Missing PV: BPMS:DOG:230:X\nWarning: Missing PV: BPMS:HTR:365:Y\nWarning: Missing PV: BPMS:EXT:748:Y\nWarning: Missing PV: BPMS:L3B:2783:X\nWarning: Missing PV: BPMS:COL0:560:Y\nWarning: Missing PV: BPMS:BPN17:400:X\nWarning: Missing PV: BPMS:COL0:480:Y\nWarning: Missing PV: BPMS:L3B:2783:Y\nWarning: Missing PV: BPMS:COL0:640:X\nWarning: Missing PV: BPMS:BPN20:400:X\nWarning: Missing PV: BPMS:L3B:3383:X\nWarning: Missing PV: BPMS:BPN15:400:TMIT\nWarning: Missing PV: BPMS:DOG:200:TMIT\nWarning: Missing PV: BPMS:COL0:880:TMIT\nWarning: Missing PV: ACCL:GUNB:455:PACT_AVG\nWarning: Missing PV: BPMS:BC2B:150:X\nWarning: Missing PV: BPMS:DOG:405:X\nWarning: Missing PV: BPMS:BPN25:400:X\nWarning: Missing PV: BPMS:COL0:720:Y\nWarning: Missing PV: BPMS:COL0:260:TMIT\nWarning: Missing PV: BPMS:L3B:2683:X\nWarning: Missing PV: BPMS:L3B:2083:Y\nWarning: Missing PV: BPMS:COL0:240:TMIT\nWarning: Missing PV: BPMS:COL1:960:X\nWarning: Missing PV: BPMS:L3B:2983:TMIT\nWarning: Missing PV: BPMS:L3B:2383:Y\nWarning: Missing PV: BPMS:L2B:1283:Y\nWarning: Missing PV: BPMS:L3B:1683:Y\nWarning: Missing PV: BPMS:COL1:320:Y\nWarning: Missing PV: BPMS:SPD:135:Y\nWarning: Missing PV: BPMS:L2B:0783:TMIT\nWarning: Missing PV: BPMS:BPN28:400:Y\nWarning: Missing PV: BPMS:COL1:260:Y\nWarning: Missing PV: BPMS:COL0:135:Y\nWarning: Missing PV: BPMS:COL1:800:TMIT\nWarning: Missing PV: BPMS:SLTD:625:X\nWarning: Missing PV: BPMS:L2B:0883:Y\nWarning: Missing PV: BPMS:BPN13:400:X\nWarning: Missing PV: BPMS:HTR:760:TMIT\nWarning: Missing PV: BPMS:DOG:180:X\nWarning: Missing PV: BPMS:L1B:H183:TMIT\nWarning: Missing PV: BPMS:BC2B:530:TMIT\nWarning: Missing PV: BPMS:L3B:2983:X\nWarning: Missing PV: BPMS:L2B:0983:Y\nWarning: Missing PV: BPMS:L2B:0583:Y\nWarning: Missing PV: BPMS:L2B:1083:TMIT\nWarning: Missing PV: BPMS:L3B:2483:TMIT\nWarning: Missing PV: BPMS:L2B:0583:X\nWarning: Missing PV: BPMS:COL1:260:TMIT\nWarning: Missing PV: BPMS:HTR:320:TMIT\nWarning: Missing PV: BPMS:L1B:0383:Y\nWarning: Missing PV: BPMS:SPD:570:TMIT\nWarning: Missing PV: BPMS:COL0:240:Y\nWarning: Missing PV: BPMS:HTR:120:X\nWarning: Missing PV: BPMS:SPD:135:TMIT\nWarning: Missing PV: BPMS:COL0:480:TMIT\nWarning: Missing PV: BPMS:L2B:1583:TMIT\nWarning: Missing PV: BPMS:L3B:3283:Y\nWarning: Missing PV: BPMS:COL0:640:TMIT\nWarning: Missing PV: BPMS:COL0:880:Y\nWarning: Missing PV: BPMS:COL1:280:X\nWarning: Missing PV: BPMS:SPD:420:X\nWarning: Missing PV: BPMS:SPD:525:Y\nWarning: Missing PV: BPMS:COL0:560:TMIT\nWarning: Missing PV: BPMS:BC2B:530:X\nWarning: Missing PV: BPMS:BPN28:200:X\nWarning: Missing PV: BPMS:BPN19:400:TMIT\nWarning: Missing PV: BPMS:HTR:320:X\nWarning: Missing PV: BPMS:BPN21:400:X\nWarning: Missing PV: BPMS:HTR:960:Y\nWarning: Missing PV: BPMS:DOG:910:Y\nWarning: Missing PV: BPMS:L1B:H183:Y\nWarning: Missing PV: BPMS:L0B:0183:Y\nWarning: Missing PV: BPMS:HTR:980:TMIT\nWarning: Missing PV: BPMS:EMIT2:300:TMIT\nWarning: Missing PV: BPMS:L3B:1683:TMIT\nWarning: Missing PV: BPMS:BC1B:440:X\nWarning: Missing PV: BPMS:L3B:2083:TMIT\nWarning: Missing PV: BPMS:COL1:560:X\nWarning: Missing PV: BPMS:BPN20:400:TMIT\nWarning: Missing PV: BPMS:BPN25:400:TMIT\nWarning: Missing PV: BPMS:L1B:H283:X\nWarning: Missing PV: BPMS:DOG:165:X\nWarning: Missing PV: BPMS:L3B:1983:Y\nWarning: Missing PV: BPMS:COL0:480:X\nWarning: Missing PV: BPMS:HTR:120:Y\nWarning: Missing PV: BPMS:HTR:960:TMIT\nWarning: Missing PV: BPMS:EXT:351:Y\nWarning: Missing PV: BPMS:L1B:0383:TMIT\nWarning: Missing PV: BPMS:L3B:1983:X\nWarning: Missing PV: BPMS:BPN14:400:X\nWarning: Missing PV: BPMS:HTR:860:Y\nWarning: Missing PV: BPMS:HTR:460:TMIT\nWarning: Missing PV: BPMS:L2B:0783:X\nWarning: Missing PV: BPMS:EMIT2:800:X\nWarning: Missing PV: BPMS:BPN19:400:Y\nWarning: Missing PV: BPMS:BPN26:400:Y\nWarning: Missing PV: BPMS:COL1:400:X\nWarning: Missing PV: BPMS:L3B:1883:Y\nWarning: Missing PV: BPMS:BPN16:400:TMIT\nWarning: Missing PV: BPMS:L3B:2183:Y\nWarning: Missing PV: BPMS:L3B:3583:TMIT\nWarning: Missing PV: BPMS:DOG:355:X\nWarning: Missing PV: BPMS:COL1:720:X\nWarning: Missing PV: BPMS:COL0:260:X\nWarning: Missing PV: BPMS:DOG:150:TMIT\nWarning: Missing PV: BPMS:L2B:1183:X\nWarning: Missing PV: BPMS:BC2B:150:Y\nWarning: Missing PV: BPMS:L2B:1083:X\nWarning: Missing PV: BPMS:COL1:880:TMIT\nWarning: Missing PV: BPMS:DOG:215:X\nWarning: Missing PV: BPMS:L1B:0283:Y\nWarning: Missing PV: BPMS:BPN17:400:TMIT\nWarning: Missing PV: BPMS:SPD:340:TMIT\nWarning: Missing PV: BPMS:SPD:340:Y\nWarning: Missing PV: BPMS:L2B:1383:TMIT\nWarning: Missing PV: BPMS:L2B:1383:Y\nWarning: Missing PV: BPMS:L3B:2683:Y\nWarning: Missing PV: BPMS:BPN22:400:Y\nWarning: Missing PV: BPMS:L1B:H183:X\nWarning: Missing PV: BPMS:HTR:460:X\nWarning: Missing PV: BPMS:BC1B:125:X\nWarning: Missing PV: BPMS:DOG:135:Y\nWarning: Missing PV: BPMS:COL1:960:Y\nWarning: Missing PV: BPMS:COL0:800:Y\nWarning: Missing PV: BPMS:L2B:0883:X\nWarning: Missing PV: BPMS:BPN27:400:X\nWarning: Missing PV: BPMS:L2B:1483:X\nWarning: Missing PV: BPMS:L3B:3183:TMIT\nWarning: Missing PV: BPMS:SPD:700:X\nWarning: Missing PV: BPMS:L3B:2883:X\nWarning: Missing PV: BPMS:COL1:720:TMIT\nWarning: Missing PV: BPMS:SPD:570:Y\nWarning: Missing PV: BPMS:L3B:2483:X\nWarning: Missing PV: BPMS:L3B:3083:X\nWarning: Missing PV: BPMS:BC1B:440:Y\nWarning: Missing PV: BPMS:COL0:940:TMIT\nWarning: Missing PV: BPMS:L3B:2783:TMIT\nWarning: Missing PV: BPMS:BPN28:200:Y\nWarning: Missing PV: BPMS:COL1:560:TMIT\nWarning: Missing PV: BPMS:COL0:800:TMIT\nWarning: Missing PV: BPMS:DOG:280:Y\nWarning: Missing PV: BPMS:COL1:880:X\nWarning: Missing PV: BPMS:BPN28:400:TMIT\nWarning: Missing PV: BPMS:HTR:365:X\nWarning: Missing PV: BPMS:L3B:2583:Y\nWarning: Missing PV: BPMS:EMIT2:300:X\nWarning: Missing PV: BPMS:L3B:3583:Y\nWarning: Missing PV: BPMS:SPD:135:X\nWarning: Missing PV: BPMS:HTR:830:Y\nWarning: Missing PV: BPMS:L3B:2283:X\nWarning: Missing PV: BPMS:L2B:1283:TMIT\nWarning: Missing PV: BPMS:COL1:320:X\nWarning: Missing PV: BPMS:L3B:2583:X\nWarning: Missing PV: BPMS:COL0:260:Y\nWarning: Missing PV: BPMS:SPD:255:X\nWarning: Missing PV: BPMS:COL1:640:X\nWarning: Missing PV: BPMS:BPN24:400:X\nWarning: Missing PV: BPMS:EMIT2:800:TMIT\nWarning: Missing PV: BPMS:EMIT2:800:Y\nWarning: Missing PV: BPMS:L2B:1483:Y\nWarning: Missing PV: BPMS:SPD:570:X\nWarning: Missing PV: BPMS:COL1:480:X\nWarning: Missing PV: BPMS:DOG:335:TMIT\nWarning: Missing PV: BPMS:L3B:3583:X\nWarning: Missing PV: BPMS:EMIT2:900:X\nWarning: Missing PV: BPMS:DOG:910:TMIT\nWarning: Missing PV: BPMS:L3B:3183:Y\nWarning: Missing PV: BPMS:COL1:400:Y\nWarning: Missing PV: BPMS:DOG:180:TMIT\nWarning: Missing PV: BPMS:L3B:2983:Y\nWarning: Missing PV: BPMS:BPN21:400:Y\nWarning: Missing PV: BPMS:BC1B:440:TMIT\nWarning: Missing PV: BPMS:COL0:135:X\nWarning: Missing PV: BPMS:DOG:135:X\nWarning: Missing PV: BPMS:DOG:165:TMIT\nWarning: Missing PV: BPMS:COL1:120:X\nWarning: Missing PV: BPMS:DOG:200:Y\nWarning: Missing PV: BPMS:DOG:575:X\nWarning: Missing PV: BPMS:COL1:480:TMIT\nWarning: Missing PV: BPMS:DOG:910:X\nWarning: Missing PV: BPMS:HTR:760:Y\nWarning: Missing PV: BPMS:DOG:180:Y\nWarning: Missing PV: BPMS:L3B:3283:TMIT\nWarning: Missing PV: BPMS:L3B:3483:TMIT\nWarning: Missing PV: BPMS:COL0:400:TMIT\nWarning: Missing PV: BPMS:DOG:120:Y\nWarning: Missing PV: BPMS:HTR:980:Y\nWarning: Missing PV: BPMS:BPN27:400:Y\nWarning: Missing PV: BPMS:COL0:280:Y\nWarning: Missing PV: BPMS:L1B:0283:TMIT\nWarning: Missing PV: BPMS:SPD:955:Y\nWarning: Missing PV: BPMS:L3B:3083:TMIT\nWarning: Missing PV: BPMS:SPD:700:TMIT\nWarning: Missing PV: BPMS:L3B:3083:Y\nWarning: Missing PV: BPMS:COL1:400:TMIT\nWarning: Missing PV: BPMS:EMIT2:900:Y\nWarning: Missing PV: BPMS:HTR:830:TMIT\nWarning: Missing PV: BPMS:EXT:748:TMIT\nWarning: Missing PV: BPMS:COL1:480:Y\nWarning: Missing PV: BPMS:L3B:2283:TMIT\nWarning: Missing PV: BPMS:EXT:351:TMIT\nWarning: Missing PV: BPMS:COL1:280:TMIT\nWarning: Missing PV: BPMS:BC2B:150:TMIT\nWarning: Missing PV: BPMS:L1B:0383:X\nWarning: Missing PV: BPMS:BPN14:400:Y\nWarning: Missing PV: BPMS:SPD:700:Y\nWarning: Missing PV: BPMS:L2B:0483:TMIT\nWarning: Missing PV: BPMS:COL1:800:X\nWarning: Missing PV: BPMS:L3B:1983:TMIT\nWarning: Missing PV: BPMS:COL0:280:X\nWarning: Missing PV: BPMS:L2B:1183:TMIT\nWarning: Missing PV: BPMS:HTR:540:TMIT\nWarning: Missing PV: BPMS:L3B:3283:X\nWarning: Missing PV: BPMS:SPD:525:X\nWarning: Missing PV: BPMS:L3B:2383:TMIT\nWarning: Missing PV: BPMS:BPN28:200:TMIT\nWarning: Missing PV: BPMS:BPN16:400:X\nWarning: Missing PV: BPMS:COL0:640:Y\nWarning: Missing PV: BPMS:SPD:420:Y\nWarning: Missing PV: BPMS:BPN23:400:X\nWarning: Missing PV: BPMS:DOG:740:Y\nWarning: Missing PV: BPMS:L3B:3483:X\nWarning: Missing PV: BPMS:L2B:1583:X\nWarning: Missing PV: BPMS:L2B:0683:TMIT\nWarning: Missing PV: BPMS:DOG:230:TMIT\nWarning: Missing PV: BPMS:SPD:340:X\nWarning: Missing PV: BPMS:COL0:320:Y\nWarning: Missing PV: BPMS:L0B:0183:TMIT\nWarning: Missing PV: BPMS:DOG:150:Y\nWarning: Missing PV: BPMS:DOG:405:TMIT\nWarning: Missing PV: BPMS:BC1B:125:TMIT\nWarning: Missing PV: BPMS:HTR:830:X\nWarning: Missing PV: BPMS:HTR:860:X\nWarning: Missing PV: BPMS:L3B:2683:TMIT\nWarning: Missing PV: BPMS:SLTD:625:TMIT\nWarning: Missing PV: BPMS:HTR:120:TMIT\nWarning: Missing PV: BPMS:COL0:240:X\nWarning: Missing PV: BPMS:COL0:560:X\nWarning: Missing PV: BPMS:HTR:365:TMIT\nWarning: Missing PV: BPMS:BPN13:400:TMIT\nWarning: Missing PV: BPMS:DOG:335:Y\nWarning: Missing PV: BPMS:DOG:215:TMIT\nWarning: Missing PV: BPMS:DOG:165:Y\nWarning: Missing PV: BPMS:COL0:320:TMIT\nWarning: Missing PV: BPMS:COL1:320:TMIT\nWarning: Missing PV: BPMS:DOG:280:TMIT\nWarning: Missing PV: BPMS:L3B:2883:Y\nWarning: Missing PV: BPMS:SLTD:895:TMIT\nWarning: Missing PV: BPMS:DOG:250:X\nWarning: Missing PV: BPMS:BPN23:400:Y\nWarning: Missing PV: BPMS:L1B:H283:Y\nWarning: Missing PV: BPMS:SPD:255:Y\nWarning: Missing PV: BPMS:L2B:0983:X\nWarning: Missing PV: BPMS:L2B:0683:Y\nWarning: Missing PV: BPMS:DOG:215:Y\nWarning: Missing PV: BPMS:L3B:1783:TMIT\nWarning: Missing PV: BPMS:DOG:250:Y\nWarning: Missing PV: BPMS:L3B:3383:TMIT\nWarning: Missing PV: BPMS:L2B:1283:X\nWarning: Missing PV: BPMS:BPN22:400:X\nWarning: Missing PV: BPMS:EMIT2:150:TMIT\nWarning: Missing PV: BPMS:DOG:405:Y\nWarning: Missing PV: BPMS:SPD:255:TMIT\nWarning: Missing PV: BPMS:L3B:1683:X\nWarning: Missing PV: BPMS:BPN24:400:TMIT\nWarning: Missing PV: BPMS:BPN21:400:TMIT\nWarning: Missing PV: BPMS:HTR:860:TMIT\nWarning: Missing PV: BPMS:HTR:460:Y\nWarning: Missing PV: BPMS:L2B:1483:TMIT\nWarning: Missing PV: BPMS:BPN18:400:TMIT\nWarning: Missing PV: BPMS:DOG:575:TMIT\n</pre> In\u00a0[26]: Copied! <pre>cmds=tao_commands(PVDATA)\nsave_cmds(cmds,filename='live_pvs_bsyd_08-06-23T23:09:50.tao')\n</pre> cmds=tao_commands(PVDATA) save_cmds(cmds,filename='live_pvs_bsyd_08-06-23T23:09:50.tao') In\u00a0[\u00a0]: Copied! <pre>import epics\nfrom epics import caget_many, caget\nfrom time import sleep, time\n\ndef caget_dict(pvlist):\n    return dict(zip(pvlist, caget_many(pvlist)))\n</pre> import epics from epics import caget_many, caget from time import sleep, time  def caget_dict(pvlist):     return dict(zip(pvlist, caget_many(pvlist))) In\u00a0[\u00a0]: Copied! <pre>caget('KLYS:LI22:11:KPHR')\n</pre> caget('KLYS:LI22:11:KPHR') In\u00a0[\u00a0]: Copied! <pre># Test get\nPVDATA = caget_dict(PVLIST)\nBAD_DEVICES = set()\nPVLIST_GOOD = []\nfor k, v in PVDATA.items():\n    if v is None:\n        #print('Bad PV:', k)\n        device = ':'.join((k.split(':')[:-1]))\n        BAD_DEVICES.add(device)\n    else:\n        PVLIST_GOOD.append(k)\n        \n# Get bmad names\nbdf = devices[['alias', 'name']].set_index('alias')\nBAD_NAMES = list(bdf.loc[list(BAD_DEVICES)]['name'])\n#BAD_NAMES        \n        \n#BAD_DEVICES, BAD_NAMES\nprint(len(BAD_DEVICES))\nprint(len(PVLIST_GOOD))\n</pre> # Test get PVDATA = caget_dict(PVLIST) BAD_DEVICES = set() PVLIST_GOOD = [] for k, v in PVDATA.items():     if v is None:         #print('Bad PV:', k)         device = ':'.join((k.split(':')[:-1]))         BAD_DEVICES.add(device)     else:         PVLIST_GOOD.append(k)          # Get bmad names bdf = devices[['alias', 'name']].set_index('alias') BAD_NAMES = list(bdf.loc[list(BAD_DEVICES)]['name']) #BAD_NAMES                  #BAD_DEVICES, BAD_NAMES print(len(BAD_DEVICES)) print(len(PVLIST_GOOD)) In\u00a0[\u00a0]: Copied! <pre>MONITOR = {pvname:epics.PV(pvname) for pvname in PVLIST_GOOD}\nsleep(1) # Wait for all to connect\n</pre> MONITOR = {pvname:epics.PV(pvname) for pvname in PVLIST_GOOD} sleep(1) # Wait for all to connect In\u00a0[\u00a0]: Copied! <pre>def get_pvdata():   \n    itime = isotime()\n    pvdata =  {k:MONITOR[k].get() for k in MONITOR}\n    return pvdata\nPVDATA = get_pvdata()\n</pre> def get_pvdata():        itime = isotime()     pvdata =  {k:MONITOR[k].get() for k in MONITOR}     return pvdata PVDATA = get_pvdata() In\u00a0[\u00a0]: Copied! <pre>#print(PVDATA);\n</pre> #print(PVDATA); In\u00a0[15]: Copied! <pre>for name in BAD_NAMES:\n    good_names.remove(name)\n</pre> for name in BAD_NAMES:     good_names.remove(name) <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[15], line 1\n----&gt; 1 for name in BAD_NAMES:\n      2     good_names.remove(name)\n\nNameError: name 'BAD_NAMES' is not defined</pre> In\u00a0[23]: Copied! <pre>DM_GOOD = {}\nfor name, dm in DM.items():\n    if name == 'tao_energy_measurements':\n        # don't filter\n        DM_GOOD[name] = dm\n    else:\n        DM_GOOD[name] = filter_datamap(dm, good_names)\n</pre> DM_GOOD = {} for name, dm in DM.items():     if name == 'tao_energy_measurements':         # don't filter         DM_GOOD[name] = dm     else:         DM_GOOD[name] = filter_datamap(dm, good_names) In\u00a0[\u00a0]: Copied! <pre>print(DM_GOOD['bpms'])\n</pre> print(DM_GOOD['bpms']) In\u00a0[17]: Copied! <pre>def tao_commands(pvdata):\n    cmds = []\n    for name, dm in DM_GOOD.items():\n        cmds.extend(dm.as_tao(pvdata))\n    return cmds\n</pre> def tao_commands(pvdata):     cmds = []     for name, dm in DM_GOOD.items():         cmds.extend(dm.as_tao(pvdata))     return cmds In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[18]: Copied! <pre>def save_cmds(cmds, filename='cmds.tao'): # Write to file for running with vanilla Tao\n    with open(filename, 'w') as f:\n        f.write('set global lattice_calc_on = F\\n')\n        f.write('set global plot_on = F\\n')    \n        f.write('set ele quad::* field_master = T')\n        f.write('set ele SC_L* is_on = F')\n        for cmd in cmds:\n            f.write(cmd+'\\n')\n        f.write('set global lattice_calc_on = T\\n')        \n        f.write('set global plot_on = T\\n')   \n</pre> def save_cmds(cmds, filename='cmds.tao'): # Write to file for running with vanilla Tao     with open(filename, 'w') as f:         f.write('set global lattice_calc_on = F\\n')         f.write('set global plot_on = F\\n')             f.write('set ele quad::* field_master = T')         f.write('set ele SC_L* is_on = F')         for cmd in cmds:             f.write(cmd+'\\n')         f.write('set global lattice_calc_on = T\\n')                 f.write('set global plot_on = T\\n')    In\u00a0[\u00a0]: Copied! <pre># Match HTR to design\ndef set_htr_twiss(tao):\n    cmds=\"\"\"\nvv\nvd\nset data HTR.begtwiss|meas = HTR.begtwiss|design\nuse dat HTR.begtwiss[1:4]\nuse var begtwiss[1:4]\nolmdif\n\"\"\".split('\\n') \n    tao.cmds(cmds)\n    tao.cmd('set global lattice_calc_on = T')\n    tao.cmd('run')\n    tao.cmd('set global plot_on = T')\n#set_htr_twiss(tao)\n</pre> # Match HTR to design def set_htr_twiss(tao):     cmds=\"\"\" vv vd set data HTR.begtwiss|meas = HTR.begtwiss|design use dat HTR.begtwiss[1:4] use var begtwiss[1:4] olmdif \"\"\".split('\\n')      tao.cmds(cmds)     tao.cmd('set global lattice_calc_on = T')     tao.cmd('run')     tao.cmd('set global plot_on = T') #set_htr_twiss(tao) In\u00a0[\u00a0]: Copied! <pre># mat2 x, y for PyEmittance\ndef get_mats():\n    mat6 = tao.matrix('Q0H01#2', 'OTR0H04')['mat6']\n    mat2x = mat6[0:2, 0:2]\n    mat2y = mat6[2:4, 2:4]\n    return mat2x, mat2y\n</pre> # mat2 x, y for PyEmittance def get_mats():     mat6 = tao.matrix('Q0H01#2', 'OTR0H04')['mat6']     mat2x = mat6[0:2, 0:2]     mat2y = mat6[2:4, 2:4]     return mat2x, mat2y In\u00a0[\u00a0]: Copied! <pre># Master switches for element scaling\ntao.cmd('set ele quad::* field_master = T')\n\n# Turn off phase overlays \ntao.cmd('set ele SC_L* is_on = F', raises=False)\n\nif MODEL == 'sc_inj':\n    tao.cmd('set ele lcavity::* autoscale_phase = T')\n</pre> # Master switches for element scaling tao.cmd('set ele quad::* field_master = T')  # Turn off phase overlays  tao.cmd('set ele SC_L* is_on = F', raises=False)  if MODEL == 'sc_inj':     tao.cmd('set ele lcavity::* autoscale_phase = T') In\u00a0[\u00a0]: Copied! <pre>pvdata = get_pvdata()\ncmds=tao_commands(pvdata)\nsave_cmds(cmds,filename='live_pvs_26_05_23_1500.tao')\n</pre> pvdata = get_pvdata() cmds=tao_commands(pvdata) save_cmds(cmds,filename='live_pvs_26_05_23_1500.tao') In\u00a0[\u00a0]: Copied! <pre>tao.cmd('scale top 0 5000')\n</pre> tao.cmd('scale top 0 5000') In\u00a0[\u00a0]: Copied! <pre>def run1():\n    #sleep(.001)\n    t1 = time()\n    pvdata = get_pvdata()\n    cmds = tao_commands(pvdata)\n    tao.cmd('set global plot_on = F;set global lattice_calc_on = F')\n    tao.cmds(cmds); # Apply\n\n    tao.cmd('set global lattice_calc_on = T')\n    tao.cmd('set global plot_on = T')\n    #toggle_beam()\n    \n    dt = time()-t1\n    #print(dt)    \n</pre> def run1():     #sleep(.001)     t1 = time()     pvdata = get_pvdata()     cmds = tao_commands(pvdata)     tao.cmd('set global plot_on = F;set global lattice_calc_on = F')     tao.cmds(cmds); # Apply      tao.cmd('set global lattice_calc_on = T')     tao.cmd('set global plot_on = T')     #toggle_beam()          dt = time()-t1     #print(dt)      In\u00a0[\u00a0]: Copied! <pre>tao.cmd('set var *|model=*|design')\ntao.cmd('set global lattice_calc_on=T')\n</pre> tao.cmd('set var *|model=*|design') tao.cmd('set global lattice_calc_on=T') In\u00a0[\u00a0]: Copied! <pre>%%time\nrun1()\n</pre> %%time run1() In\u00a0[\u00a0]: Copied! <pre># Set twiss\nset_htr_twiss(tao)\n</pre> # Set twiss set_htr_twiss(tao) In\u00a0[\u00a0]: Copied! <pre># Check charge (pC)\ndf = pd.DataFrame(tao.data_d_array('orbit', 'charge'))\ndf['charge_live'] =df['meas_value']*1e12\ndf[['ele_name', 'charge_live']]\n</pre> # Check charge (pC) df = pd.DataFrame(tao.data_d_array('orbit', 'charge')) df['charge_live'] =df['meas_value']*1e12 df[['ele_name', 'charge_live']] In\u00a0[\u00a0]: Copied! <pre>tao.cmd('set var *|model=*|design')\n</pre> tao.cmd('set var *|model=*|design') In\u00a0[\u00a0]: Copied! <pre>%%tao\nuse dat orbit.x\nuse dat orbit.y\nsc floor -5 5\nsc top\nx_scale * 0 50\nsc top\n</pre> %%tao use dat orbit.x use dat orbit.y sc floor -5 5 sc top x_scale * 0 50 sc top In\u00a0[\u00a0]: Copied! <pre># Run forever\nwhile True:\n    run1()\n</pre> # Run forever while True:     run1()"},{"location":"examples/bmad-live-sc-linac/#sc_linac-live","title":"<code>sc_linac</code> Live\u00b6","text":""},{"location":"examples/bmad-live-sc-linac/#bmad-model","title":"Bmad model\u00b6","text":""},{"location":"examples/bmad-live-sc-linac/#datamaps-and-all-pvs-needed","title":"Datamaps, and all PVs needed\u00b6","text":""},{"location":"examples/bmad-live-sc-linac/#epics","title":"EPICS\u00b6","text":""},{"location":"examples/bmad-live-sc-linac/#fiter-datamamps-again","title":"Fiter datamamps again\u00b6","text":""},{"location":"examples/bmad-live-sc-linac/#tao-conveniences","title":"Tao conveniences\u00b6","text":""},{"location":"examples/bmad-live-sc-linac/#form-commands-using-pvdata-and-datamaps","title":"Form commands using PVDATA and datamaps\u00b6","text":""},{"location":"examples/bmad-live-sc-linac/#continuous-loop","title":"Continuous loop\u00b6","text":""},{"location":"examples/bmad-live-sc-linac/#continuous-run","title":"Continuous run\u00b6","text":""},{"location":"examples/bsa_snapshot/","title":"BSA Data Extraction","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>from lcls_live.bsa import bsa_snapshot\n</pre> from lcls_live.bsa import bsa_snapshot In\u00a0[3]: Copied! <pre>?bsa_snapshot\n</pre> ?bsa_snapshot <pre>Signature: bsa_snapshot(timestamp, beampath, pvnames=None)\nDocstring:\nExtract as a snapshot (PV values) nearest a timestamp from a BSA HDF5 file.\n\nParameters\n----------\nh5file: str\n    BSA HDF5 file with data that includes the timestamp\n    \ntimestamp: pd.DateTime or datetime.datetime\n    This must be localized (not naive time)\n    \npvnames : list or None\n    List of PV names to extract. If None, all PVs in the source file will be extracted.\n    Optional, default=None\n    \nReturns\n-------\nsnapshot: dict\n    Dict with:\n        'pvdata' : dict of {pv name:pv value}\n        'timestamp' : pd.Timestamp, including the nanosecond.\n        'source' : Original HDF5 file that the data came from.\n\nExamples\n--------\n&gt;&gt;&gt;bsa_snapshot('2021-11-11T00:00:00-08:00', 'cu_hxr')\nFile:      ~/GitHub/lcls-live/lcls_live/bsa.py\nType:      function\n</pre> In\u00a0[4]: Copied! <pre>%%time\nsnapshot = bsa_snapshot('2021-12-11T00:00:00-08:00', 'cu_hxr')\n\nsnapshot.keys()\n</pre> %%time snapshot = bsa_snapshot('2021-12-11T00:00:00-08:00', 'cu_hxr')  snapshot.keys() <pre>CPU times: user 439 ms, sys: 38.6 ms, total: 478 ms\nWall time: 1.28 s\n</pre> Out[4]: <pre>dict_keys(['pvdata', 'timestamp', 'source'])</pre> In\u00a0[5]: Copied! <pre># The data is a simple dict\npvdata = snapshot['pvdata']\nlen(pvdata)\n</pre> # The data is a simple dict pvdata = snapshot['pvdata'] len(pvdata) Out[5]: <pre>1091</pre> In\u00a0[6]: Copied! <pre># Here are a few keys in the dict\nlist(pvdata)[0:10]\n</pre> # Here are a few keys in the dict list(pvdata)[0:10] Out[6]: <pre>['ACCL_IN20_300_L0A_A',\n 'ACCL_IN20_300_L0A_P',\n 'ACCL_IN20_400_L0B_A',\n 'ACCL_IN20_400_L0B_P',\n 'ACCL_LI21_180_L1X_A',\n 'ACCL_LI21_180_L1X_P',\n 'ACCL_LI21_1_L1S_A',\n 'ACCL_LI21_1_L1S_P',\n 'BLD_SYS0_500_ANG_X',\n 'BLD_SYS0_500_ANG_Y']</pre> In\u00a0[7]: Copied! <pre># And some values\nfor k in list(pvdata)[0:10]:\n    print(k, pvdata[k])\n</pre> # And some values for k in list(pvdata)[0:10]:     print(k, pvdata[k]) <pre>ACCL_IN20_300_L0A_A 57.99538201588009\nACCL_IN20_300_L0A_P -0.00917495265120749\nACCL_IN20_400_L0B_A 69.47708616061887\nACCL_IN20_400_L0B_P -2.564164251349297\nACCL_LI21_180_L1X_A 21.016761493860674\nACCL_LI21_180_L1X_P -160.00175793392177\nACCL_LI21_1_L1S_A 111.53502637024258\nACCL_LI21_1_L1S_P -22.394640079900164\nBLD_SYS0_500_ANG_X -0.03628770291941744\nBLD_SYS0_500_ANG_Y -0.0050121151142197545\n</pre> In\u00a0[8]: Copied! <pre># This is the exact time the data is at\nsnapshot['timestamp']\n</pre> # This is the exact time the data is at snapshot['timestamp'] Out[8]: <pre>Timestamp('2021-12-11 08:00:00.003286466+0000', tz='UTC')</pre> In\u00a0[9]: Copied! <pre># And the original HDF5 source file\nsnapshot['source']\n</pre> # And the original HDF5 source file snapshot['source'] Out[9]: <pre>'/gpfs/slac/staas/fs1/g/bsd/BSAService/data/2021/12/11/CU_HXR_20211211_080825.h5'</pre> In\u00a0[10]: Copied! <pre># Note that some values are nan\npvdata['BLM_UNDH_0235_QDCRAW']    \n</pre> # Note that some values are nan pvdata['BLM_UNDH_0235_QDCRAW']     Out[10]: <pre>array(nan)</pre> In\u00a0[11]: Copied! <pre># Adding a list pv names to be extracted. Note that any PV not present is simply returned as None\nbsa_snapshot('2021-12-11T00:00:00-08:00', 'cu_hxr', \n             pvnames = ['ACCL_IN20_300_L0A_A', 'ACCL_IN20_300_L0A_P', 'dummy'])\n</pre> # Adding a list pv names to be extracted. Note that any PV not present is simply returned as None bsa_snapshot('2021-12-11T00:00:00-08:00', 'cu_hxr',               pvnames = ['ACCL_IN20_300_L0A_A', 'ACCL_IN20_300_L0A_P', 'dummy']) Out[11]: <pre>{'pvdata': {'ACCL_IN20_300_L0A_A': array(57.99538202),\n  'ACCL_IN20_300_L0A_P': array(-0.00917495),\n  'dummy': None},\n 'timestamp': Timestamp('2021-12-11 08:00:00.003286466+0000', tz='UTC'),\n 'source': '/gpfs/slac/staas/fs1/g/bsd/BSAService/data/2021/12/11/CU_HXR_20211211_080825.h5'}</pre> In\u00a0[12]: Copied! <pre># The timestamp must be localized, so this will fail:\ntry:\n    bsa_snapshot('2021-12-11T00:00:00', 'cu_hxr')\nexcept Exception as ex:\n    print(ex)\n</pre> # The timestamp must be localized, so this will fail: try:     bsa_snapshot('2021-12-11T00:00:00', 'cu_hxr') except Exception as ex:     print(ex) <pre>Cannot convert tz-naive Timestamp, use tz_localize to localize\n</pre> In\u00a0[13]: Copied! <pre>import datetime\n# This is not localized:\ndatetime.datetime(2021, 12, 1, 17, 7, 49)\n</pre> import datetime # This is not localized: datetime.datetime(2021, 12, 1, 17, 7, 49) Out[13]: <pre>datetime.datetime(2021, 12, 1, 17, 7, 49)</pre> In\u00a0[14]: Copied! <pre># but this is:\ndtime = datetime.datetime(2021, 12, 1, 17, 7, 49, tzinfo=datetime.timezone.utc)\ndtime\n</pre> # but this is: dtime = datetime.datetime(2021, 12, 1, 17, 7, 49, tzinfo=datetime.timezone.utc) dtime Out[14]: <pre>datetime.datetime(2021, 12, 1, 17, 7, 49, tzinfo=datetime.timezone.utc)</pre> In\u00a0[15]: Copied! <pre># And will work with bsa_snapshot\nbsa_snapshot(dtime, 'cu_hxr')['timestamp']\n</pre> # And will work with bsa_snapshot bsa_snapshot(dtime, 'cu_hxr')['timestamp'] Out[15]: <pre>Timestamp('2021-12-01 17:07:49.002202872+0000', tz='UTC')</pre> In\u00a0[16]: Copied! <pre>from lcls_live.bsa import bsa_h5file, BSA_DATA_SEARCH_PATHS\n</pre> from lcls_live.bsa import bsa_h5file, BSA_DATA_SEARCH_PATHS In\u00a0[17]: Copied! <pre># These are the pahs searched.\nBSA_DATA_SEARCH_PATHS\n</pre> # These are the pahs searched. BSA_DATA_SEARCH_PATHS Out[17]: <pre>['/gpfs/slac/staas/fs1/g/bsd/BSAService/data/',\n '/nfs/slac/g/bsd/BSAService/data/']</pre> In\u00a0[18]: Copied! <pre># Find the appropriate file\nbsa_h5file('2021-12-11T00:00:00-08:00', 'cu_hxr')\n</pre> # Find the appropriate file bsa_h5file('2021-12-11T00:00:00-08:00', 'cu_hxr') Out[18]: <pre>'/gpfs/slac/staas/fs1/g/bsd/BSAService/data/2021/12/11/CU_HXR_20211211_080825.h5'</pre> In\u00a0[19]: Copied! <pre>?bsa_h5file\n</pre> ?bsa_h5file <pre>Signature: bsa_h5file(timestamp, beampath)\nDocstring:\nFinds the BSA HDF5 file that contains the timestamp for a given beampath\n\nBSA data files are named as:\n    CU_SXR_20211210_140742.h5\n    \nWhich corresponds to '{beampath}_{time_str}.h5' with time_str in the format: '%Y%m%d_%H%M%S'\n    \nSee the documentation in:\n    https://www.slac.stanford.edu/grp/ad/docs/model/matlab/bsd.html\n     \"The data files are named with the UTC datestamp of the END of their data taking period\"\n     \nParameters\n----------\n\ntimestamp: pd.DateTime or datetime.datetime\n    This must be localized (not naive time)\n\nbeampath : str\n        one of ['cu_hxr', 'cu_sxr'] (case independent)\n    \nReturns\n-------\nh5file : str\n    Full path to the HDF5 file that should contain the time. \n        \n        \nExamples\n--------\n\n&gt;&gt;&gt; bsa_h5file('2021-12-11T00:00:00-08:00', 'cu_hxr')\n'/gpfs/slac/staas/fs1/g/bsd/BSAService/data/2021/12/11/CU_HXR_20211211_080825.h5'\nFile:      ~/GitHub/lcls-live/lcls_live/bsa.py\nType:      function\n</pre>"},{"location":"examples/bsa_snapshot/#bsa-data-extraction","title":"BSA Data Extraction\u00b6","text":"<p>LCLS-Live provides simple functions to extract beam synchronous acquisition (BSA) data from archived HDF5 files. These files are stored on SLAC systems, and the user must have access to these to use these functions.</p> <p>See the documentation: LCLS BEAM SYNCHRONOUS DATASTORE USER GUIDE at: https://www.slac.stanford.edu/grp/ad/docs/model/matlab/bsd.html</p>"},{"location":"examples/bsa_snapshot/#bsa-snapshots","title":"BSA snapshots\u00b6","text":"<p>This is the basic high-level function.</p>"},{"location":"examples/bsa_snapshot/#notes-on-timestamps","title":"Notes on timestamps\u00b6","text":"<p>Timestamps here must have localization information (i.e. the time zone). Otherwise it is ambiguous what time to extract. The internal data files and directories are named and described in UTC time only.</p> <p>See: https://pandas.pydata.org/docs/reference/api/pandas.Timestamp.html</p>"},{"location":"examples/bsa_snapshot/#helper-functions","title":"Helper functions\u00b6","text":""},{"location":"examples/datamaps/","title":"DataMap examples","text":"In\u00a0[1]: Copied! <pre># Useful for debugging\n%load_ext autoreload\n%autoreload 2\n\n%config InlineBackend.figure_format = 'retina'\n</pre> # Useful for debugging %load_ext autoreload %autoreload 2  %config InlineBackend.figure_format = 'retina' In\u00a0[2]: Copied! <pre>import json\nimport os\n</pre> import json import os In\u00a0[3]: Copied! <pre>PVDATA = json.load(open('data/PVDATA-2021-04-21T08:10:25.000000-07:00.json'))\nlen(PVDATA)\n</pre> PVDATA = json.load(open('data/PVDATA-2021-04-21T08:10:25.000000-07:00.json')) len(PVDATA) Out[3]: <pre>740</pre> In\u00a0[4]: Copied! <pre>from lcls_live.datamaps.tabular import TabularDataMap\n\nimport pandas as pd\nimport dataclasses \n</pre> from lcls_live.datamaps.tabular import TabularDataMap  import pandas as pd import dataclasses  In\u00a0[5]: Copied! <pre># Make some tabular data\ndat0 = [\n    \n    {'name': 'BC1_offset',\n     'pvname':'BMLN:LI21:235:MOTR',  # mm\n     'bmad_factor': 0.001,\n     'bmad_name': 'O_BC1_OFFSET',\n     'bmad_attribute': 'offset'\n    },\n    \n    {'name': 'BC2_offset',\n     'pvname':'BMLN:LI24:805:MOTR', # mm\n     'bmad_factor': 0.001,\n     'bmad_name': 'O_BC2_OFFSET',\n     'bmad_attribute': 'offset'\n    },\n    \n    {\n    'name': 'L1_phase',\n    'description': 'Controls the L1 phase, which is the single klystron L21_1. We will disable this for now, because the KlystronDataMap handles the phase directly.',\n    'pvname': 'ACCL:LI21:1:L1S_S_PV',\n    'bmad_name':'O_L1',\n    'bmad_factor': 0,  # We'll disable this for now. The Klystron handles it. \n    'bmad_attribute':'phase_deg'\n    \n}\n]\n\ndat_hxr = [\n        {\n    'name': 'L2_phase',\n    'pvname': 'ACCL:LI22:1:PDES',\n    'bmad_name':'O_L2',\n    'bmad_factor': 1,\n    'bmad_attribute':'phase_deg'\n    \n},\n    {\n    'name': 'L3_phase',\n    'pvname': 'ACCL:LI25:1:PDES',\n    'bmad_name':'O_L3',\n    'bmad_attribute':'phase_deg',\n    'bmad_offset': 0\n    \n}, \n]\n\n# SXR has different PVs\ndat_sxr = [\n        {\n    'name': 'L2_phase',\n    'pvname': 'ACCL:LI22:1:PDES:SETDATA_1',\n    'bmad_name':'O_L2',\n    'bmad_factor': 1,\n    'bmad_attribute':'phase_deg'\n    \n},\n    {\n    'name': 'L3_phase',\n    'pvname': 'ACCL:LI25:1:PDES:SETDATA_1',\n    'bmad_name':'O_L3',\n    'bmad_attribute':'phase_deg',\n    'bmad_offset': 0\n    \n}, \n]\n\n\n#Note that there are sone NaNs here. That's okay.\ndf = pd.DataFrame(dat0+dat_hxr)\ndf\n</pre> # Make some tabular data dat0 = [          {'name': 'BC1_offset',      'pvname':'BMLN:LI21:235:MOTR',  # mm      'bmad_factor': 0.001,      'bmad_name': 'O_BC1_OFFSET',      'bmad_attribute': 'offset'     },          {'name': 'BC2_offset',      'pvname':'BMLN:LI24:805:MOTR', # mm      'bmad_factor': 0.001,      'bmad_name': 'O_BC2_OFFSET',      'bmad_attribute': 'offset'     },          {     'name': 'L1_phase',     'description': 'Controls the L1 phase, which is the single klystron L21_1. We will disable this for now, because the KlystronDataMap handles the phase directly.',     'pvname': 'ACCL:LI21:1:L1S_S_PV',     'bmad_name':'O_L1',     'bmad_factor': 0,  # We'll disable this for now. The Klystron handles it.      'bmad_attribute':'phase_deg'      } ]  dat_hxr = [         {     'name': 'L2_phase',     'pvname': 'ACCL:LI22:1:PDES',     'bmad_name':'O_L2',     'bmad_factor': 1,     'bmad_attribute':'phase_deg'      },     {     'name': 'L3_phase',     'pvname': 'ACCL:LI25:1:PDES',     'bmad_name':'O_L3',     'bmad_attribute':'phase_deg',     'bmad_offset': 0      },  ]  # SXR has different PVs dat_sxr = [         {     'name': 'L2_phase',     'pvname': 'ACCL:LI22:1:PDES:SETDATA_1',     'bmad_name':'O_L2',     'bmad_factor': 1,     'bmad_attribute':'phase_deg'      },     {     'name': 'L3_phase',     'pvname': 'ACCL:LI25:1:PDES:SETDATA_1',     'bmad_name':'O_L3',     'bmad_attribute':'phase_deg',     'bmad_offset': 0      },  ]   #Note that there are sone NaNs here. That's okay. df = pd.DataFrame(dat0+dat_hxr) df Out[5]: name pvname bmad_factor bmad_name bmad_attribute description bmad_offset 0 BC1_offset BMLN:LI21:235:MOTR 0.001 O_BC1_OFFSET offset NaN NaN 1 BC2_offset BMLN:LI24:805:MOTR 0.001 O_BC2_OFFSET offset NaN NaN 2 L1_phase ACCL:LI21:1:L1S_S_PV 0.000 O_L1 phase_deg Controls the L1 phase, which is the single kly... NaN 3 L2_phase ACCL:LI22:1:PDES 1.000 O_L2 phase_deg NaN NaN 4 L3_phase ACCL:LI25:1:PDES NaN O_L3 phase_deg NaN 0.0 In\u00a0[6]: Copied! <pre># Make the DataMap object, identifying the columns to be used\nDM = TabularDataMap(df, pvname='pvname', element='bmad_name', attribute='bmad_attribute', factor='bmad_factor', offset='bmad_offset')\n\nDM.pvlist\n</pre> # Make the DataMap object, identifying the columns to be used DM = TabularDataMap(df, pvname='pvname', element='bmad_name', attribute='bmad_attribute', factor='bmad_factor', offset='bmad_offset')  DM.pvlist Out[6]: <pre>['BMLN:LI21:235:MOTR',\n 'BMLN:LI24:805:MOTR',\n 'ACCL:LI21:1:L1S_S_PV',\n 'ACCL:LI22:1:PDES',\n 'ACCL:LI25:1:PDES']</pre> In\u00a0[7]: Copied! <pre># Process the data for Bmad commands\nDM.as_bmad(PVDATA)\n</pre> # Process the data for Bmad commands DM.as_bmad(PVDATA) Out[7]: <pre>['O_BC1_OFFSET[offset] = 0.001 * 247.85581047127175',\n 'O_BC2_OFFSET[offset] = 0.001 * 385.0',\n 'O_L1[phase_deg] = 0.0 * -22.43420088792822',\n 'O_L2[phase_deg] = -36.284427384073055',\n 'O_L3[phase_deg] = 0.0']</pre> In\u00a0[8]: Copied! <pre># or Tao commands\nDM.as_tao(PVDATA)\n</pre> # or Tao commands DM.as_tao(PVDATA) Out[8]: <pre>['set ele O_BC1_OFFSET offset = 0.001 * 247.85581047127175',\n 'set ele O_BC2_OFFSET offset = 0.001 * 385.0',\n 'set ele O_L1 phase_deg = 0.0 * -22.43420088792822',\n 'set ele O_L2 phase_deg = -36.284427384073055',\n 'set ele O_L3 phase_deg = 0.0']</pre> In\u00a0[9]: Copied! <pre># Save, and reload\nJSON_OUT = 'linac_TabularDataMap.json'\n\nDM.to_json(JSON_OUT)\n\nDM2 = TabularDataMap.from_json(open(JSON_OUT).read())\nDM2.data\n</pre> # Save, and reload JSON_OUT = 'linac_TabularDataMap.json'  DM.to_json(JSON_OUT)  DM2 = TabularDataMap.from_json(open(JSON_OUT).read()) DM2.data Out[9]: name pvname bmad_factor bmad_name bmad_attribute description bmad_offset 0 BC1_offset BMLN:LI21:235:MOTR 0.001 O_BC1_OFFSET offset None NaN 1 BC2_offset BMLN:LI24:805:MOTR 0.001 O_BC2_OFFSET offset None NaN 2 L1_phase ACCL:LI21:1:L1S_S_PV 0.000 O_L1 phase_deg Controls the L1 phase, which is the single kly... NaN 3 L2_phase ACCL:LI22:1:PDES 1.000 O_L2 phase_deg None NaN 4 L3_phase ACCL:LI25:1:PDES NaN O_L3 phase_deg None 0.0 In\u00a0[10]: Copied! <pre># cleanup\nos.remove(JSON_OUT)\n</pre> # cleanup os.remove(JSON_OUT) In\u00a0[11]: Copied! <pre># Read a previously made csv file. This has slightly different columns\ndf2 = pd.read_csv('../lcls_live/data/cu_hxr/quad_mapping.csv')[0:10]\ndf2.columns\n</pre> # Read a previously made csv file. This has slightly different columns df2 = pd.read_csv('../lcls_live/data/cu_hxr/quad_mapping.csv')[0:10] df2.columns Out[11]: <pre>Index(['device_name', 'attribute', 'unit', 'bmad_ele_name', 'bmad_factor',\n       'bmad_attribute', 'example_value'],\n      dtype='object')</pre> In\u00a0[12]: Copied! <pre>df2['pvname'] = df2['device_name']+':'+df2['attribute']\n\nDM2 = TabularDataMap(df2, pvname='pvname', element='bmad_ele_name', attribute='bmad_attribute', factor='bmad_factor', offset='')\nDM2.pvlist\n</pre> df2['pvname'] = df2['device_name']+':'+df2['attribute']  DM2 = TabularDataMap(df2, pvname='pvname', element='bmad_ele_name', attribute='bmad_attribute', factor='bmad_factor', offset='') DM2.pvlist Out[12]: <pre>['QUAD:LI21:211:BDES',\n 'QUAD:LI21:221:BDES',\n 'QUAD:LI21:243:BDES',\n 'QUAD:LI21:251:BDES',\n 'QUAD:LI21:271:BDES',\n 'QUAD:LI21:335:BDES',\n 'QUAD:LI24:713:BDES',\n 'QUAD:LI24:740:BDES',\n 'QUAD:LI24:860:BDES',\n 'QUAD:LI24:892:BDES']</pre> In\u00a0[13]: Copied! <pre># Here these aren't in our PVDATA\nDM2.as_tao(PVDATA)\n</pre> # Here these aren't in our PVDATA DM2.as_tao(PVDATA) Out[13]: <pre>['set ele QM11 b1_gradient = -1/(10.0*0.108) * 4.2315152',\n 'set ele CQ11 b1_gradient = -1/(10.0*0.108) * -0.0204323',\n 'set ele SQ13 b1_gradient = -1/(10.0*0.160) * 0.0',\n 'set ele CQ12 b1_gradient = -1/(10.0*0.108) * -0.2459959',\n 'set ele QM12 b1_gradient = -1/(10.0*0.108) * -6.1242668',\n 'set ele QM15 b1_gradient = -1/(10.0*0.108) * -5.47263',\n 'set ele QM21 b1_gradient = -1/(10.0*0.461) * 35.4159609',\n 'set ele CQ21 b1_gradient = -1/(10.0*0.108) * -0.0621288',\n 'set ele CQ22 b1_gradient = -1/(10.0*0.108) * 1.35389',\n 'set ele QM22 b1_gradient = -1/(10.0*0.461) * -40.7820027']</pre> In\u00a0[14]: Copied! <pre># We could  check beforehand:\nmissing = [name for name in DM2.pvlist if name not in PVDATA]\nlen(missing)\n</pre> # We could  check beforehand: missing = [name for name in DM2.pvlist if name not in PVDATA] len(missing) Out[14]: <pre>0</pre> In\u00a0[15]: Copied! <pre>from pytao import Tao\ntao = Tao('-init $LCLS_LATTICE/bmad/models/cu_hxr/tao.init -slice OTR2:END -noplot')\n</pre> from pytao import Tao tao = Tao('-init $LCLS_LATTICE/bmad/models/cu_hxr/tao.init -slice OTR2:END -noplot') In\u00a0[16]: Copied! <pre>def quad_pvinfo(tao, ele):\n    \"\"\"\n    Returns dict of PV information for use in a DataMap\n    \"\"\"\n    head = tao.ele_head(ele)\n    attrs = tao.ele_gen_attribs(ele)\n    device = head['alias']\n    \n    d = {}\n    d['bmad_name'] = ele\n    d['pvname_rbv'] = device+':BACT'\n    d['pvname'] = device+':BDES'    \n    d['bmad_factor'] = -1/attrs['L']/10\n    d['bmad_attribute'] = 'b1_gradient'\n    return d\n\nquad_pvinfo(tao, 'QM01')\n</pre> def quad_pvinfo(tao, ele):     \"\"\"     Returns dict of PV information for use in a DataMap     \"\"\"     head = tao.ele_head(ele)     attrs = tao.ele_gen_attribs(ele)     device = head['alias']          d = {}     d['bmad_name'] = ele     d['pvname_rbv'] = device+':BACT'     d['pvname'] = device+':BDES'         d['bmad_factor'] = -1/attrs['L']/10     d['bmad_attribute'] = 'b1_gradient'     return d  quad_pvinfo(tao, 'QM01') Out[16]: <pre>{'bmad_name': 'QM01',\n 'pvname_rbv': 'QUAD:IN20:631:BACT',\n 'pvname': 'QUAD:IN20:631:BDES',\n 'bmad_factor': -0.9259259259259259,\n 'bmad_attribute': 'b1_gradient'}</pre> In\u00a0[17]: Copied! <pre>quad_names = tao.lat_list('quad::*', 'ele.name', flags='-no_slaves')\n\ndfq = pd.DataFrame([quad_pvinfo(tao, ele) for ele in quad_names])\ndfq\n</pre> quad_names = tao.lat_list('quad::*', 'ele.name', flags='-no_slaves')  dfq = pd.DataFrame([quad_pvinfo(tao, ele) for ele in quad_names]) dfq Out[17]: bmad_name pvname_rbv pvname bmad_factor bmad_attribute 0 QM01 QUAD:IN20:631:BACT QUAD:IN20:631:BDES -0.925926 b1_gradient 1 QM02 QUAD:IN20:651:BACT QUAD:IN20:651:BDES -0.925926 b1_gradient 2 QB QUAD:IN20:731:BACT QUAD:IN20:731:BDES -0.936330 b1_gradient 3 QM03 QUAD:IN20:771:BACT QUAD:IN20:771:BDES -0.925926 b1_gradient 4 QM04 QUAD:IN20:781:BACT QUAD:IN20:781:BDES -0.925926 b1_gradient ... ... ... ... ... ... 180 QHXH47 QUAD:UNDH:4780:BACT QUAD:UNDH:4780:BDES -1.190476 b1_gradient 181 QUE1 QUAD:DMPH:300:BACT QUAD:DMPH:300:BDES -0.181818 b1_gradient 182 QUE2 QUAD:DMPH:380:BACT QUAD:DMPH:380:BDES -0.181818 b1_gradient 183 QDMP1 QUAD:DMPH:500:BACT QUAD:DMPH:500:BDES -0.232558 b1_gradient 184 QDMP2 QUAD:DMPH:600:BACT QUAD:DMPH:600:BDES -0.232558 b1_gradient <p>185 rows \u00d7 5 columns</p> In\u00a0[18]: Copied! <pre>QUAD_DATAMAP = TabularDataMap(dfq, pvname='pvname', element='bmad_name', attribute = 'bmad_attribute', factor='bmad_factor')\n</pre> QUAD_DATAMAP = TabularDataMap(dfq, pvname='pvname', element='bmad_name', attribute = 'bmad_attribute', factor='bmad_factor') In\u00a0[19]: Copied! <pre>#JSONFILE = os.path.join(data_dir, 'cu_hxr/quad_TabularDataMap.json')\n#QUAD_DATAMAP.to_json(JSONFILE)\n</pre> #JSONFILE = os.path.join(data_dir, 'cu_hxr/quad_TabularDataMap.json') #QUAD_DATAMAP.to_json(JSONFILE) In\u00a0[20]: Copied! <pre># The syntax is flexible enough to use for getting measurements for Tao\nENERGY_MEAS = [\n    {\n    'name': 'L1_energy',\n    'pvname': 'BEND:LI21:231:EDES', # or EDES\n    'tao_datum': 'BC1.energy[1]',        \n    'factor': 1e9\n    },\n    {\n    'name': 'L2_energy',\n    'pvname': 'BEND:LI24:790:EDES', # or EDES\n    'tao_datum': 'BC2.energy[1]',\n    'factor': 1e9\n    },\n    {\n    'name': 'L3_HXR_energy',\n    'pvname': 'BEND:DMPH:400:EDES', # or EDES\n    'tao_datum': 'L3.energy[2]',\n    'factor': 1e9\n    }\n   #{\n   #'name': 'L3_SXR_energy',\n   #'pvname': 'BEND:DMPS:400:EDES', # or EDES\n   #'factor': 1e9\n   #},       \n]\ndf = pd.DataFrame(ENERGY_MEAS)\nDM = TabularDataMap(df, pvname='pvname', element='tao_datum', factor='factor',\n                   tao_format = 'set data {element}|meas  = {value}',\n                   bmad_format = '! No equivalent Bmad format for: set data {element}|meas  = {value}'\n                   )\nDM.as_tao(PVDATA)\n</pre> # The syntax is flexible enough to use for getting measurements for Tao ENERGY_MEAS = [     {     'name': 'L1_energy',     'pvname': 'BEND:LI21:231:EDES', # or EDES     'tao_datum': 'BC1.energy[1]',             'factor': 1e9     },     {     'name': 'L2_energy',     'pvname': 'BEND:LI24:790:EDES', # or EDES     'tao_datum': 'BC2.energy[1]',     'factor': 1e9     },     {     'name': 'L3_HXR_energy',     'pvname': 'BEND:DMPH:400:EDES', # or EDES     'tao_datum': 'L3.energy[2]',     'factor': 1e9     }    #{    #'name': 'L3_SXR_energy',    #'pvname': 'BEND:DMPS:400:EDES', # or EDES    #'factor': 1e9    #},        ] df = pd.DataFrame(ENERGY_MEAS) DM = TabularDataMap(df, pvname='pvname', element='tao_datum', factor='factor',                    tao_format = 'set data {element}|meas  = {value}',                    bmad_format = '! No equivalent Bmad format for: set data {element}|meas  = {value}'                    ) DM.as_tao(PVDATA) Out[20]: <pre>['set data BC1.energy[1]|meas  = 1000000000.0 * 0.22',\n 'set data BC2.energy[1]|meas  = 1000000000.0 * 4.5',\n 'set data L3.energy[2]|meas  = 1000000000.0 * 11.0']</pre> In\u00a0[21]: Copied! <pre># and this will produce\nDM.as_bmad(PVDATA)\n</pre> # and this will produce DM.as_bmad(PVDATA) Out[21]: <pre>['! No equivalent Bmad format for: set data BC1.energy[1]|meas  = 1000000000.0 * 0.22',\n '! No equivalent Bmad format for: set data BC2.energy[1]|meas  = 1000000000.0 * 4.5',\n '! No equivalent Bmad format for: set data L3.energy[2]|meas  = 1000000000.0 * 11.0']</pre> In\u00a0[22]: Copied! <pre># Save\n#JSON_OUT = os.path.join(data_dir, 'cu_hxr/tao_energy_measurements_TabularDataMap.json')\n#DM.to_json(JSON_OUT)\n</pre> # Save #JSON_OUT = os.path.join(data_dir, 'cu_hxr/tao_energy_measurements_TabularDataMap.json') #DM.to_json(JSON_OUT) In\u00a0[23]: Copied! <pre>from lcls_live.datamaps.klystron import subbooster_pvinfo, SUBBOOSTER_SECTORS\n</pre> from lcls_live.datamaps.klystron import subbooster_pvinfo, SUBBOOSTER_SECTORS In\u00a0[24]: Copied! <pre>SUBBOOSTERS = []\nfor sector in SUBBOOSTER_SECTORS:\n    \n    dat = subbooster_pvinfo(sector, beamcode=1)  # beamcode=1 =&gt; HXR, beamcode=2 =&gt; SXR\n    dat['bmad_name'] = f'SBST_{sector}'\n    dat['bmad_attribute'] = 'phase_deg'\n    SUBBOOSTERS.append(dat)\ndf = pd.DataFrame(SUBBOOSTERS)    \ndf  \n</pre> SUBBOOSTERS = [] for sector in SUBBOOSTER_SECTORS:          dat = subbooster_pvinfo(sector, beamcode=1)  # beamcode=1 =&gt; HXR, beamcode=2 =&gt; SXR     dat['bmad_name'] = f'SBST_{sector}'     dat['bmad_attribute'] = 'phase_deg'     SUBBOOSTERS.append(dat) df = pd.DataFrame(SUBBOOSTERS)     df   Out[24]: name phase_pvname desciption bmad_name bmad_attribute 0 SBST_21 SBST:LI21:1:PHAS Normal subbooster SBST_21 phase_deg 1 SBST_22 SBST:LI22:1:PHAS Normal subbooster SBST_22 phase_deg 2 SBST_23 SBST:LI23:1:PHAS Normal subbooster SBST_23 phase_deg 3 SBST_24 SBST:LI24:1:PHAS Normal subbooster SBST_24 phase_deg 4 SBST_25 SBST:LI25:1:PHAS Normal subbooster SBST_25 phase_deg 5 SBST_26 SBST:LI26:1:PHAS Normal subbooster SBST_26 phase_deg 6 SBST_27 SBST:LI27:1:PHAS Normal subbooster SBST_27 phase_deg 7 SBST_28 SBST:LI28:1:PHAS Normal subbooster SBST_28 phase_deg 8 SBST_29 ACCL:LI29:0:KLY_PDES Special feedback subbooster, beamcode 1 SBST_29 phase_deg 9 SBST_30 ACCL:LI30:0:KLY_PDES Special feedback subbooster, beamcode 1 SBST_30 phase_deg In\u00a0[25]: Copied! <pre>def beginning_meas(name, pvprefix):\n    dat =  [\n    {\n    'name': f'{name}_beta_x_meas',\n    'pvname': f'{pvprefix}:BETA_X', \n    'bmad_name': 'beginning',   \n    'bmad_attribute': 'beta_a'\n    },\n    {\n    'name': f'{name}_beta_y_meas',\n    'pvname': f'{pvprefix}:BETA_Y', \n    'bmad_name': 'beginning',   \n    'bmad_attribute': 'beta_b'\n    },\n    {\n    'name': f'{name}_alpha_x_meas',\n    'pvname': f'{pvprefix}:ALPHA_X', \n    'bmad_name': 'beginning',   \n    'bmad_attribute': 'alpha_a'\n    },\n    {\n    'name': f'{name}_alpha_y_meas',\n    'pvname': f'{pvprefix}:ALPHA_Y', \n    'bmad_name': 'beginning',   \n    'bmad_attribute': 'alpha_b'\n    },    \n    ]\n    \n    df= pd.DataFrame(dat)\n\n    return TabularDataMap(df, pvname='pvname', element='bmad_name', attribute = 'bmad_attribute')\n\nOTR2_BEGINNING = beginning_meas('OTR2', 'OTRS:IN20:571')\nOTR2_BEGINNING.data\n</pre> def beginning_meas(name, pvprefix):     dat =  [     {     'name': f'{name}_beta_x_meas',     'pvname': f'{pvprefix}:BETA_X',      'bmad_name': 'beginning',        'bmad_attribute': 'beta_a'     },     {     'name': f'{name}_beta_y_meas',     'pvname': f'{pvprefix}:BETA_Y',      'bmad_name': 'beginning',        'bmad_attribute': 'beta_b'     },     {     'name': f'{name}_alpha_x_meas',     'pvname': f'{pvprefix}:ALPHA_X',      'bmad_name': 'beginning',        'bmad_attribute': 'alpha_a'     },     {     'name': f'{name}_alpha_y_meas',     'pvname': f'{pvprefix}:ALPHA_Y',      'bmad_name': 'beginning',        'bmad_attribute': 'alpha_b'     },         ]          df= pd.DataFrame(dat)      return TabularDataMap(df, pvname='pvname', element='bmad_name', attribute = 'bmad_attribute')  OTR2_BEGINNING = beginning_meas('OTR2', 'OTRS:IN20:571') OTR2_BEGINNING.data  Out[25]: name pvname bmad_name bmad_attribute 0 OTR2_beta_x_meas OTRS:IN20:571:BETA_X beginning beta_a 1 OTR2_beta_y_meas OTRS:IN20:571:BETA_Y beginning beta_b 2 OTR2_alpha_x_meas OTRS:IN20:571:ALPHA_X beginning alpha_a 3 OTR2_alpha_y_meas OTRS:IN20:571:ALPHA_Y beginning alpha_b In\u00a0[26]: Copied! <pre>WS02_BEGINNING = beginning_meas('WS02', 'WIRE:IN20:561')\n</pre> WS02_BEGINNING = beginning_meas('WS02', 'WIRE:IN20:561') In\u00a0[27]: Copied! <pre>from lcls_live.datamaps.klystron import KlystronDataMap, klystron_pvinfo, existing_LCLS_klystrons_sector_station\n</pre> from lcls_live.datamaps.klystron import KlystronDataMap, klystron_pvinfo, existing_LCLS_klystrons_sector_station In\u00a0[28]: Copied! <pre># Get a sector, station that exists\nexisting_LCLS_klystrons_sector_station\n</pre> # Get a sector, station that exists existing_LCLS_klystrons_sector_station Out[28]: <pre>((20, 6),\n (20, 7),\n (20, 8),\n (21, 1),\n (21, 2),\n (21, 3),\n (21, 4),\n (21, 5),\n (21, 6),\n (21, 7),\n (21, 8),\n (22, 1),\n (22, 2),\n (22, 3),\n (22, 4),\n (22, 5),\n (22, 6),\n (22, 7),\n (22, 8),\n (23, 1),\n (23, 2),\n (23, 3),\n (23, 4),\n (23, 5),\n (23, 6),\n (23, 7),\n (23, 8),\n (24, 1),\n (24, 2),\n (24, 3),\n (24, 4),\n (24, 5),\n (24, 6),\n (25, 1),\n (25, 2),\n (25, 3),\n (25, 4),\n (25, 5),\n (25, 6),\n (25, 7),\n (25, 8),\n (26, 1),\n (26, 2),\n (26, 4),\n (26, 5),\n (26, 6),\n (26, 7),\n (26, 8),\n (27, 1),\n (27, 2),\n (27, 3),\n (27, 4),\n (27, 5),\n (27, 6),\n (27, 7),\n (27, 8),\n (28, 1),\n (28, 2),\n (28, 3),\n (28, 4),\n (28, 5),\n (28, 6),\n (28, 7),\n (28, 8),\n (29, 1),\n (29, 2),\n (29, 3),\n (29, 4),\n (29, 5),\n (29, 6),\n (29, 7),\n (29, 8),\n (30, 1),\n (30, 2),\n (30, 3),\n (30, 4),\n (30, 5),\n (30, 6),\n (30, 7),\n (30, 8))</pre> In\u00a0[29]: Copied! <pre># This will return a flat dict of info\nklystron_pvinfo(30, 6)\n</pre> # This will return a flat dict of info klystron_pvinfo(30, 6) Out[29]: <pre>{'name': 'K30_6',\n 'sector': 30,\n 'station': 6,\n 'description': 'Klystron in sector 30, station 6, beamcode 1',\n 'enld_pvname': 'KLYS:LI30:61:ENLD',\n 'phase_pvname': 'KLYS:LI30:61:PHAS',\n 'accelerate_pvname': 'KLYS:LI30:61:BEAMCODE1_STAT',\n 'swrd_pvname': 'KLYS:LI30:61:SWRD',\n 'stat_pvname': 'KLYS:LI30:61:STAT',\n 'hdsc_pvname': 'KLYS:LI30:61:HDSC',\n 'dsta_pvname': 'KLYS:LI30:61:DSTA'}</pre> In\u00a0[30]: Copied! <pre>?KlystronDataMap\n</pre> ?KlystronDataMap <pre>Init signature:\nKlystronDataMap(\n    name: str,\n    sector: int,\n    station: int,\n    description: str = '',\n    enld_pvname: str = '',\n    phase_pvname: str = '',\n    accelerate_pvname: str = '',\n    swrd_pvname: str = '',\n    stat_pvname: str = '',\n    hdsc_pvname: str = '',\n    dsta_pvname: str = '',\n) -&gt; None\nDocstring:     \nAttributes\n----------\nbmad_name : str\npvlist : list[str]\n\nMethods\n-------\nevaluate(pvdata) :\n    Returns\n    -------\n    dict of:\n        enld : float\n            energy gain in MeV\n        phase : float\n            phase in deg\n        in_use : bool\n            \nas_bmad(pvdata)\n    Returns\n    -------\n    list of str:\n        Bmad lattice strings to set values extracted from pvdata\n        \nas_tao(pvdata)\n    Returns\n    -------\n    list of str:\n        Tao command strings  \n        \nto_json(file=None)\n    Returns\n    -------\n        JSON string, or writes to file if given. \n\n@classmethod\nfrom_json(s):\n    Returns a new KlystronDataMap from a JSON string or file\n    \nFile:           ~/Code/GitHub/lcls-live/lcls_live/datamaps/klystron.py\nType:           type\nSubclasses:     \n</pre> In\u00a0[31]: Copied! <pre># This makes an object\nKlystronDataMap(**klystron_pvinfo(21, 6, beamcode=1))\n</pre> # This makes an object KlystronDataMap(**klystron_pvinfo(21, 6, beamcode=1)) Out[31]: <pre>KlystronDataMap(name='K21_6', sector=21, station=6, description='Klystron in sector 21, station 6, beamcode 1', enld_pvname='KLYS:LI21:61:ENLD', phase_pvname='KLYS:LI21:61:PHAS', accelerate_pvname='KLYS:LI21:61:BEAMCODE1_STAT', swrd_pvname='KLYS:LI21:61:SWRD', stat_pvname='KLYS:LI21:61:STAT', hdsc_pvname='KLYS:LI21:61:HDSC', dsta_pvname='KLYS:LI21:61:DSTA')</pre> In\u00a0[32]: Copied! <pre>k = KlystronDataMap(**klystron_pvinfo(21, 6, beamcode=1))\n\n# These are the PV names needed to mapping data\nk.pvlist\n</pre> k = KlystronDataMap(**klystron_pvinfo(21, 6, beamcode=1))  # These are the PV names needed to mapping data k.pvlist  Out[32]: <pre>['KLYS:LI21:61:ENLD',\n 'KLYS:LI21:61:PHAS',\n 'KLYS:LI21:61:BEAMCODE1_STAT',\n 'KLYS:LI21:61:SWRD',\n 'KLYS:LI21:61:STAT',\n 'KLYS:LI21:61:HDSC',\n 'KLYS:LI21:61:DSTA']</pre> In\u00a0[33]: Copied! <pre># This will extract those and produce useful information\nk.evaluate(PVDATA)\n</pre> # This will extract those and produce useful information k.evaluate(PVDATA) Out[33]: <pre>{'enld': 249.342, 'phase': -0.2623023986816406, 'in_use': True}</pre> In\u00a0[34]: Copied! <pre># Actual inputs for a simulation\nk.as_bmad(PVDATA)\n</pre> # Actual inputs for a simulation k.as_bmad(PVDATA) Out[34]: <pre>['K21_6[ENLD_MeV] = 249.342',\n 'K21_6[phase_deg] = -0.2623023986816406',\n 'K21_6[in_use] = 1']</pre> In\u00a0[35]: Copied! <pre># A complete JSON string for serialization\nk.to_json()\n</pre> # A complete JSON string for serialization k.to_json() Out[35]: <pre>'{\"name\": \"K21_6\", \"sector\": 21, \"station\": 6, \"description\": \"Klystron in sector 21, station 6, beamcode 1\", \"enld_pvname\": \"KLYS:LI21:61:ENLD\", \"phase_pvname\": \"KLYS:LI21:61:PHAS\", \"accelerate_pvname\": \"KLYS:LI21:61:BEAMCODE1_STAT\", \"swrd_pvname\": \"KLYS:LI21:61:SWRD\", \"stat_pvname\": \"KLYS:LI21:61:STAT\", \"hdsc_pvname\": \"KLYS:LI21:61:HDSC\", \"dsta_pvname\": \"KLYS:LI21:61:DSTA\"}'</pre> In\u00a0[36]: Copied! <pre># Make a large list\n\nKLYSTRON_DATAMAPS = []\nfor sector, station in existing_LCLS_klystrons_sector_station:\n    #print(sector, station)    \n    info = klystron_pvinfo(sector, station)\n    k = KlystronDataMap(**info)\n\n    KLYSTRON_DATAMAPS.append(k)\n</pre> # Make a large list  KLYSTRON_DATAMAPS = [] for sector, station in existing_LCLS_klystrons_sector_station:     #print(sector, station)         info = klystron_pvinfo(sector, station)     k = KlystronDataMap(**info)      KLYSTRON_DATAMAPS.append(k) In\u00a0[37]: Copied! <pre># Check that our data is sufficient \n\nfor k in KLYSTRON_DATAMAPS:\n    for pv in k.pvlist:\n        if pv not in PVDATA:\n            print(k.name, pv)\n</pre> # Check that our data is sufficient   for k in KLYSTRON_DATAMAPS:     for pv in k.pvlist:         if pv not in PVDATA:             print(k.name, pv) <pre>K20_6 GUN:IN20:1:GN1_AAVG\nK20_6 GUN:IN20:1:GN1_PAVG\nK20_7 ACCL:IN20:300:L0A_AACT_DS0\nK20_7 ACCL:IN20:300:L0A_PACT_DS0\nK20_8 ACCL:IN20:400:L0B_AACT_DS0\nK20_8 ACCL:IN20:400:L0B_PACT_DS0\nK21_1 ACCL:LI21:1:L1S_AACT_DS0\nK21_1 ACCL:LI21:1:L1S_PACT_DS0\nK21_2 ACCL:LI21:180:L1X_AACT_DS0\nK21_2 ACCL:LI21:180:L1X_PACT_DS0\nK24_1 ACCL:LI24:100:KLY_PDES:SETDATA_1\nK24_2 ACCL:LI24:200:KLY_PDES:SETDATA_1\nK24_3 ACCL:LI24:300:KLY_PDES:SETDATA_1\n</pre> In\u00a0[38]: Copied! <pre>s = KLYSTRON_DATAMAPS[0].to_json()\ns\n</pre> s = KLYSTRON_DATAMAPS[0].to_json() s Out[38]: <pre>'{\"name\": \"K20_6\", \"sector\": 20, \"station\": 6, \"description\": \"Klystron in sector 20, station 6, beamcode 1 for the GUN\", \"enld_pvname\": \"GUN:IN20:1:GN1_AAVG\", \"phase_pvname\": \"GUN:IN20:1:GN1_PAVG\", \"accelerate_pvname\": \"\", \"swrd_pvname\": \"\", \"stat_pvname\": \"\", \"hdsc_pvname\": \"\", \"dsta_pvname\": \"\"}'</pre> In\u00a0[39]: Copied! <pre>KlystronDataMap.from_json(s)\n</pre> KlystronDataMap.from_json(s) Out[39]: <pre>KlystronDataMap(name='K20_6', sector=20, station=6, description='Klystron in sector 20, station 6, beamcode 1 for the GUN', enld_pvname='GUN:IN20:1:GN1_AAVG', phase_pvname='GUN:IN20:1:GN1_PAVG', accelerate_pvname='', swrd_pvname='', stat_pvname='', hdsc_pvname='', dsta_pvname='')</pre>"},{"location":"examples/datamaps/#datamap-examples","title":"DataMap examples\u00b6","text":"<p><code>DataMaps</code> are configurable objects with the purpose of translating PV values to simulation inputs. They do not retain any values. Rather, they provide methods <code>.to_tao(pvdata)</code>, <code>.to_bmad(pvdata)</code> that will produce input for Tao and Bmad, respectively, from a dict-like <code>pvdata</code> object with the actual PV names and values.</p>"},{"location":"examples/datamaps/#pvdata","title":"PVDATA\u00b6","text":"<p>Get some actual data that we will use to map</p>"},{"location":"examples/datamaps/#tabular","title":"Tabular\u00b6","text":"<p>Often PVs have a simple linear mapping to simulation inputs. The <code>TabularDataMap</code> helps with this</p>"},{"location":"examples/datamaps/#from-csv","title":"from CSV\u00b6","text":""},{"location":"examples/datamaps/#quads-from-pytao","title":"Quads from Pytao\u00b6","text":""},{"location":"examples/datamaps/#measurements-for-tao","title":"Measurements for Tao\u00b6","text":""},{"location":"examples/datamaps/#subboosters","title":"Subboosters\u00b6","text":""},{"location":"examples/datamaps/#beginning-twiss-measurements","title":"Beginning Twiss measurements\u00b6","text":""},{"location":"examples/datamaps/#klystrondatamap","title":"KlystronDataMap\u00b6","text":""},{"location":"examples/epics_proxy_example/","title":"EPICS Proxy example","text":"In\u00a0[1]: Copied! <pre># Useful for debugging\n%load_ext autoreload\n%autoreload 2\n</pre> # Useful for debugging %load_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>from lcls_live.epics import epics_proxy\nimport os\n</pre> from lcls_live.epics import epics_proxy import os In\u00a0[3]: Copied! <pre>epics = epics_proxy('data/epics_snapshot_2018-03-06T15:21:15.000000-08:00.json', verbose=True)\n</pre> epics = epics_proxy('data/epics_snapshot_2018-03-06T15:21:15.000000-08:00.json', verbose=True) <pre>Loaded data/epics_snapshot_2018-03-06T15:21:15.000000-08:00.json with 2065 PVs\n</pre> In\u00a0[4]: Copied! <pre># Data is kept internally as a dict in .pvdata:\nlist(epics.pvdata)[0:10]\n</pre> # Data is kept internally as a dict in .pvdata: list(epics.pvdata)[0:10] Out[4]: <pre>['ACCL:IN20:350:FUDGE',\n 'ACCL:LI21:180:L1X_S_AV',\n 'ACCL:LI21:180:L1X_S_PV',\n 'ACCL:LI21:1:FUDGE',\n 'ACCL:LI21:1:L1S_S_PV',\n 'ACCL:LI22:1:FUDGE',\n 'ACCL:LI24:100:KLY_PDES',\n 'ACCL:LI24:200:KLY_PDES',\n 'ACCL:LI24:300:KLY_PDES',\n 'ACCL:LI25:1:FUDGE']</pre> In\u00a0[5]: Copied! <pre># caget fetches from .pvdata\nepics.caget('KLYS:LI21:11:ENLD')\n</pre> # caget fetches from .pvdata epics.caget('KLYS:LI21:11:ENLD') Out[5]: <pre>115.836</pre> In\u00a0[6]: Copied! <pre># caput writes to .pvdata\nepics.caput('KLYS:LI21:11:ENLD', 3)\nepics.caget('KLYS:LI21:11:ENLD')\n</pre> # caput writes to .pvdata epics.caput('KLYS:LI21:11:ENLD', 3) epics.caget('KLYS:LI21:11:ENLD') Out[6]: <pre>3</pre> In\u00a0[7]: Copied! <pre># PV\npv = epics.PV('KLYS:LI21:11:ENLD')\npv.get()\n</pre> # PV pv = epics.PV('KLYS:LI21:11:ENLD') pv.get() <pre>PV for KLYS:LI21:11:ENLD\n</pre> Out[7]: <pre>3</pre> In\u00a0[8]: Copied! <pre># caget_many \nepics.caget_many(['KLYS:LI21:11:ENLD',\n 'ACCL:LI21:1:L1S_S_PV',\n 'KLYS:LI21:11:PDES',\n 'KLYS:LI21:11:SWRD',\n 'KLYS:LI21:11:STAT',\n 'KLYS:LI21:11:HDSC',\n 'KLYS:LI21:11:DSTA',\n 'KLYS:LI21:11:BEAMCODE1_STAT',\n 'ACCL:LI21:180:L1X_S_AV',\n 'ACCL:LI21:180:L1X_S_PV'])\n</pre> # caget_many  epics.caget_many(['KLYS:LI21:11:ENLD',  'ACCL:LI21:1:L1S_S_PV',  'KLYS:LI21:11:PDES',  'KLYS:LI21:11:SWRD',  'KLYS:LI21:11:STAT',  'KLYS:LI21:11:HDSC',  'KLYS:LI21:11:DSTA',  'KLYS:LI21:11:BEAMCODE1_STAT',  'ACCL:LI21:180:L1X_S_AV',  'ACCL:LI21:180:L1X_S_PV']) Out[8]: <pre>[3,\n -26.12494033014282,\n -24.5,\n 0,\n 1,\n 1048577.0,\n [1610612738.0, 528640.0],\n 1.0,\n 20.01551950520014,\n -159.9562692633193]</pre> In\u00a0[9]: Copied! <pre># Non-epics routine to save .pvdata to a JSON file\nepics.save(filename='test.json')\n</pre> # Non-epics routine to save .pvdata to a JSON file epics.save(filename='test.json') <pre>Saved test.json\n</pre> In\u00a0[10]: Copied! <pre># Corresponding load routine\nepics.load(filename='test.json')\n</pre> # Corresponding load routine epics.load(filename='test.json') <pre>Loaded test.json with 2065 PVs\n</pre> In\u00a0[11]: Copied! <pre># Cleanup\nos.remove('test.json')\n</pre> # Cleanup os.remove('test.json') In\u00a0[12]: Copied! <pre># Start with a 'base' source of epics data\nepics0 = epics_proxy('data/epics_snapshot_2018-03-06T15:21:15.000000-08:00.json', verbose=True)\n\n# Make another proxy\nepics1 = epics_proxy('cache.json', epics=epics0, verbose=True)\n</pre> # Start with a 'base' source of epics data epics0 = epics_proxy('data/epics_snapshot_2018-03-06T15:21:15.000000-08:00.json', verbose=True)  # Make another proxy epics1 = epics_proxy('cache.json', epics=epics0, verbose=True) <pre>Loaded data/epics_snapshot_2018-03-06T15:21:15.000000-08:00.json with 2065 PVs\n</pre> In\u00a0[13]: Copied! <pre># Get a value\nepics1.caget('KLYS:LI21:11:ENLD')\n</pre> # Get a value epics1.caget('KLYS:LI21:11:ENLD') <pre>Error: pv not cached: KLYS:LI21:11:ENLD\nLoading from epics\n</pre> Out[13]: <pre>115.836</pre> In\u00a0[14]: Copied! <pre># This is the internal data\nepics1.pvdata\n</pre> # This is the internal data epics1.pvdata Out[14]: <pre>{'KLYS:LI21:11:ENLD': 115.836}</pre> In\u00a0[15]: Copied! <pre>epics1.caget_many(['KLYS:LI21:11:ENLD', 'KLYS:LI21:11:DSTA'])\n</pre> epics1.caget_many(['KLYS:LI21:11:ENLD', 'KLYS:LI21:11:DSTA']) Out[15]: <pre>[115.836, [1610612738.0, 528640.0]]</pre> In\u00a0[16]: Copied! <pre># This is the internal data\nepics1.pvdata\n</pre> # This is the internal data epics1.pvdata Out[16]: <pre>{'KLYS:LI21:11:ENLD': 115.836}</pre> In\u00a0[17]: Copied! <pre># Save to JSON\nepics1.save()\n</pre> # Save to JSON epics1.save() <pre>Saved cache.json\n</pre> In\u00a0[18]: Copied! <pre># Cleanup\nos.remove('cache.json')\n</pre> # Cleanup os.remove('cache.json')"},{"location":"examples/epics_proxy_example/#epics-proxy-example","title":"EPICS Proxy example\u00b6","text":"<p>The epics proxy should provide methods that look the same as those in pyepics https://cars9.uchicago.edu/software/python/pyepics3/</p>"},{"location":"examples/epics_proxy_example/#nested-proxies","title":"Nested proxies\u00b6","text":""},{"location":"examples/classic/LCLS_Classic_Model/","title":"LCLS Classic model","text":"In\u00a0[1]: Copied! <pre># Useful for debugging\n%load_ext autoreload\n%autoreload 2\n</pre> # Useful for debugging %load_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>%pylab --no-import-all inline\n%config InlineBackend.figure_format = 'retina'\n</pre> %pylab --no-import-all inline %config InlineBackend.figure_format = 'retina' <pre>Populating the interactive namespace from numpy and matplotlib\n</pre> In\u00a0[3]: Copied! <pre>from lcls_live.bmad import LCLSTaoModel\nfrom lcls_live.epics import epics_proxy\n\nimport os\n</pre> from lcls_live.bmad import LCLSTaoModel from lcls_live.epics import epics_proxy  import os  In\u00a0[4]: Copied! <pre># Make sure this exists\nassert 'LCLS_CLASSIC_LATTICE' in os.environ\n</pre> # Make sure this exists assert 'LCLS_CLASSIC_LATTICE' in os.environ In\u00a0[5]: Copied! <pre># Cached EPICS pv data\nSNAPSHOT = 'data/epics_snapshot_2018-03-06T15:21:15.000000-08:00.json'\n\nepics = epics_proxy(SNAPSHOT, verbose=True)\n</pre> # Cached EPICS pv data SNAPSHOT = 'data/epics_snapshot_2018-03-06T15:21:15.000000-08:00.json'  epics = epics_proxy(SNAPSHOT, verbose=True) <pre>Loaded data/epics_snapshot_2018-03-06T15:21:15.000000-08:00.json with 2068 PVs\n</pre> In\u00a0[6]: Copied! <pre>M = LCLSTaoModel('lcls_classic', epics = epics ,verbose=True, ploton=True)\nprint(M)\n</pre> M = LCLSTaoModel('lcls_classic', epics = epics ,verbose=True, ploton=True) print(M) <pre>Initialized Tao with /var/folders/wj/lfgr01993dx79p9cm_skykbw0000gn/T/tmpxv7uebcy/tao/tao.init\nLoading all settings\nReading: settings/klystron_settings.bmad\nWritten: /var/folders/wj/lfgr01993dx79p9cm_skykbw0000gn/T/tmpxv7uebcy/tao/settings/klystron_settings.bmad\nReading: settings/linac_settings.bmad\nWritten: /var/folders/wj/lfgr01993dx79p9cm_skykbw0000gn/T/tmpxv7uebcy/tao/settings/linac_settings.bmad\nWritten: /var/folders/wj/lfgr01993dx79p9cm_skykbw0000gn/T/tmpxv7uebcy/tao/settings/coll_settings.bmad\nCalling: settings/LEM_settings.tao\nWritten: /var/folders/wj/lfgr01993dx79p9cm_skykbw0000gn/T/tmpxv7uebcy/tao/settings/LEM_settings.tao\noffsetting bunch compressors\ncall /var/folders/wj/lfgr01993dx79p9cm_skykbw0000gn/T/tmpxv7uebcy/tao/scripts/BC_offsets.tao\nLEMing\ncall /var/folders/wj/lfgr01993dx79p9cm_skykbw0000gn/T/tmpxv7uebcy/tao/scripts/LEM.tao\nConfigured.\n_______________________________________________\n_______________________________________________\nLCLS Copper Linac EPICS info\n\nBunch charge off cathode:  250.8 pC\nVCC offset x, y:   -0.5,    0.5 mm\nLaser heater energy      39.12 \u03bcJ =&gt;  44.72 keV rms energy spread\nBunch charge in LTU:           178.1 pC\nBC1 mean current:              220.7 A\nBC2 peak current:             4510.4 A\n\nLinac    Energy (MeV)      Phase (deg)    fudge (%)\nL1       238.842        -26.12        99.17\nL1X       220.039        -160.0\nL2       5000.08        -31.77        101.9\nL3       14429.0          -8.0        104.0\n\nFEL Pulse energy :                2.1 mJ\n_______________________________________________\n</pre> In\u00a0[7]: Copied! <pre>%%tao\nplace floor beta_compare\nset lattice base = model\n</pre> %%tao place floor beta_compare set lattice base = model <pre>-------------------------\nTao&gt; place floor beta_compare\n-------------------------\nTao&gt; set lattice base = model\n-------------------------\nTao&gt; \n</pre> In\u00a0[8]: Copied! <pre># Optional.\n# For archiver, if off-site\n\n# Open an SSH tunnel in a terminal like:\n# ssh -D 8080 &lt;SLAC username&gt;@&lt;SLAC machine&gt;\n# And then set:\nif False:\n    os.environ['http_proxy']='socks5h://localhost:8080'\n    os.environ['HTTPS_PROXY']='socks5h://localhost:8080'\n    os.environ['ALL_PROXY']='socks5h://localhost:8080'\n    \n    # Restore from some other time\n    #M.archiver_restore('2018-11-06T11:22:45.000000-08:00')\n    M.archiver_restore('2018-03-06T14:21:29.000000-08:00')\n</pre> # Optional. # For archiver, if off-site  # Open an SSH tunnel in a terminal like: # ssh -D 8080 @ # And then set: if False:     os.environ['http_proxy']='socks5h://localhost:8080'     os.environ['HTTPS_PROXY']='socks5h://localhost:8080'     os.environ['ALL_PROXY']='socks5h://localhost:8080'          # Restore from some other time     #M.archiver_restore('2018-11-06T11:22:45.000000-08:00')     M.archiver_restore('2018-03-06T14:21:29.000000-08:00') In\u00a0[9]: Copied! <pre>%%tao\nset beam_init beam_track_end = UNDSTART\nset csr_param n_bin = 40\nsnparticle 10000\nset bmad_com csr_and_space_charge_on = T\nset csr_param ds_track_step = 0.01\nset ele BC1BEG:BC1END CSR_METHOD = 1_dim\nset ele BC2BEG:BC2END CSR_METHOD = 1_dim\nbeamon\nbeamoff\n</pre> %%tao set beam_init beam_track_end = UNDSTART set csr_param n_bin = 40 snparticle 10000 set bmad_com csr_and_space_charge_on = T set csr_param ds_track_step = 0.01 set ele BC1BEG:BC1END CSR_METHOD = 1_dim set ele BC2BEG:BC2END CSR_METHOD = 1_dim beamon beamoff <pre>-------------------------\nTao&gt; set beam_init beam_track_end = UNDSTART\n-------------------------\nTao&gt; set csr_param n_bin = 40\n-------------------------\nTao&gt; snparticle 10000\n-------------------------\nTao&gt; set bmad_com csr_and_space_charge_on = T\n-------------------------\nTao&gt; set csr_param ds_track_step = 0.01\n-------------------------\nTao&gt; set ele BC1BEG:BC1END CSR_METHOD = 1_dim\n[INFO] tao_set_elements_cmd:\n    Set successful for 26 elements out of 29\n-------------------------\nTao&gt; set ele BC2BEG:BC2END CSR_METHOD = 1_dim\n[INFO] tao_set_elements_cmd:\n    Set successful for 25 elements out of 28\n-------------------------\nTao&gt; beamon\n2206 particle(s) lost at element 280: CE11  Total lost: 2206  of 10000\nTotal number of lost particles by the end of universe  1:  2206.\n-------------------------\nTao&gt; beamoff\n-------------------------\nTao&gt; \n</pre> In\u00a0[10]: Copied! <pre>from pmd_beamphysics import ParticleGroup\n</pre> from pmd_beamphysics import ParticleGroup In\u00a0[11]: Copied! <pre>P = ParticleGroup(data=M.bunch_data('BC2FIN'))\nPalive = P.where(P['status'] == 1)\nPdead = P.where(P['status'] != 1)\nPalive.plot('delta_t', 'delta_pz', bins=100)\nif len(Pdead) &gt;0:\n    print(Pdead)\n</pre> P = ParticleGroup(data=M.bunch_data('BC2FIN')) Palive = P.where(P['status'] == 1) Pdead = P.where(P['status'] != 1) Palive.plot('delta_t', 'delta_pz', bins=100) if len(Pdead) &gt;0:     print(Pdead) <pre>ParticleGroup with 2206 particles with total charge 5.514999999997761e-11 C\n</pre> In\u00a0[12]: Copied! <pre>from lcls_live.bmad.classic.evaluate import run_LCLSTao, evaluate_LCLSTao\n</pre> from lcls_live.bmad.classic.evaluate import run_LCLSTao, evaluate_LCLSTao In\u00a0[13]: Copied! <pre>settings00 = {\n   # 'ele:O_BC1:angle_deg':-5.12345,\n   # 'ele:O_BC2:angle_deg':-2.0,\n   # 'ele:O_L1:phase_deg':-25.1,\n   # 'ele:O_L2:phase_deg':-41.4,\n   # 'ele:O_L3:phase_deg':0.0,\n   # 'ele:O_L1_fudge:f': 1.0,\n   # 'ele:O_L2_fudge:f': 1.0,\n   # 'ele:O_L3_fudge:f': 1.0,\n    'ele:CE11:x1_limit': 2.5e-3,  # Basic 'horn cutting'\n    'ele:CE11:x2_limit': 4.0e-3,\n    'csr_param:n_bin':40,\n    'csr_param:ds_track_step':0.01,\n    'beam_init:n_particle': 10000,\n    'beam:beam_saved_at':'CE11, UNDSTART',\n    'beam:beam_track_end':'UNDSTART',\n    'bmad_com:csr_and_space_charge_on':True,\n    'ele:BC1BEG:BC1END:CSR_METHOD': '1_Dim',\n    'ele:BC2BEG:BC2END:CSR_METHOD': '1_Dim'\n}\n\nM = run_LCLSTao(settings=settings00, model_name='lcls_classic', verbose=True)\n</pre> settings00 = {    # 'ele:O_BC1:angle_deg':-5.12345,    # 'ele:O_BC2:angle_deg':-2.0,    # 'ele:O_L1:phase_deg':-25.1,    # 'ele:O_L2:phase_deg':-41.4,    # 'ele:O_L3:phase_deg':0.0,    # 'ele:O_L1_fudge:f': 1.0,    # 'ele:O_L2_fudge:f': 1.0,    # 'ele:O_L3_fudge:f': 1.0,     'ele:CE11:x1_limit': 2.5e-3,  # Basic 'horn cutting'     'ele:CE11:x2_limit': 4.0e-3,     'csr_param:n_bin':40,     'csr_param:ds_track_step':0.01,     'beam_init:n_particle': 10000,     'beam:beam_saved_at':'CE11, UNDSTART',     'beam:beam_track_end':'UNDSTART',     'bmad_com:csr_and_space_charge_on':True,     'ele:BC1BEG:BC1END:CSR_METHOD': '1_Dim',     'ele:BC2BEG:BC2END:CSR_METHOD': '1_Dim' }  M = run_LCLSTao(settings=settings00, model_name='lcls_classic', verbose=True) <pre>Initialized Tao with /var/folders/wj/lfgr01993dx79p9cm_skykbw0000gn/T/tmplz_l628j/tao/tao.init\nConfigured.\nset global lattice_calc_on = F\nset ele CE11 x1_limit = 0.0025\nset ele CE11 x2_limit = 0.004\nset csr_param  n_bin = 40\nset csr_param  ds_track_step = 0.01\nset beam_init  n_particle = 10000\nset beam  beam_saved_at = CE11, UNDSTART\nset beam  beam_track_end = UNDSTART\nset bmad_com  csr_and_space_charge_on = True\nset ele BC1BEG:BC1END CSR_METHOD = 1_Dim\nset ele BC2BEG:BC2END CSR_METHOD = 1_Dim\nset global lattice_calc_on = T\n</pre> <p>Because Tao runs as a library in global space, you can patch in commands:</p> In\u00a0[14]: Copied! <pre>%%tao\nbeamoff\nset global plot_on = True \nplace floor zphase\nszpz undstart\nx-s floor -.055 -0.02\nsc\n</pre> %%tao beamoff set global plot_on = True  place floor zphase szpz undstart x-s floor -.055 -0.02 sc <pre>-------------------------\nTao&gt; beamoff\n-------------------------\nTao&gt; set global plot_on = True \n-------------------------\nTao&gt; place floor zphase\n[ABORT | 2021-JUN-04 14:33:02] tao_graph_phase_space_setup:\n    NO BEAM AT ELEMENT: BEGINNING\n    CANNOT DO PHASE_SPACE PLOTTING FOR CURVE: zphase.z.c1\n-------------------------\nTao&gt; szpz undstart\n-------------------------\nTao&gt; x-s floor -.055 -0.02\n-------------------------\nTao&gt; sc\n-------------------------\nTao&gt; \n</pre> In\u00a0[15]: Copied! <pre># This will run the model, and return a dict with values from the following expressions\nexpressions = [\n    'lat::orbit.x[end]',\n    'beam::n_particle_loss[end]'    \n]\nres = evaluate_LCLSTao(settings=settings00, \n               #  epics_json='data/epics_snapshot_2018-03-06T11:22:45.000000-08:00.json',\n                 expressions=expressions,\n                 beam_archive_path = '.'\n                )\nres\n</pre> # This will run the model, and return a dict with values from the following expressions expressions = [     'lat::orbit.x[end]',     'beam::n_particle_loss[end]'     ] res = evaluate_LCLSTao(settings=settings00,                 #  epics_json='data/epics_snapshot_2018-03-06T11:22:45.000000-08:00.json',                  expressions=expressions,                  beam_archive_path = '.'                 ) res Out[15]: <pre>{'lat::orbit.x[end]': array([1.30823192e-17]),\n 'beam::n_particle_loss[end]': array([2438.]),\n 'beam_archive': '/Users/chrisonian/Code/GitHub/lcls-live/examples/classic/bmad_beam_482e3bbb788185985ec2348c7ea21059.h5'}</pre> In\u00a0[16]: Copied! <pre># Restore something from the archiver\nsettings00 = {\n    'csr_param:n_bin':40,\n    'csr_param:ds_track_step':0.01,\n    'beam_init:n_particle': 10000,\n    'beam:beam_saved_at':'CE11, UNDSTART',\n    'beam:beam_track_end':'UNDSTART',\n    'bmad_com:csr_and_space_charge_on':True,\n    'ele:BC1BEG:BC1END:CSR_METHOD': '1_Dim',\n    'ele:BC2BEG:BC2END:CSR_METHOD': '1_Dim'\n}\n\n\nres2 = evaluate_LCLSTao(settings=settings00, \n                 epics_json='data/epics_snapshot_2018-03-06T11:22:45.000000-08:00.json',\n                 expressions=expressions,\n                 beam_archive_path = '.'\n                )\nres2\n</pre> # Restore something from the archiver settings00 = {     'csr_param:n_bin':40,     'csr_param:ds_track_step':0.01,     'beam_init:n_particle': 10000,     'beam:beam_saved_at':'CE11, UNDSTART',     'beam:beam_track_end':'UNDSTART',     'bmad_com:csr_and_space_charge_on':True,     'ele:BC1BEG:BC1END:CSR_METHOD': '1_Dim',     'ele:BC2BEG:BC2END:CSR_METHOD': '1_Dim' }   res2 = evaluate_LCLSTao(settings=settings00,                   epics_json='data/epics_snapshot_2018-03-06T11:22:45.000000-08:00.json',                  expressions=expressions,                  beam_archive_path = '.'                 ) res2 <pre>Written: /var/folders/wj/lfgr01993dx79p9cm_skykbw0000gn/T/tmp415insqv/tao/settings/coll_settings.bmad\n</pre> Out[16]: <pre>{'lat::orbit.x[end]': array([3.17398106e-17]),\n 'beam::n_particle_loss[end]': array([2386.]),\n 'beam_archive': '/Users/chrisonian/Code/GitHub/lcls-live/examples/classic/bmad_beam_f1a19a6e56f51b4c768081c9a5d82b66.h5'}</pre> In\u00a0[17]: Copied! <pre>from pmd_beamphysics import particle_paths\nimport h5py\n</pre> from pmd_beamphysics import particle_paths import h5py In\u00a0[18]: Copied! <pre>afile = res['beam_archive']\nh5 = h5py.File(afile, 'r')\nppaths = particle_paths(h5)\nppaths\n</pre> afile = res['beam_archive'] h5 = h5py.File(afile, 'r') ppaths = particle_paths(h5) ppaths  Out[18]: <pre>['/data/00001/particles/', '/data/00002/particles/', '/data/00003/particles/']</pre> In\u00a0[19]: Copied! <pre>P = ParticleGroup(h5[ppaths[-1]])\n\nPalive = P.where(P['status'] == 1)\nPdead = P.where(P['status'] != 1)\nPalive.plot('delta_t', 'delta_pz', bins=100)\n# These particles were lost (probably due to collimation)\nPdead \n</pre> P = ParticleGroup(h5[ppaths[-1]])  Palive = P.where(P['status'] == 1) Pdead = P.where(P['status'] != 1) Palive.plot('delta_t', 'delta_pz', bins=100) # These particles were lost (probably due to collimation) Pdead  Out[19]: <pre>&lt;ParticleGroup with 2438 particles at 0x1663632e0&gt;</pre> In\u00a0[20]: Copied! <pre># Cleanup\nos.remove(res['beam_archive'])\nos.remove(res2['beam_archive'])\n</pre> # Cleanup os.remove(res['beam_archive']) os.remove(res2['beam_archive']) In\u00a0[21]: Copied! <pre>res2\n</pre> res2 Out[21]: <pre>{'lat::orbit.x[end]': array([3.17398106e-17]),\n 'beam::n_particle_loss[end]': array([2386.]),\n 'beam_archive': '/Users/chrisonian/Code/GitHub/lcls-live/examples/classic/bmad_beam_f1a19a6e56f51b4c768081c9a5d82b66.h5'}</pre>"},{"location":"examples/classic/LCLS_Classic_Model/#lcls-classic-model","title":"LCLS Classic model\u00b6","text":""},{"location":"examples/classic/LCLS_Classic_Model/#get-snapshot","title":"Get snapshot\u00b6","text":""},{"location":"examples/classic/LCLS_Classic_Model/#archiver-restore","title":"Archiver restore\u00b6","text":""},{"location":"examples/classic/LCLS_Classic_Model/#track-particles-with-csr","title":"Track particles with CSR\u00b6","text":""},{"location":"examples/classic/LCLS_Classic_Model/#plot","title":"Plot\u00b6","text":""},{"location":"examples/classic/LCLS_Classic_Model/#functional-usage","title":"Functional usage\u00b6","text":""},{"location":"examples/classic/LCLS_Classic_Model/#plot","title":"Plot\u00b6","text":""},{"location":"examples/classic/LCLS_Model/","title":"LCLS Model","text":"In\u00a0[1]: Copied! <pre># Useful for debugging\n%load_ext autoreload\n%autoreload 2\n\n%config InlineBackend.figure_format = 'retina'\n</pre> # Useful for debugging %load_ext autoreload %autoreload 2  %config InlineBackend.figure_format = 'retina' In\u00a0[2]: Copied! <pre># Cached EPICS pv data\n#epics = epics_proxy('data/epics_snapshot_2018-03-06T11:22:45.000000-08:00.json', verbose=True)\n</pre> # Cached EPICS pv data #epics = epics_proxy('data/epics_snapshot_2018-03-06T11:22:45.000000-08:00.json', verbose=True) In\u00a0[3]: Copied! <pre>from lcls_live.bmad import LCLSTaoModel\nfrom lcls_live.epics import epics_proxy\nimport os\n</pre> from lcls_live.bmad import LCLSTaoModel from lcls_live.epics import epics_proxy import os In\u00a0[4]: Copied! <pre># Make sure this exists\nassert 'LCLS_LATTICE' in os.environ\n</pre> # Make sure this exists assert 'LCLS_LATTICE' in os.environ In\u00a0[5]: Copied! <pre>M = LCLSTaoModel('cu_hxr', epics = None, verbose=True, ploton=True)\nprint(M)\n</pre> M = LCLSTaoModel('cu_hxr', epics = None, verbose=True, ploton=True) print(M) <pre>Initialized Tao with /var/folders/wj/lfgr01993dx79p9cm_skykbw0000gn/T/tmpqsnksklg/tao/tao.init\nConfigured.\nTODO: epics hooks for cu_hxr\n</pre> In\u00a0[6]: Copied! <pre>%%tao \nsho var linac_fudge\n</pre> %%tao  sho var linac_fudge <pre>-------------------------\nTao&gt; sho var linac_fudge\n  Variable                   Slave Parameters           Meas         Model        Design  Useit_opt\n  linac_fudge[1]             O_L1_FUDGE[F]          0.0000E+00    1.0000E+00    1.0000E+00       F\n  linac_fudge[2]             O_L2_FUDGE[F]          0.0000E+00    1.0000E+00    1.0000E+00       F\n  linac_fudge[3]             O_L3_FUDGE[F]          0.0000E+00    1.0000E+00    1.0000E+00       F\n  Variable                   Slave Parameters           Meas         Model        Design  Useit_opt\n-------------------------\nTao&gt; \n</pre> In\u00a0[7]: Copied! <pre>%%tao\nset beam_init beam_track_end = UEEND\nset csr_param n_bin = 40\nsnparticle 10000\nbeamon\nbeamoff\n</pre> %%tao set beam_init beam_track_end = UEEND set csr_param n_bin = 40 snparticle 10000 beamon beamoff <pre>-------------------------\nTao&gt; set beam_init beam_track_end = UEEND\n-------------------------\nTao&gt; set csr_param n_bin = 40\n-------------------------\nTao&gt; snparticle 10000\n-------------------------\nTao&gt; beamon\n-------------------------\nTao&gt; beamoff\n-------------------------\nTao&gt; \n</pre> In\u00a0[8]: Copied! <pre>%%tao\nplace floor emittancexy\nx-a all s\nsc\n</pre> %%tao place floor emittancexy x-a all s sc <pre>-------------------------\nTao&gt; place floor emittancexy\n-------------------------\nTao&gt; x-a all s\n-------------------------\nTao&gt; sc\n-------------------------\nTao&gt; \n</pre> In\u00a0[9]: Copied! <pre>from pmd_beamphysics import ParticleGroup\n</pre> from pmd_beamphysics import ParticleGroup In\u00a0[10]: Copied! <pre>P1 = ParticleGroup(data=M.bunch_data('UEBEG'))\nP1.plot('delta_t', 'delta_p', figsize=(6,6))\n</pre> P1 = ParticleGroup(data=M.bunch_data('UEBEG')) P1.plot('delta_t', 'delta_p', figsize=(6,6)) In\u00a0[11]: Copied! <pre>P1 = ParticleGroup(data=M.bunch_data('UEEND'))\nP1.plot('delta_t', 'delta_p', figsize=(6,6))\n</pre> P1 = ParticleGroup(data=M.bunch_data('UEEND')) P1.plot('delta_t', 'delta_p', figsize=(6,6))"},{"location":"examples/classic/LCLS_Model/#lcls-cu_hxr-model","title":"LCLS <code>cu_hxr</code> Model\u00b6","text":""},{"location":"examples/classic/LCLS_Model/#track-particles","title":"Track particles\u00b6","text":""},{"location":"examples/classic/LCLS_Model/#plot","title":"Plot\u00b6","text":""},{"location":"examples/classic/bmad_examples/","title":"Bmad examples","text":"In\u00a0[1]: Copied! <pre># Useful for debugging\n%load_ext autoreload\n%autoreload 2\n</pre> # Useful for debugging %load_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>from lcls_live.bmad.classic.tools import bmad_klystron_lines, write_bmad_klystron_settings, bmad_linac_phasing_lines, write_bmad_linac_phasing_lines, tao_BC_and_LEM_lines, write_tao_BC_and_LEM_lines\n#from lcls_live.bmad.classic.tools import bmad_collimator_lines\nfrom lcls_live.klystron import Klystron, existing_LCLS_klystrons\nfrom lcls_live.epics import epics_proxy\nimport json\nimport os\n</pre> from lcls_live.bmad.classic.tools import bmad_klystron_lines, write_bmad_klystron_settings, bmad_linac_phasing_lines, write_bmad_linac_phasing_lines, tao_BC_and_LEM_lines, write_tao_BC_and_LEM_lines #from lcls_live.bmad.classic.tools import bmad_collimator_lines from lcls_live.klystron import Klystron, existing_LCLS_klystrons from lcls_live.epics import epics_proxy import json import os In\u00a0[3]: Copied! <pre># Proxy setup\nepics = epics_proxy('data/epics_snapshot_2018-03-06T15:21:15.000000-08:00.json', verbose=True)\n</pre> # Proxy setup epics = epics_proxy('data/epics_snapshot_2018-03-06T15:21:15.000000-08:00.json', verbose=True) <pre>Loaded data/epics_snapshot_2018-03-06T15:21:15.000000-08:00.json with 2068 PVs\n</pre> In\u00a0[4]: Copied! <pre># List of Klystron objects\nklist = existing_LCLS_klystrons(epics)\n</pre> # List of Klystron objects klist = existing_LCLS_klystrons(epics) In\u00a0[5]: Copied! <pre># Bmad lines for one klystron\nbmad_klystron_lines(klist[10])\n</pre> # Bmad lines for one klystron bmad_klystron_lines(klist[10]) Out[5]: <pre>['!---------------',\n '! K22_3',\n 'O_K22_3[ENLD_MeV] = 210.644',\n 'O_K22_3[phase_deg] = -0.0376129150390625']</pre> In\u00a0[6]: Copied! <pre>write_bmad_klystron_settings(klist, filePath='klystron_settings.bmad', verbose=True)\n</pre> write_bmad_klystron_settings(klist, filePath='klystron_settings.bmad', verbose=True) <pre>Written: klystron_settings.bmad\n</pre> In\u00a0[7]: Copied! <pre>bmad_linac_phasing_lines(epics)\n</pre> bmad_linac_phasing_lines(epics) Out[7]: <pre>['! Linac overall phasing',\n 'O_L1[phase_deg] = 0 ! K21_1 sets this directly. This is a delta on top of that.',\n 'O_L2[phase_deg] = -31.773465756544063',\n 'O_L3[phase_deg] = -8.0']</pre> In\u00a0[8]: Copied! <pre>write_bmad_linac_phasing_lines(filePath='linac_settings.bmad', epics=epics, verbose=True)\n</pre> write_bmad_linac_phasing_lines(filePath='linac_settings.bmad', epics=epics, verbose=True) <pre>Written: linac_settings.bmad\n</pre> In\u00a0[9]: Copied! <pre># Cleanup\nos.remove('klystron_settings.bmad')\nos.remove('linac_settings.bmad')\n</pre> # Cleanup os.remove('klystron_settings.bmad') os.remove('linac_settings.bmad') In\u00a0[10]: Copied! <pre>tao_BC_and_LEM_lines(epics)\n</pre> tao_BC_and_LEM_lines(epics) Out[10]: <pre>['set dat BC1.energy[1]|meas = 220038515.89541337',\n 'set dat BC2.energy[1]|meas = 5000084964.69758',\n 'set dat L3.energy[2]|meas = 14429000000.0',\n 'set dat BC1.offset[1]|meas = 0.24763859750636236',\n 'set dat BC2.offset[1]|meas = 0.38501205883567324',\n '! Charge after horn cutting:      178.1 pC',\n '! For BC1 current 220.6596353167397 A',\n 'set dat BC1.beam[1]|meas = 7.651311099276582e-05',\n '! For BC2 current 4510.379420893232 A',\n 'set dat BC2.beam[1]|meas = 3.4170792924812643e-06']</pre> In\u00a0[11]: Copied! <pre>write_tao_BC_and_LEM_lines(filePath='set_LEM_energies.tao', epics=epics, verbose=True)\n</pre> write_tao_BC_and_LEM_lines(filePath='set_LEM_energies.tao', epics=epics, verbose=True) <pre>Written: set_LEM_energies.tao\n</pre> Out[11]: <pre>['set dat BC1.energy[1]|meas = 220038515.89541337',\n 'set dat BC2.energy[1]|meas = 5000084964.69758',\n 'set dat L3.energy[2]|meas = 14429000000.0',\n 'set dat BC1.offset[1]|meas = 0.24763859750636236',\n 'set dat BC2.offset[1]|meas = 0.38501205883567324',\n '! Charge after horn cutting:      178.1 pC',\n '! For BC1 current 220.6596353167397 A',\n 'set dat BC1.beam[1]|meas = 7.651311099276582e-05',\n '! For BC2 current 4510.379420893232 A',\n 'set dat BC2.beam[1]|meas = 3.4170792924812643e-06']</pre> In\u00a0[12]: Copied! <pre># cleanup\nos.remove('set_LEM_energies.tao')\n</pre> # cleanup os.remove('set_LEM_energies.tao') In\u00a0[13]: Copied! <pre>#bmad_collimator_lines(epics)\n</pre> #bmad_collimator_lines(epics) In\u00a0[14]: Copied! <pre>madnames = json.load(open('data/madname_pvs.json'))\n</pre> madnames = json.load(open('data/madname_pvs.json'))"},{"location":"examples/classic/bmad_examples/#bmad-examples","title":"Bmad examples\u00b6","text":""},{"location":"examples/classic/bmad_examples/#linac","title":"Linac\u00b6","text":""},{"location":"examples/classic/bmad_examples/#tao-lem-and-bunch-compressor-settings","title":"Tao LEM and Bunch Compressor settings\u00b6","text":""},{"location":"examples/classic/bmad_examples/#collimators","title":"Collimators\u00b6","text":""},{"location":"examples/classic/bmad_examples/#quads","title":"Quads\u00b6","text":""},{"location":"examples/classic/csv_data_examples/","title":"LCLS data","text":"In\u00a0[1]: Copied! <pre>from lcls_live import data_dir \n\nimport pandas\n\nimport os\n</pre> from lcls_live import data_dir   import pandas  import os In\u00a0[2]: Copied! <pre># data_dir is kept within the lcls2-live package. Its contents:\nos.listdir(data_dir)\n</pre> # data_dir is kept within the lcls2-live package. Its contents: os.listdir(data_dir) Out[2]: <pre>['cu_sxr', 'datamaps_master.json', 'classic', 'cu', 'cu_hxr', 'cu_inj', 'eic']</pre> In\u00a0[3]: Copied! <pre>csvfile=os.path.join(data_dir, 'classic/cor_mapping.csv')\n\npandas.read_csv(csvfile)\n</pre> csvfile=os.path.join(data_dir, 'classic/cor_mapping.csv')  pandas.read_csv(csvfile) Out[3]: device_name attribute unit bmad_ele_name bmad_factor bmad_attribute example_value 0 XCOR:IN20:121 BDES kG-m XC00 -1/10.0 bl_hkick 0 1 YCOR:IN20:122 BDES kG-m YC00 -1/10.0 bl_vkick 0 2 XCOR:IN20:221 BDES kG-m XC01 -1/10.0 bl_hkick 0 3 YCOR:IN20:222 BDES kG-m YC01 -1/10.0 bl_vkick 0 4 XCOR:IN20:311 BDES kG-m XC02 -1/10.0 bl_hkick 0 ... ... ... ... ... ... ... ... 303 YCOR:DMP1:298 BDES kG-m YCUE2 -1/10.0 bl_vkick 0 304 YCOR:DMP1:391 BDES kG-m YCD3 -1/10.0 bl_vkick 0 305 XCOR:DMP1:392 BDES kG-m XCD3 -1/10.0 bl_hkick 0 306 YCOR:DMP1:440 BDES kG-m YCDD -1/10.0 bl_vkick 0 307 XCOR:DMP1:602 BDES kG-m XCDD -1/10.0 bl_hkick 0 <p>308 rows \u00d7 7 columns</p> In\u00a0[4]: Copied! <pre>from lcls_live.bmad.classic.tools import bmad_from_csv\nfrom lcls_live.epics import epics_proxy\n</pre> from lcls_live.bmad.classic.tools import bmad_from_csv from lcls_live.epics import epics_proxy In\u00a0[5]: Copied! <pre>epics = epics_proxy('data/epics_snapshot_2018-03-06T11:22:45.000000-08:00.json')\n</pre> epics = epics_proxy('data/epics_snapshot_2018-03-06T11:22:45.000000-08:00.json') In\u00a0[6]: Copied! <pre>?bmad_from_csv\n</pre> ?bmad_from_csv <pre>Signature: bmad_from_csv(csvfile, epics, outfile=None)\nDocstring:\nCreate Bmad-style settings from a CSV mapping file, and an epics interface.\n\nExample: \n    bmad_from_csv('collimator_mapping.csv', epics, 'test.bmad')\n    \nFile:      ~/Code/GitHub/lcls-live/lcls_live/bmad/classic/tools.py\nType:      function\n</pre> In\u00a0[7]: Copied! <pre># Make bmad lines. Optionally give an output file\nbmad_from_csv(os.path.join(data_dir, 'classic/cor_mapping.csv'), epics, outfile='test.bmad')\n</pre> # Make bmad lines. Optionally give an output file bmad_from_csv(os.path.join(data_dir, 'classic/cor_mapping.csv'), epics, outfile='test.bmad') <pre>Written: test.bmad\n</pre> Out[7]: <pre>['XC00[bl_hkick] = -1/10.0*-0.00059694199',\n 'YC00[bl_vkick] = -1/10.0*-0.00075944',\n 'XC01[bl_hkick] = -1/10.0*-0.0006258966851055385',\n 'YC01[bl_vkick] = -1/10.0*0.0004835578197856088',\n 'XC02[bl_hkick] = -1/10.0*-0.00046577',\n 'YC02[bl_vkick] = -1/10.0*0.00031641',\n 'XC03[bl_hkick] = -1/10.0*0.0',\n 'YC03[bl_vkick] = -1/10.0*-5.2102e-08',\n 'XC04[bl_hkick] = -1/10.0*-0.00071736',\n 'YC04[bl_vkick] = -1/10.0*0.00047232',\n 'XC05[bl_hkick] = -1/10.0*0.0025873',\n 'YC05[bl_vkick] = -1/10.0*-0.00058456',\n 'XC06[bl_hkick] = -1/10.0*0.002105',\n 'YC06[bl_vkick] = -1/10.0*0.002421',\n 'XC07[bl_hkick] = -1/10.0*-0.0003813',\n 'YC07[bl_vkick] = -1/10.0*-0.0016075',\n 'XC08[bl_hkick] = -1/10.0*0.00120816',\n 'YC08[bl_vkick] = -1/10.0*-0.00447',\n 'XC09[bl_hkick] = -1/10.0*0.00586',\n 'YC09[bl_vkick] = -1/10.0*0.001008',\n 'XC10[bl_hkick] = -1/10.0*-0.0024667508',\n 'YC10[bl_vkick] = -1/10.0*0.00056825018',\n 'XC11[bl_hkick] = -1/10.0*0.006455684161086112',\n 'YC11[bl_vkick] = -1/10.0*0.0029842686',\n 'XCA11[bl_hkick] = -1/10.0*-0.0043394915',\n 'YCA11[bl_vkick] = -1/10.0*-0.0020313103919078687',\n 'XCA12[bl_hkick] = -1/10.0*0.00076987445',\n 'YCA12[bl_vkick] = -1/10.0*-0.00062872968',\n 'YC21203[bl_vkick] = -1/10.0*0.0023187129',\n 'XC21202[bl_hkick] = -1/10.0*0.0072416311',\n 'XCM11[bl_hkick] = -1/10.0*0.00061854188',\n 'YCM11[bl_vkick] = -1/10.0*4.0740496e-05',\n 'XCM13[bl_hkick] = -1/10.0*0.0027668374183866455',\n 'YCM12[bl_vkick] = -1/10.0*0.00021708498472992673',\n 'XC21302[bl_hkick] = -1/10.0*0.0014239155949128503',\n 'YC21303[bl_vkick] = -1/10.0*-0.00652163507997823',\n 'XCM14[bl_hkick] = -1/10.0*-0.00012912',\n 'YCM15[bl_vkick] = -1/10.0*0.004193',\n 'XC21402[bl_hkick] = -1/10.0*0.0007367623020338048',\n 'YC21403[bl_vkick] = -1/10.0*-0.002655702606804092',\n 'XC21502[bl_hkick] = -1/10.0*0.0009810745955049626',\n 'YC21503[bl_vkick] = -1/10.0*0.0009470111996360641',\n 'XC21602[bl_hkick] = -1/10.0*0.0011446511249190968',\n 'YC21603[bl_vkick] = -1/10.0*-0.00011049409674953917',\n 'XC21702[bl_hkick] = -1/10.0*4.6826547387984083e-05',\n 'YC21703[bl_vkick] = -1/10.0*-0.0002142324265136712',\n 'XC21802[bl_hkick] = -1/10.0*0.0033042194597294326',\n 'YC21803[bl_vkick] = -1/10.0*0.0011319485743219466',\n 'XC21900[bl_hkick] = -1/10.0*-0.005232068174437173',\n 'YC21900[bl_vkick] = -1/10.0*-0.0011351825760391302',\n 'XC22202[bl_hkick] = -1/10.0*0.0004537031210900945',\n 'YC22203[bl_vkick] = -1/10.0*0.0001617178649652875',\n 'XC22302[bl_hkick] = -1/10.0*0.0',\n 'YC22303[bl_vkick] = -1/10.0*2.5012885715308493e-05',\n 'XC22402[bl_hkick] = -1/10.0*0.0021271967190123944',\n 'YC22403[bl_vkick] = -1/10.0*0.0',\n 'XC22502[bl_hkick] = -1/10.0*0.0',\n 'YC22503[bl_vkick] = -1/10.0*0.0014328917819096182',\n 'XC22602[bl_hkick] = -1/10.0*0.002792137182742852',\n 'YC22603[bl_vkick] = -1/10.0*0.0',\n 'XC22702[bl_hkick] = -1/10.0*0.0',\n 'YC22703[bl_vkick] = -1/10.0*-0.0007514539404314284',\n 'XC22802[bl_hkick] = -1/10.0*0.001825068747292168',\n 'YC22803[bl_vkick] = -1/10.0*0.0018934471316730667',\n 'XC22900[bl_hkick] = -1/10.0*0.0',\n 'YC22900[bl_vkick] = -1/10.0*0.0015668137344436095',\n 'XC23202[bl_hkick] = -1/10.0*-0.006613951946525511',\n 'YC23203[bl_vkick] = -1/10.0*0.0',\n 'XC23302[bl_hkick] = -1/10.0*1.2973521999506565e-19',\n 'YC23303[bl_vkick] = -1/10.0*-0.00026351712439917364',\n 'XC23402[bl_hkick] = -1/10.0*0.007296399116616583',\n 'YC23403[bl_vkick] = -1/10.0*0.0',\n 'XC23502[bl_hkick] = -1/10.0*0.0',\n 'YC23503[bl_vkick] = -1/10.0*0.0012191602693686627',\n 'XC23602[bl_hkick] = -1/10.0*-0.0026163279088533115',\n 'YC23603[bl_vkick] = -1/10.0*0.0',\n 'XC23702[bl_hkick] = -1/10.0*0.0',\n 'YC23703[bl_vkick] = -1/10.0*0.0001245268927856503',\n 'XC23802[bl_hkick] = -1/10.0*-0.0007723648507416341',\n 'YC23803[bl_vkick] = -1/10.0*0.0',\n 'XC23900[bl_hkick] = -1/10.0*0.0',\n 'YC23900[bl_vkick] = -1/10.0*0.002710348827878821',\n 'XC24202[bl_hkick] = -1/10.0*0.006386749998088966',\n 'YC24203[bl_vkick] = -1/10.0*0.0',\n 'XC24302[bl_hkick] = -1/10.0*-0.004453694822560144',\n 'YC24303[bl_vkick] = -1/10.0*-0.0014665522128015222',\n 'XC24402[bl_hkick] = -1/10.0*0.003173165147615027',\n 'YC24403[bl_vkick] = -1/10.0*0.0',\n 'XC24502[bl_hkick] = -1/10.0*-0.00381591624349128',\n 'YC24503[bl_vkick] = -1/10.0*0.00655203991291128',\n 'XC24602[bl_hkick] = -1/10.0*0.04500906490847499',\n 'YC24603[bl_vkick] = -1/10.0*0.0064460747213885665',\n 'XC24702[bl_hkick] = -1/10.0*0.018157176495835394',\n 'YC24703[bl_vkick] = -1/10.0*-0.006141808598518677',\n 'XC24900[bl_hkick] = -1/10.0*0.0255722',\n 'YC24900[bl_vkick] = -1/10.0*0.017085331037702288',\n 'XC25202[bl_hkick] = -1/10.0*0.01424277701568237',\n 'YC25203[bl_vkick] = -1/10.0*0.0',\n 'XC25302[bl_hkick] = -1/10.0*0.0',\n 'YC25303[bl_vkick] = -1/10.0*-0.0051291189',\n 'XC25402[bl_hkick] = -1/10.0*0.0028920028',\n 'YC25403[bl_vkick] = -1/10.0*0.0',\n 'XC25502[bl_hkick] = -1/10.0*0.0',\n 'YC25503[bl_vkick] = -1/10.0*0.008910775206614707',\n 'XC25602[bl_hkick] = -1/10.0*0.006436384743051886',\n 'YC25603[bl_vkick] = -1/10.0*0.0',\n 'XC25702[bl_hkick] = -1/10.0*-0.0038580508',\n 'YC25703[bl_vkick] = -1/10.0*0.00011757056',\n 'XC25802[bl_hkick] = -1/10.0*-0.0107167',\n 'YC25803[bl_vkick] = -1/10.0*-0.0',\n 'XC25900[bl_hkick] = -1/10.0*-0.0056056171',\n 'YC25900[bl_vkick] = -1/10.0*0.00031324079',\n 'XC26202[bl_hkick] = -1/10.0*0.0159185',\n 'YC26203[bl_vkick] = -1/10.0*0.0',\n 'XC26302[bl_hkick] = -1/10.0*0.0',\n 'YC26303[bl_vkick] = -1/10.0*0.0044062633',\n 'XC26402[bl_hkick] = -1/10.0*-0.0111868',\n 'YC26403[bl_vkick] = -1/10.0*0.0',\n 'XC26502[bl_hkick] = -1/10.0*0.0',\n 'YC26503[bl_vkick] = -1/10.0*-0.0126104',\n 'XC26602[bl_hkick] = -1/10.0*-0.0046320871',\n 'YC26603[bl_vkick] = -1/10.0*0.0',\n 'XC26702[bl_hkick] = -1/10.0*0.0',\n 'YC26703[bl_vkick] = -1/10.0*0.0010543063',\n 'XC26802[bl_hkick] = -1/10.0*-0.0081573028',\n 'YC26803[bl_vkick] = -1/10.0*0.0',\n 'XC26900[bl_hkick] = -1/10.0*0.0266851',\n 'YC26900[bl_vkick] = -1/10.0*0.0109912',\n 'XC27202[bl_hkick] = -1/10.0*-0.0078616847',\n 'YC27203[bl_vkick] = -1/10.0*-0.0',\n 'XC27302[bl_hkick] = -1/10.0*0.0',\n 'YC27303[bl_vkick] = -1/10.0*-0.00065888909',\n 'XC27402[bl_hkick] = -1/10.0*0.0061922502',\n 'YC27403[bl_vkick] = -1/10.0*0.0',\n 'XC27502[bl_hkick] = -1/10.0*0.0',\n 'YC27503[bl_vkick] = -1/10.0*-0.014271',\n 'XC27602[bl_hkick] = -1/10.0*0.002354393',\n 'YC27603[bl_vkick] = -1/10.0*0.0',\n 'XC27702[bl_hkick] = -1/10.0*0.0',\n 'YC27703[bl_vkick] = -1/10.0*0.0154816',\n 'XC27802[bl_hkick] = -1/10.0*-0.0186101',\n 'YC27803[bl_vkick] = -1/10.0*-0.0',\n 'XC27900[bl_hkick] = -1/10.0*0.0045506116',\n 'YC27900[bl_vkick] = -1/10.0*0.0004593517995656',\n 'XC28202[bl_hkick] = -1/10.0*0.006916180646155299',\n 'YC28203[bl_vkick] = -1/10.0*0.0',\n 'XC28302[bl_hkick] = -1/10.0*0.0',\n 'YC28303[bl_vkick] = -1/10.0*-0.0018744774',\n 'XC28402[bl_hkick] = -1/10.0*0.0077022442',\n 'YC28403[bl_vkick] = -1/10.0*0.0',\n 'XC28502[bl_hkick] = -1/10.0*0.0',\n 'YC28503[bl_vkick] = -1/10.0*-0.007396901837155208',\n 'XC28602[bl_hkick] = -1/10.0*-0.010496942678049648',\n 'YC28603[bl_vkick] = -1/10.0*0.0',\n 'XC28702[bl_hkick] = -1/10.0*0.0',\n 'YC28703[bl_vkick] = -1/10.0*-0.004456467',\n 'XC28802[bl_hkick] = -1/10.0*0.0254307',\n 'YC28803[bl_vkick] = -1/10.0*0.0',\n 'XC28900[bl_hkick] = -1/10.0*0.0',\n 'YC28900[bl_vkick] = -1/10.0*0.0034466254',\n 'XC29202[bl_hkick] = -1/10.0*-0.013082',\n 'YC29203[bl_vkick] = -1/10.0*0.0',\n 'XC29302[bl_hkick] = -1/10.0*0.0',\n 'YC29303[bl_vkick] = -1/10.0*-0.00088399166',\n 'XC29402[bl_hkick] = -1/10.0*0.0081804849',\n 'YC29403[bl_vkick] = -1/10.0*0.0',\n 'XC29502[bl_hkick] = -1/10.0*0.0',\n 'YC29503[bl_vkick] = -1/10.0*0.0121339',\n 'XC29602[bl_hkick] = -1/10.0*-0.0054313048',\n 'YC29603[bl_vkick] = -1/10.0*0.0',\n 'XC29702[bl_hkick] = -1/10.0*0.0',\n 'YC29703[bl_vkick] = -1/10.0*-0.0126719',\n 'XC29802[bl_hkick] = -1/10.0*-0.0090118476',\n 'YC29803[bl_vkick] = -1/10.0*0.0',\n 'XC29900[bl_hkick] = -1/10.0*0.0',\n 'YC29900[bl_vkick] = -1/10.0*0.0053165319',\n 'XC30202[bl_hkick] = -1/10.0*0.0098552456',\n 'YC30203[bl_vkick] = -1/10.0*0.0',\n 'XC30302[bl_hkick] = -1/10.0*0.0',\n 'YC30303[bl_vkick] = -1/10.0*0.0104512',\n 'XC30402[bl_hkick] = -1/10.0*0.0116309',\n 'YC30403[bl_vkick] = -1/10.0*0.0',\n 'XC30502[bl_hkick] = -1/10.0*0.0',\n 'YC30503[bl_vkick] = -1/10.0*-0.00029294573',\n 'XC30602[bl_hkick] = -1/10.0*0.0116635',\n 'YC30603[bl_vkick] = -1/10.0*0.0',\n 'XC30702[bl_hkick] = -1/10.0*0.0',\n 'YC30703[bl_vkick] = -1/10.0*0.0022248251',\n 'XC30802[bl_hkick] = -1/10.0*-0.0324942',\n 'YC30803[bl_vkick] = -1/10.0*-0.0064821935',\n 'YC30900[bl_vkick] = -1/10.0*-0.0141928',\n 'XC30900[bl_hkick] = -1/10.0*-0.0033939376',\n 'YCBSYQ1[bl_vkick] = -1/10.0*0.0154583',\n 'XCBSYQ2[bl_hkick] = -1/10.0*0.0356147',\n 'XCBSYQ3[bl_hkick] = -1/10.0*0.0098391283',\n 'YCBSYQ4[bl_vkick] = -1/10.0*0.0020892564',\n 'XCBSYQ5[bl_hkick] = -1/10.0*0.0011055839',\n 'YCBSYQ6[bl_vkick] = -1/10.0*0.0211416',\n 'XCA0[bl_hkick] = -1/10.0*0.0129006',\n 'YCA0[bl_vkick] = -1/10.0*-0.0072844568',\n 'YCVM1[bl_vkick] = -1/10.0*0.0139704',\n 'XCVM2[bl_hkick] = -1/10.0*-0.0078902',\n 'YCVB1[bl_vkick] = -1/10.0*-0.0101805',\n 'YCVB3[bl_vkick] = -1/10.0*-0.0066133029',\n 'XCVM3[bl_hkick] = -1/10.0*-0.0536461',\n 'YCVM4[bl_vkick] = -1/10.0*-0.0016709782',\n 'XCDL1[bl_hkick] = -1/10.0*-0.0261605',\n 'YCDL1[bl_vkick] = -1/10.0*-0.0250936',\n 'XCQT12[bl_hkick] = -1/10.0*-0.024181',\n 'YCQT12[bl_vkick] = -1/10.0*0.0050752281',\n 'XCDL2[bl_hkick] = -1/10.0*-0.0104621',\n 'YCDL2[bl_vkick] = -1/10.0*0.0227779',\n 'XCQT22[bl_hkick] = -1/10.0*0.0950371',\n 'YCQT22[bl_vkick] = -1/10.0*-0.0309693',\n 'XCDL3[bl_hkick] = -1/10.0*0.0091192089',\n 'YCDL3[bl_vkick] = -1/10.0*-0.0124526',\n 'XCQT32[bl_hkick] = -1/10.0*0.02612381363880746',\n 'YCQT32[bl_vkick] = -1/10.0*0.00775004664730824',\n 'XCDL4[bl_hkick] = -1/10.0*0.024538211320627647',\n 'YCDL4[bl_vkick] = -1/10.0*0.0257679',\n 'XCQT42[bl_hkick] = -1/10.0*-0.0425939',\n 'YCQT42[bl_vkick] = -1/10.0*-0.040481112931789076',\n 'YCEM1[bl_vkick] = -1/10.0*0.0070841246',\n 'XCEM2[bl_hkick] = -1/10.0*0.0475376',\n 'YCEM3[bl_vkick] = -1/10.0*0.0068124899',\n 'XCEM4[bl_hkick] = -1/10.0*-0.0317234',\n 'XCE31[bl_hkick] = -1/10.0*0.0187539',\n 'YCE32[bl_vkick] = -1/10.0*0.0149518',\n 'XCE33[bl_hkick] = -1/10.0*0.0035038913655287803',\n 'YCE34[bl_vkick] = -1/10.0*0.01042625509016189',\n 'XCE35[bl_hkick] = -1/10.0*0.0049977444',\n 'YCE36[bl_vkick] = -1/10.0*0.00565294',\n 'XCUM1[bl_hkick] = -1/10.0*0.014274982402359077',\n 'YCUM2[bl_vkick] = -1/10.0*0.04284595920903862',\n 'YCUM3[bl_vkick] = -1/10.0*0.0025508164206928734',\n 'XCUM4[bl_hkick] = -1/10.0*0.0187847829608311',\n 'XCU01[bl_hkick] = -1/10.0*2.2696218e-06',\n 'YCU01[bl_vkick] = -1/10.0*0.0',\n 'XCU02[bl_hkick] = -1/10.0*0.0',\n 'YCU02[bl_vkick] = -1/10.0*0.0',\n 'XCU03[bl_hkick] = -1/10.0*0.0',\n 'YCU03[bl_vkick] = -1/10.0*0.0',\n 'XCU04[bl_hkick] = -1/10.0*0.0',\n 'YCU04[bl_vkick] = -1/10.0*0.0',\n 'XCU05[bl_hkick] = -1/10.0*0.0',\n 'YCU05[bl_vkick] = -1/10.0*0.0',\n 'XCU06[bl_hkick] = -1/10.0*0.0',\n 'YCU06[bl_vkick] = -1/10.0*0.0',\n 'XCU07[bl_hkick] = -1/10.0*0.0',\n 'YCU07[bl_vkick] = -1/10.0*0.0',\n 'XCU08[bl_hkick] = -1/10.0*0.0',\n 'YCU08[bl_vkick] = -1/10.0*0.0',\n 'XCU09[bl_hkick] = -1/10.0*0.0',\n 'YCU09[bl_vkick] = -1/10.0*0.0',\n 'XCU10[bl_hkick] = -1/10.0*0.0',\n 'YCU10[bl_vkick] = -1/10.0*0.0',\n 'XCU11[bl_hkick] = -1/10.0*0.0',\n 'YCU11[bl_vkick] = -1/10.0*0.0',\n 'XCU12[bl_hkick] = -1/10.0*0.0',\n 'YCU12[bl_vkick] = -1/10.0*0.0',\n 'XCU13[bl_hkick] = -1/10.0*0.0',\n 'YCU13[bl_vkick] = -1/10.0*0.0',\n 'XCU14[bl_hkick] = -1/10.0*0.0',\n 'YCU14[bl_vkick] = -1/10.0*0.000324',\n 'XCU15[bl_hkick] = -1/10.0*0.0',\n 'YCU15[bl_vkick] = -1/10.0*0.0',\n 'XCU16[bl_hkick] = -1/10.0*0.0',\n 'YCU16[bl_vkick] = -1/10.0*0.0',\n 'XCU17[bl_hkick] = -1/10.0*0.0',\n 'YCU17[bl_vkick] = -1/10.0*0.0',\n 'XCU18[bl_hkick] = -1/10.0*0.0',\n 'YCU18[bl_vkick] = -1/10.0*-0.000108',\n 'XCU19[bl_hkick] = -1/10.0*0.0',\n 'YCU19[bl_vkick] = -1/10.0*0.0',\n 'XCU20[bl_hkick] = -1/10.0*0.0',\n 'YCU20[bl_vkick] = -1/10.0*0.0',\n 'XCU21[bl_hkick] = -1/10.0*0.0',\n 'YCU21[bl_vkick] = -1/10.0*0.0',\n 'XCU22[bl_hkick] = -1/10.0*0.0',\n 'YCU22[bl_vkick] = -1/10.0*0.0',\n 'XCU23[bl_hkick] = -1/10.0*0.0',\n 'YCU23[bl_vkick] = -1/10.0*0.0',\n 'XCU24[bl_hkick] = -1/10.0*0.0',\n 'YCU24[bl_vkick] = -1/10.0*0.0',\n 'XCU25[bl_hkick] = -1/10.0*0.0',\n 'YCU25[bl_vkick] = -1/10.0*0.0',\n 'XCU26[bl_hkick] = -1/10.0*0.0',\n 'YCU26[bl_vkick] = -1/10.0*0.0',\n 'XCU27[bl_hkick] = -1/10.0*0.0',\n 'YCU27[bl_vkick] = -1/10.0*0.0',\n 'XCU28[bl_hkick] = -1/10.0*0.0',\n 'YCU28[bl_vkick] = -1/10.0*0.0',\n 'XCU29[bl_hkick] = -1/10.0*0.0',\n 'YCU29[bl_vkick] = -1/10.0*0.0',\n 'XCU30[bl_hkick] = -1/10.0*6.0946396e-06',\n 'YCU30[bl_vkick] = -1/10.0*0.0',\n 'XCU31[bl_hkick] = -1/10.0*0.0',\n 'YCU31[bl_vkick] = -1/10.0*0.0',\n 'XCU32[bl_hkick] = -1/10.0*0.0',\n 'YCU32[bl_vkick] = -1/10.0*0.0',\n 'XCU33[bl_hkick] = -1/10.0*-1.1997552e-05',\n 'YCU33[bl_vkick] = -1/10.0*0.0',\n 'XCUE1[bl_hkick] = -1/10.0*0.0103638',\n 'YCUE2[bl_vkick] = -1/10.0*-0.0582',\n 'YCD3[bl_vkick] = -1/10.0*-0.109',\n 'XCD3[bl_hkick] = -1/10.0*-0.0226372',\n 'YCDD[bl_vkick] = -1/10.0*-0.109',\n 'XCDD[bl_hkick] = -1/10.0*0.0878592']</pre> In\u00a0[8]: Copied! <pre># Cleanup\nos.remove('test.bmad')\n</pre> # Cleanup os.remove('test.bmad')"},{"location":"examples/classic/csv_data_examples/#lcls-data","title":"LCLS data\u00b6","text":""},{"location":"examples/classic/csv_data_examples/#load-csv-using-pandas","title":"Load CSV using pandas\u00b6","text":""},{"location":"examples/classic/csv_data_examples/#parse-csv-for-bmad","title":"Parse CSV for Bmad\u00b6","text":""},{"location":"examples/classic/device_examples/","title":"Klystron example","text":"In\u00a0[1]: Copied! <pre># Useful for debugging\n%load_ext autoreload\n%autoreload 2\n</pre> # Useful for debugging %load_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre>from lcls_live.epics import epics_proxy\nfrom lcls_live import Klystron,  Magnet, BPM\nimport os\n</pre> from lcls_live.epics import epics_proxy from lcls_live import Klystron,  Magnet, BPM import os In\u00a0[3]: Copied! <pre>epics = epics_proxy('data/epics_snapshot_2018-03-06T15:21:15.000000-08:00.json', verbose=True)\n</pre> epics = epics_proxy('data/epics_snapshot_2018-03-06T15:21:15.000000-08:00.json', verbose=True) <pre>Loaded data/epics_snapshot_2018-03-06T15:21:15.000000-08:00.json with 2068 PVs\n</pre> In\u00a0[4]: Copied! <pre>k = Klystron(sector=21,station=2, epics=epics, verbose=True)\n</pre> k = Klystron(sector=21,station=2, epics=epics, verbose=True) <pre>caget_many on ['ACCL:LI21:180:L1X_S_AV', 'ACCL:LI21:180:L1X_S_PV', 'KLYS:LI21:21:PDES', 'KLYS:LI21:21:SWRD', 'KLYS:LI21:21:STAT', 'KLYS:LI21:21:HDSC', 'KLYS:LI21:21:DSTA', 'KLYS:LI21:21:BEAMCODE1_STAT']\n</pre> In\u00a0[5]: Copied! <pre># Base PV name\nk.name\n</pre> # Base PV name k.name Out[5]: <pre>'KLYS:LI21:21'</pre> In\u00a0[6]: Copied! <pre># Basic attributes are listed in\nk.attributes\n</pre> # Basic attributes are listed in k.attributes Out[6]: <pre>['enld', 'phase', 'pdes', 'swrd', 'stat', 'hdsc', 'dsta', 'acc_trigger_status']</pre> In\u00a0[7]: Copied! <pre># and thes attributes are held as\nk.enld, k.phase, k.pdes, k.swrd, k.stat, k.hdsc, k.dsta, k.acc_trigger_status\n</pre> # and thes attributes are held as k.enld, k.phase, k.pdes, k.swrd, k.stat, k.hdsc, k.dsta, k.acc_trigger_status Out[7]: <pre>(20.01551950520014,\n -159.9562692633193,\n -110.9,\n 0,\n 1,\n 5242881.0,\n [1610612738.0, 528640.0],\n 1.0)</pre> In\u00a0[8]: Copied! <pre># Summary methods\nk.is_usable(), k.is_accelerating(), k.has_faults()\n</pre> # Summary methods k.is_usable(), k.is_accelerating(), k.has_faults() Out[8]: <pre>(True, True, False)</pre> In\u00a0[9]: Copied! <pre># Here are the faults\nk.faults\n</pre> # Here are the faults k.faults Out[9]: <pre>[]</pre> In\u00a0[10]: Copied! <pre>from lcls_live import Collimator\n</pre> from lcls_live import Collimator In\u00a0[11]: Copied! <pre>coll = Collimator(name='COLL:LI21:235', epics=epics)\nprint(coll)\n</pre> coll = Collimator(name='COLL:LI21:235', epics=epics) print(coll) <pre>COLL with offset -3.4 mm\n</pre> In\u00a0[12]: Copied! <pre>coll.attributes\n</pre> coll.attributes Out[12]: <pre>['motr', 'lvpos']</pre> In\u00a0[13]: Copied! <pre>from lcls_live import Magnet\n</pre> from lcls_live import Magnet In\u00a0[14]: Copied! <pre>m = Magnet(name='QUAD:LI30:301', epics=epics, verbose=True)\nm.attributes, m.type\n</pre> m = Magnet(name='QUAD:LI30:301', epics=epics, verbose=True) m.attributes, m.type <pre>caget_many on ['QUAD:LI30:301:BACT']\n</pre> Out[14]: <pre>(['bact'], 'QUAD')</pre>"},{"location":"examples/classic/device_examples/#klystron-example","title":"Klystron example\u00b6","text":""},{"location":"examples/classic/device_examples/#collimator-example","title":"Collimator example\u00b6","text":""},{"location":"examples/classic/device_examples/#magnet-example","title":"Magnet example\u00b6","text":""},{"location":"live/get-lcls-live/","title":"Tao tooling","text":"<p><code>lcls-live</code> is packaged with a command line tool for generating tao commands from live or archived EPICS process variables. This command may be executed using epics:  </p> <pre><code>get-lcls-live --tao --beampath cu_hxr --source epics &gt; cmd.tao\n</code></pre> <p>And with archiver:</p> <p><code>$ get-lcls-live --tao --beampath cu_hxr --source archiver --isotime '2021-04-21T08:10:25.000000-07:00' &gt; cmd.tao</code></p> <p>At present the tool accomodates <code>--tao</code> or <code>--bmad</code> options for generating commands, <code>--beampath cu_hxr</code> or <code>--beampath cu_sxr</code>, <code>--source archiver</code> or <code>--source epics</code>.</p>"},{"location":"live/get-lcls-live/#epics-remote-environment","title":"Epics remote environment","text":"<p>Access to production process variables requires setting of the <code>$CA_NAME_SERVER_PORT</code>, <code>$LCLS_PROD_HOST</code>, and <code>$SLAC_MACHINE</code>. The utility script <code>configure-epics-remote</code> is installed with <code>lcls-live</code>. The script will perform forward local connections to the <code>$CA_NAME_SERVER_PORT</code> to the <code>$LCLS_PROD_HOST</code> via a double hop ssh and will required entry of your SLAC password. The process will run in the background and will require manual kill, identifying the pid with <code>ps aux |grep ssh</code>.</p> <p><code>$ configure-epics-remote</code></p>"},{"location":"live/get-lcls-live/#remote-archiver-environment","title":"Remote archiver environment","text":"<p>The remote archiver requires an ssh tunnel, which can be configured using the <code>configure-archiver-remote</code> script installed with lcls-live. This should be executed in a separate shell from the Tao command and the process allowed to continue for the duration of archiver use. The script requires setting the <code>$SLAC_ARCHIVER_HOST</code> and <code>$SLAC_USERNAME</code> environment variables. </p> <p><code>$ configure-archiver-remote</code></p>"},{"location":"live/get-lcls-live/#datamaps","title":"Datamaps","text":"<p>A utility notebook for generating datamaps is provided in <code>examples/LCLS_datamaps.ipynb</code>. This constructs relevant datamaps using the <code>pytao</code> Tao interface and requires setting the <code>$LCLS_LATTICE</code> and <code>$ACC_ROOT_DIR</code> </p>"},{"location":"other/","title":"Other resources","text":""},{"location":"other/#bmad","title":"Bmad","text":"<p>Bmad is used to model electron beam dynamics in thethe LCLS accelerators from the injectors through the undulators, and to the beam dumps.</p> <p>Bmad Homepage</p> <p>Bmad Manual</p> <p>Tao Manual</p> <p>Issues and Bug Reports should be entered on the Bmad GitHub</p>"},{"location":"other/#lume","title":"LUME","text":"<p>www.lume.science</p>"},{"location":"other/#pydm","title":"PyDM","text":"<p>Tutorial</p> <p>Documentation</p>"},{"location":"other/#matlab","title":"Matlab","text":"<p>Matlab Programmers Guide</p> <p>Software release procedure</p> <p>Cheatsheet</p>"},{"location":"other/#mad-lattices","title":"MAD Lattices","text":"<p>MAD Lattice release</p>"},{"location":"other/#device-element-name-and-pv-name-references","title":"Device, element name and PV name references","text":"<p>Oracle</p> <p>CVS</p> <p>Directory Service (?)</p> <p>Beamline Boundaries</p>"}]}